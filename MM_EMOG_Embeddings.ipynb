{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oEGBcom383pS"
      },
      "outputs": [],
      "source": [
        "# !pip install httplib2==0.15.0 #Requires restart on colab\n",
        "# !pip install --user flair\n",
        "# !pip install transformers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TbZOYtJzlUww"
      },
      "outputs": [],
      "source": [
        "import re\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import transformers\n",
        "\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "nltk.download('stopwords')\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sn\n",
        "from tabulate import tabulate\n",
        "\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.metrics import f1_score, accuracy_score, hamming_loss, classification_report, confusion_matrix, multilabel_confusion_matrix"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cXAStttJH8cz"
      },
      "outputs": [],
      "source": [
        "import time\n",
        "import math\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torch.nn.parameter import Parameter\n",
        "from torch.nn.modules.module import Module"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zuQPQHrHNs91"
      },
      "outputs": [],
      "source": [
        "from torch import cuda\n",
        "device = 'cuda' if cuda.is_available() else 'cpu'\n",
        "print(device)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Setup\n",
        "\n",
        "- add texts and labels\n",
        "- set preprocessing parameters\n",
        "- set model parameters"
      ],
      "metadata": {
        "id": "zmhAdWrO9GRy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#DATA\n",
        "\n",
        "original_train_sentences = []    #List of texts\n",
        "original_train_labels = []      #List of labels\n",
        "\n",
        "#PREPROCESSING\n",
        "DEIDENTIFY = True     #True -> replaces URLs, emails, and usernames with reserved tokens\n",
        "EMOPRESERVE = True    #True -> adds emoticons and emojis to tokenizer vocabulary and prevents them from being affected by further text cleaning\n",
        "TEXTCLEAN = False     #True -> removes or isolates specific punctuations and expands contractions\n",
        "TOKEN_TYPE = \"ws\"     #wp -> wordpiece tokenization; ws -> word split\n",
        "\n",
        "#GCN Parameters\n",
        "EDGE = 2                                # 0:d2w 1:d2w+w2w 2:d2w+w2w+d2d\n",
        "NODE = 2 if TOKEN_TYPE == \"ws\" else 1   # 0:one-hot #1:BERT  #2:GLOVE\n",
        "NUM_LAYERS = 2\n",
        "HIDDEN_DIM = 200\n",
        "DROP_OUT = 0.5\n",
        "LR = 0.02\n",
        "WEIGHT_DECAY = 0\n",
        "EARLY_STOPPING = 10\n",
        "GCN_EPOCHS = 200\n",
        "\n",
        "#BERT Parameters\n",
        "BERT_EPOCHS = 200\n",
        "BERT_DROPOUT = 0.5\n",
        "BERT_LR = 1e-05\n",
        "BERT_EARLYSTOP = 10\n",
        "MAX_LENGTH = 256\n",
        "\n",
        "#General Parameters\n",
        "BATCH_SIZE = 32"
      ],
      "metadata": {
        "id": "Eru0Bjt89K2x"
      },
      "execution_count": 131,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f3QSsuKsDaz4"
      },
      "source": [
        "#Load Resources"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 132,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UKfgCH5aDQuG",
        "outputId": "804deade-c563-4692-c13f-94d5f624d2c8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2609\n",
            "[':)', ':-)', ':]', ':-]', ':3', ':-3', ':>', ':->', '8)', '8-)']\n"
          ]
        }
      ],
      "source": [
        "#Load list of emoticons\n",
        "with open(\"resources/TextEmoticonList.txt\", \"r\") as file:\n",
        "  emoticonList = file.read().split(\"\\n\")\n",
        "\n",
        "#Remove emoticons with spaces in-between\n",
        "emoticonList = [emoticon for emoticon in emoticonList if len(emoticon.split(\" \")) == 1]\n",
        "\n",
        "#Remove one character emoticons\n",
        "emoticonList = [emoticon for emoticon in emoticonList if len(emoticon) > 1]\n",
        "\n",
        "print(len(emoticonList))\n",
        "print(emoticonList[:10])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 133,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Knh2n_bAZOrF",
        "outputId": "b151e646-53a5-4323-83a8-b6f844e514bc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1627\n",
            "['😀', '😁', '😂', '🤣', '😃', '😄', '😅', '😆', '😉', '😊']\n",
            "['\\\\U0001f600', '\\\\U0001f601', '\\\\U0001f602', '\\\\U0001f923', '\\\\U0001f603', '\\\\U0001f604', '\\\\U0001f605', '\\\\U0001f606', '\\\\U0001f609', '\\\\U0001f60a']\n"
          ]
        }
      ],
      "source": [
        "#Load list of emojis\n",
        "emojiList = pd.read_csv(\"resources/Emojis-Grid view.csv\")\n",
        "emojiList = emojiList[emojiList[\"Emoji\"] != \"C\"]\n",
        "emojiList = emojiList[\"Emoji\"].tolist()\n",
        "\n",
        "#Unicode versions\n",
        "emojiList_uni = [emoji.encode('unicode-escape').decode('ASCII') for emoji in emojiList]\n",
        "\n",
        "print(len(emojiList))\n",
        "print(emojiList[:10])\n",
        "print(emojiList_uni[:10])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AmEEIqrm-ZTY"
      },
      "source": [
        "# Load Lexicons"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cVfHLyfD-ZTZ"
      },
      "source": [
        "##EmoLex"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 134,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_cIYB9ye-ZTZ",
        "outputId": "71aea270-7188-4115-b37f-30d876735775"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Emotions: ['anger' 'anticipation' 'disgust' 'fear' 'joy' 'negative' 'positive'\n",
            " 'sadness' 'surprise' 'trust']\n",
            "Punctuations: []\n",
            "Stop words: {'haven', 'don'}\n"
          ]
        }
      ],
      "source": [
        "emoLex = pd.read_csv(\"_LEXICONS/NRC-Emotion-Lexicon-Wordlevel-v0.92.txt\", delimiter = \"\\t\", names = [\"Term\", \"AffectCategory\", \"AssociationFlag\"])\n",
        "print(\"Emotions:\", emoLex[\"AffectCategory\"].unique())\n",
        "\n",
        "#Check for punctuations on lexicon\n",
        "print(\"Punctuations:\", [text for text in emoLex[\"Term\"].unique().astype(str) if len(re.findall(\"[^#\\w]\", text)) > 0])\n",
        "\n",
        "#Check for stopwords\n",
        "stop = stopwords.words(\"english\")\n",
        "print(\"Stop words:\", set(emoLex[\"Term\"].unique().astype(str)) & set(stop))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 135,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "VrJMfEyuW0GI",
        "outputId": "9b9c5353-f495-4421-ba65-be440ad2fd9d"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "AffectCategory  anger  anticipation  disgust  fear  joy  negative  positive  \\\n",
              "Term                                                                          \n",
              "aback               0             0        0     0    0         0         0   \n",
              "abacus              0             0        0     0    0         0         0   \n",
              "abandon             0             0        0     1    0         1         0   \n",
              "abandoned           1             0        0     1    0         1         0   \n",
              "abandonment         1             0        0     1    0         1         0   \n",
              "\n",
              "AffectCategory  sadness  surprise  trust  other                 labels  \n",
              "Term                                                                    \n",
              "aback                 0         0      0      0  [0, 0, 0, 0, 0, 0, 0]  \n",
              "abacus                0         0      1      1  [0, 0, 0, 0, 0, 0, 1]  \n",
              "abandon               1         0      0      0  [0, 0, 1, 1, 0, 1, 0]  \n",
              "abandoned             1         0      0      0  [1, 0, 1, 1, 0, 1, 0]  \n",
              "abandonment           1         1      0      0  [1, 0, 1, 1, 1, 1, 0]  "
            ],
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th>AffectCategory</th>\n",
              "      <th>anger</th>\n",
              "      <th>anticipation</th>\n",
              "      <th>disgust</th>\n",
              "      <th>fear</th>\n",
              "      <th>joy</th>\n",
              "      <th>negative</th>\n",
              "      <th>positive</th>\n",
              "      <th>sadness</th>\n",
              "      <th>surprise</th>\n",
              "      <th>trust</th>\n",
              "      <th>other</th>\n",
              "      <th>labels</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Term</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>aback</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>[0, 0, 0, 0, 0, 0, 0]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>abacus</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>[0, 0, 0, 0, 0, 0, 1]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>abandon</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>[0, 0, 1, 1, 0, 1, 0]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>abandoned</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>[1, 0, 1, 1, 0, 1, 0]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>abandonment</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>[1, 0, 1, 1, 1, 1, 0]</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ]
          },
          "metadata": {},
          "execution_count": 135
        }
      ],
      "source": [
        "emoLex = pd.pivot(emoLex.loc[emoLex[\"Term\"].notna()], index = \"Term\", columns = \"AffectCategory\", values = \"AssociationFlag\")\n",
        "\n",
        "emoLex_labels = [\"anger\", \"disgust\", \"fear\", \"sadness\", \"surprise\", \"negative\", \"other\"] #removed none\n",
        "emoLex_otherLabels = [x for x in emoLex.columns.values if x not in emoLex_labels]\n",
        "\n",
        "emoLex[\"other\"] = (emoLex[emoLex_otherLabels].sum(axis = 1) > 0).astype(int)\n",
        "emoLex[\"labels\"] = [np.array(x) for x in emoLex[emoLex_labels].values.tolist()]\n",
        "\n",
        "emoLex_allTokens = emoLex.index.values\n",
        "emoLex_allEmotions = np.stack(emoLex[\"labels\"].values)\n",
        "\n",
        "emoLex.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SemhFfyV-ZTa"
      },
      "source": [
        "##TEC"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 136,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ca9VnMgi-ZTa",
        "outputId": "0d5fa11c-3d6e-4ff2-b05f-0eb5e0ceb754"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Emotions: ['anticipation' 'fear' 'anger' 'trust' 'surprise' 'sadness' 'joy'\n",
            " 'disgust']\n",
            "Punctuations: ['25/1', 'spring/summer', '20/20', '85%', 'r&amp', '9/11', '12/12/12', '30%', 'a$ap', '$2', 'love/hate', '25%', '+1', '50%', '95%', '40%', '$1', '60%', '^_^', '$20', '=d', '2%', '5%', '99%', '$200', 'and/or', '$100', '#&lt', '$10', '$50', '20%', 'w/', 'm&amp', '1%', '1/2', '12%', '#a&amp', '3%', 'b&amp', '10%', '4%', '6%', '*sigh*', 'w/out', 'h&amp', '=/', '//', '70%', 'w/o', '_&lt', '\\\\\\\\', 'f*ck', 'a&amp', 'sh*t', 'times&lt', 'f**king', 'things&lt', 'boyfriend/girlfriend', '^mj', 'them&lt', 'f***ing', 'b*tch', 'night&lt', 'f******', 'f*cking', 'f**k', 'back&lt', '$30', 'f***', 'bf/gf', '$300', 'school&lt', 'sky+', 'at&amp', 'today&lt', '$15', 'time&lt', 'him/her', 'day&lt', '24/7', '$80', '1/4', 'it&lt', '3/4', '80%', 'me&lt', 'b+', '&lt', '$25', 'me&amp', '9%', '98%', 'you&lt', '$60', '2/3', 'he/she', 'b/c', '$5', '$40', '75%', '$4', 'basic/glitter', 'standard&amp', 'sms/dm/', 'follow/rt', 'following/rt', '/line', '100%', 's/o', '&amp', 'class&gt', '2&gt', '94%', 'w/a', 'though&gt', '87%', 'you&gt', 'better&lt', 'night&gt', 'now&gt', 'ke$ha', '$1000', 'a*', '50/50', '0%', '&gt', '$8', 'me&gt', '7%', '$3', '90%', '\\\\\\\\3', '/3', '$$', 'day/night', '**', '^__^', '3&lt', 'w/my', '\\\\r', '^^', 'open&lt', 'mouth&lt', 'room&lt', 'a$$', 'now&lt', '$$$']\n",
            "Stop words: {'it', 'don', 'your', 'having', 'ain', 'haven', 'him', 'can', 'with', 'above', 'out', 'their', 'by', 'during', 'themselves', 'if', 'further', 'them', 'isn', 'while', 'shouldn', 'couldn', 'should', 'aren', 'through', 'where', 'were', 'own', 'most', 'does', 'who', 'has', 'hasn', 'theirs', 'down', 'which', 'but', 'being', 'until', 'those', 'than', 'after', 'both', 'been', 'ourselves', 'itself', 'any', 'be', 'off', 're', 'between', 'is', 'you', 'only', 'or', 'they', 'hers', 'from', 'up', 'how', 'other', 've', 'himself', 'doing', 'herself', 'that', 'no', 'didn', 'then', 'yours', 'few', 'yourself', 'some', 'weren', 'under', 'now', 'once', 'because', 'ours', 'against', 'over', 'for', 'so', 'do', 'doesn', 'll', 'hadn', 'had', 'wasn', 'won', 'her', 'these', 'am', 'why', 'nor', 'an', 'same', 'we', 'about', 'wouldn', 'on', 'very', 'below', 'will', 'too', 'not', 'our', 'at', 'such', 'yourselves', 'did', 'his', 'ma', 'before', 'was', 'my', 'are', 'each', 'he', 'me', 'myself', 'what', 'when', 'again', 'here', 'this', 'whom', 'she'}\n"
          ]
        }
      ],
      "source": [
        "tec = pd.read_csv(\"_LEXICONS/NRC-Hashtag-Emotion-Lexicon-v0.2.txt\", delimiter = \"\\t\", names = [\"AffectCategory\", \"Term\", \"Score\"])\n",
        "print(\"Emotions:\", tec[\"AffectCategory\"].unique())\n",
        "\n",
        "#Check for punctuations on lexicon\n",
        "print(\"Punctuations:\", [text for text in tec[\"Term\"].unique().astype(str) if len(re.findall(\"[^#\\w]\", text)) > 0])\n",
        "\n",
        "#Check for stopwords\n",
        "stop = stopwords.words(\"english\")\n",
        "print(\"Stop words:\", set(tec[\"Term\"].unique().astype(str)) & set(stop))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 137,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "sJgFpylodfl9",
        "outputId": "ab491415-ca4c-4e8b-a35b-1e0d16948dd8"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "AffectCategory             anger  anticipation  disgust  fear  joy  sadness  \\\n",
              "Term                                                                          \n",
              "#&lt                           0             0        0     0    1        0   \n",
              "#1                             0             0        0     0    0        0   \n",
              "#100thingsaboutme              0             0        0     0    0        0   \n",
              "#100thingsthatmakemehappy      0             0        0     0    1        0   \n",
              "#121212concert                 0             0        0     0    0        0   \n",
              "\n",
              "AffectCategory             surprise  trust  other              labels  \n",
              "Term                                                                   \n",
              "#&lt                              0      0      1  [0, 0, 0, 0, 0, 1]  \n",
              "#1                                0      0      0  [0, 0, 0, 0, 0, 0]  \n",
              "#100thingsaboutme                 0      0      0  [0, 0, 0, 0, 0, 0]  \n",
              "#100thingsthatmakemehappy         0      0      1  [0, 0, 0, 0, 0, 1]  \n",
              "#121212concert                    1      0      0  [0, 0, 0, 0, 1, 0]  "
            ],
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th>AffectCategory</th>\n",
              "      <th>anger</th>\n",
              "      <th>anticipation</th>\n",
              "      <th>disgust</th>\n",
              "      <th>fear</th>\n",
              "      <th>joy</th>\n",
              "      <th>sadness</th>\n",
              "      <th>surprise</th>\n",
              "      <th>trust</th>\n",
              "      <th>other</th>\n",
              "      <th>labels</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Term</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>#&amp;lt</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>[0, 0, 0, 0, 0, 1]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>#1</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>[0, 0, 0, 0, 0, 0]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>#100thingsaboutme</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>[0, 0, 0, 0, 0, 0]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>#100thingsthatmakemehappy</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>[0, 0, 0, 0, 0, 1]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>#121212concert</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>[0, 0, 0, 0, 1, 0]</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ]
          },
          "metadata": {},
          "execution_count": 137
        }
      ],
      "source": [
        "scoreThreshold = 0.5\n",
        "\n",
        "tec[\"Value\"] = (tec[\"Score\"] > scoreThreshold).astype(int)\n",
        "tec = pd.pivot(tec.loc[tec[\"Term\"].notna()], index = \"Term\", columns = \"AffectCategory\", values = \"Value\").fillna(0).astype(int)\n",
        "\n",
        "tec_labels = [\"anger\", \"disgust\", \"fear\", \"sadness\", \"surprise\", \"other\"] #removed none\n",
        "tec_otherLabels = [x for x in tec.columns.values if x not in tec_labels]\n",
        "\n",
        "tec[\"other\"] = (tec[tec_otherLabels].sum(axis = 1) > 0).astype(int)\n",
        "tec[\"labels\"] = [np.array(x) for x in tec[tec_labels].values.tolist()]\n",
        "\n",
        "tec_allTokens = tec.index.values\n",
        "tec_allEmotions = np.stack(tec[\"labels\"].values)\n",
        "\n",
        "tec.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c5J2GPPG-ZTa"
      },
      "source": [
        "##SenticNet"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 138,
      "metadata": {
        "id": "Vim00U2U-ZTb"
      },
      "outputs": [],
      "source": [
        "senticNet = pd.read_csv(\"_LEXICONS/senticnet_tsv.txt\", delimiter = \"\\t\", keep_default_na = False)\n",
        "\n",
        "senticNet[\"PRIMARY EMOTION\"] = senticNet[\"PRIMARY EMOTION\"].str.replace(\"#\", \"\")\n",
        "senticNet.loc[senticNet[\"PRIMARY EMOTION\"].isin([\"enthusiasm\", \"eagerness\", \"responsiveness\"]), \"MainEmotion\"] = \"eagerness\"\n",
        "senticNet.loc[senticNet[\"PRIMARY EMOTION\"].isin([\"calmness\", \"bliss\", \"serenity\"]), \"MainEmotion\"] = \"calmness\"\n",
        "senticNet.loc[senticNet[\"PRIMARY EMOTION\"].isin([\"joy\", \"ecstasy\", \"contentment\"]), \"MainEmotion\"] = \"joy\"\n",
        "senticNet.loc[senticNet[\"PRIMARY EMOTION\"].isin([\"pleasantness\", \"acceptance\", \"delight\"]), \"MainEmotion\"] = \"pleasantness\"\n",
        "senticNet.loc[senticNet[\"PRIMARY EMOTION\"].isin([\"disgust\", \"dislike\", \"loathing\"]), \"MainEmotion\"] = \"disgust\"\n",
        "senticNet.loc[senticNet[\"PRIMARY EMOTION\"].isin([\"sadness\", \"grief\", \"melancholy\"]), \"MainEmotion\"] = \"sadness\"\n",
        "senticNet.loc[senticNet[\"PRIMARY EMOTION\"].isin([\"anger\", \"annoyance\", \"rage\"]), \"MainEmotion\"] = \"anger\"\n",
        "senticNet.loc[senticNet[\"PRIMARY EMOTION\"].isin([\"fear\", \"anxiety\", \"terror\"]), \"MainEmotion\"] = \"fear\"\n",
        "\n",
        "senticNet[\"SECONDAY EMOTION\"] = senticNet[\"SECONDAY EMOTION\"].str.replace(\"#\", \"\")\n",
        "senticNet.loc[senticNet[\"SECONDAY EMOTION\"].isin([\"enthusiasm\", \"eagerness\", \"responsiveness\"]), \"SecondEmotion\"] = \"eagerness\"\n",
        "senticNet.loc[senticNet[\"SECONDAY EMOTION\"].isin([\"calmness\", \"bliss\", \"serenity\"]), \"SecondEmotion\"] = \"calmness\"\n",
        "senticNet.loc[senticNet[\"SECONDAY EMOTION\"].isin([\"joy\", \"ecstasy\", \"contentment\"]), \"SecondEmotion\"] = \"joy\"\n",
        "senticNet.loc[senticNet[\"SECONDAY EMOTION\"].isin([\"pleasantness\", \"acceptance\", \"delight\"]), \"SecondEmotion\"] = \"pleasantness\"\n",
        "senticNet.loc[senticNet[\"SECONDAY EMOTION\"].isin([\"disgust\", \"dislike\", \"loathing\"]), \"SecondEmotion\"] = \"disgust\"\n",
        "senticNet.loc[senticNet[\"SECONDAY EMOTION\"].isin([\"sadness\", \"grief\", \"melancholy\"]), \"SecondEmotion\"] = \"sadness\"\n",
        "senticNet.loc[senticNet[\"SECONDAY EMOTION\"].isin([\"anger\", \"annoyance\", \"rage\"]), \"SecondEmotion\"] = \"anger\"\n",
        "senticNet.loc[senticNet[\"SECONDAY EMOTION\"].isin([\"fear\", \"anxiety\", \"terror\"]), \"SecondEmotion\"] = \"fear\"\n",
        "\n",
        "senticNet[\"Value\"] = 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 139,
      "metadata": {
        "id": "JvyhJeoOlhUk"
      },
      "outputs": [],
      "source": [
        "temp = pd.concat((senticNet[[\"CONCEPT\", \"MainEmotion\"]],\n",
        "                  senticNet.loc[senticNet[\"SecondEmotion\"].notna(), [\"CONCEPT\", \"SecondEmotion\"]].rename(columns = {\"SecondEmotion\": \"MainEmotion\"}),\n",
        "                  senticNet[[\"CONCEPT\", \"POLARITY VALUE\"]].rename(columns = {\"POLARITY VALUE\": \"MainEmotion\"})))\n",
        "temp = temp.drop_duplicates()\n",
        "temp[\"Value\"] = 1\n",
        "\n",
        "senticNet = pd.pivot(temp, index = \"CONCEPT\", columns = \"MainEmotion\", values = \"Value\").fillna(0).astype(int)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 140,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "cTsPG2Vokw-V",
        "outputId": "4bdf13e7-4ffd-40ce-a08d-0badf352e505"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "MainEmotion  anger  calmness  disgust  eagerness  fear  joy  nan  negative  \\\n",
              "CONCEPT                                                                      \n",
              "( :              0         0        0          0     0    1    1         0   \n",
              "( x              0         0        0          0     0    1    1         0   \n",
              "(':              0         0        0          0     0    1    1         0   \n",
              "(-':             0         0        0          0     0    1    1         0   \n",
              "(-:              0         0        0          0     0    1    1         0   \n",
              "\n",
              "MainEmotion  pleasantness  positive  sadness  other              labels  \n",
              "CONCEPT                                                                  \n",
              "( :                     0         1        0      1  [0, 0, 0, 0, 0, 1]  \n",
              "( x                     0         1        0      1  [0, 0, 0, 0, 0, 1]  \n",
              "(':                     0         1        0      1  [0, 0, 0, 0, 0, 1]  \n",
              "(-':                    0         1        0      1  [0, 0, 0, 0, 0, 1]  \n",
              "(-:                     0         1        0      1  [0, 0, 0, 0, 0, 1]  "
            ],
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th>MainEmotion</th>\n",
              "      <th>anger</th>\n",
              "      <th>calmness</th>\n",
              "      <th>disgust</th>\n",
              "      <th>eagerness</th>\n",
              "      <th>fear</th>\n",
              "      <th>joy</th>\n",
              "      <th>nan</th>\n",
              "      <th>negative</th>\n",
              "      <th>pleasantness</th>\n",
              "      <th>positive</th>\n",
              "      <th>sadness</th>\n",
              "      <th>other</th>\n",
              "      <th>labels</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>CONCEPT</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>( :</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>[0, 0, 0, 0, 0, 1]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>( x</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>[0, 0, 0, 0, 0, 1]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>(':</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>[0, 0, 0, 0, 0, 1]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>(-':</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>[0, 0, 0, 0, 0, 1]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>(-:</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>[0, 0, 0, 0, 0, 1]</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ]
          },
          "metadata": {},
          "execution_count": 140
        }
      ],
      "source": [
        "senticNet_labels = [\"anger\", \"disgust\", \"fear\", \"sadness\", \"negative\", \"other\"] #removed none\n",
        "senticNet_otherLabels = [x for x in senticNet.columns.values if x not in senticNet_labels]\n",
        "\n",
        "senticNet[\"other\"] = (senticNet[senticNet_otherLabels].sum(axis = 1) > 0).astype(int)\n",
        "senticNet[\"labels\"] = [np.array(x) for x in senticNet[senticNet_labels].values.tolist()]\n",
        "\n",
        "senticNet_allTokens = senticNet.index.values\n",
        "senticNet_allEmotions = np.stack(senticNet[\"labels\"].values)\n",
        "\n",
        "senticNet.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hJPI-IXrBkrP"
      },
      "source": [
        "# Dataset Preparation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 141,
      "metadata": {
        "id": "-GyzNkI7W03D"
      },
      "outputs": [],
      "source": [
        "train_size = len(original_train_sentences)\n",
        "test_size = 0\n",
        "\n",
        "sentences = original_train_sentences"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a2W7wKTBfa71"
      },
      "source": [
        "# Preprocess"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 142,
      "metadata": {
        "id": "sbws3oNj7nSP"
      },
      "outputs": [],
      "source": [
        "if TOKEN_TYPE == \"wp\":\n",
        "  tokenTitle = \"WordPiece\"\n",
        "elif TOKEN_TYPE == \"ws\":\n",
        "  tokenTitle = \"WordSplit\"\n",
        "else:\n",
        "  raise Exception(\"Invalid token type.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 143,
      "metadata": {
        "id": "-CFuPPcWFk-4"
      },
      "outputs": [],
      "source": [
        "tokenURL = \"_URL_\"\n",
        "tokenEmail = \"_EMAIL_\"\n",
        "tokenUsername = \"_USER_\"\n",
        "reserveTokens = [tokenURL, tokenEmail, tokenUsername]\n",
        "\n",
        "#CLEANING PROCESS\n",
        "#- Include emojis and emoticons\n",
        "#- Replace url, email, and usernames with tokens\n",
        "#- Remove non-major puncutations and separate them from words with whitespaces\n",
        "#- Lowercase\n",
        "def preprocess_str(string):\n",
        "\n",
        "  #Preclean\n",
        "  if DEIDENTIFY:\n",
        "    string = re.sub(r\"https?://[^\\s]+\", tokenURL, string)              #Links\n",
        "    string = re.sub(r\"[\\w.+-]+@[\\w-]+\\.[\\w.-]+\", tokenEmail, string)   #Email\n",
        "    string = re.sub(r\"@[a-zA-Z0-9_]{2,}\", tokenUsername, string)       #Usernames\n",
        "\n",
        "  #Emoticon/Emoji split\n",
        "  tokens = [string]\n",
        "  if EMOPRESERVE:\n",
        "    allEmo = emoticonList + emojiList + emojiList_uni + reserveTokens\n",
        "    for emoticon in allEmo:\n",
        "      if emoticon in string:\n",
        "        splits = []\n",
        "        for split in tokens:\n",
        "          splits.append(re.split(r\"(\" + re.escape(emoticon) + \")\", split))\n",
        "        tokens = [y.strip() for x in splits for y in x if y != \"\"]\n",
        "\n",
        "  for idx in range(len(tokens)):\n",
        "    if EMOPRESERVE and tokens[idx] in allEmo: #Skip emoticons, emojis\n",
        "      continue\n",
        "\n",
        "    if TEXTCLEAN:\n",
        "      tokens[idx] = re.sub(r\"[^A-Za-z0-9(),!?\\.\\'\\`]\", \" \", tokens[idx])\n",
        "      tokens[idx] = re.sub(r\"\\'s\", \" \\'s\", tokens[idx])\n",
        "      tokens[idx] = re.sub(r\"\\'ve\", \" \\'ve\", tokens[idx])\n",
        "      tokens[idx] = re.sub(r\"n\\'t\", \" n\\'t\", tokens[idx])\n",
        "      tokens[idx] = re.sub(r\"\\'re\", \" \\'re\", tokens[idx])\n",
        "      tokens[idx] = re.sub(r\"\\'d\", \" \\'d\", tokens[idx])\n",
        "      tokens[idx] = re.sub(r\"\\'ll\", \" \\'ll\", tokens[idx])\n",
        "      tokens[idx] = re.sub(r\",\", \" , \", tokens[idx])\n",
        "      tokens[idx] = re.sub(r\"!\", \" ! \", tokens[idx])\n",
        "      tokens[idx] = re.sub(r\"\\(\", \" ( \", tokens[idx])\n",
        "      tokens[idx] = re.sub(r\"\\)\", \" ) \", tokens[idx])\n",
        "      tokens[idx] = re.sub(r\"\\?\", \" ? \", tokens[idx])\n",
        "      tokens[idx] = re.sub(r\"\\.\", \" . \", tokens[idx])\n",
        "      tokens[idx] = re.sub(r\"\\s{2,}\", \" \", tokens[idx])\n",
        "\n",
        "    #Lower case and strip by default\n",
        "    tokens[idx] = tokens[idx].lower().strip()\n",
        "\n",
        "  return \" \".join(tokens)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eyfCxMUJeEQ4"
      },
      "source": [
        "##Tokenizer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 144,
      "metadata": {
        "id": "6KsklvB7KNwt"
      },
      "outputs": [],
      "source": [
        "#Load BERT tokenizer\n",
        "if TOKEN_TYPE == \"wp\":\n",
        "  from transformers import BertTokenizer\n",
        "  tokenizer = BertTokenizer.from_pretrained(\"bert-base-uncased\")\n",
        "\n",
        "  if DEIDENTIFY:\n",
        "    tokenizer.add_tokens(reserveTokens)\n",
        "\n",
        "  if EMOPRESERVE:\n",
        "    tokenizer.add_tokens(emoticonList + emojiList + emojiList_uni)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 145,
      "metadata": {
        "id": "mg8OoA7JeGTr"
      },
      "outputs": [],
      "source": [
        "def tokenize_str(string):\n",
        "  if TOKEN_TYPE.lower() == \"wp\":\n",
        "    #Use BERT Tokenizer\n",
        "    return tokenizer.tokenize(string)\n",
        "  elif TOKEN_TYPE.lower() == \"ws\":\n",
        "    return string.split()\n",
        "  else:\n",
        "    raise Exception(\"Unknown value for TOKEN_TYPE\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZMkEBxr6fMQi"
      },
      "source": [
        "## Remove less frequent words, tokenize sentences"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 146,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "referenced_widgets": [
            "a09331114a3e4dc7b82fd818fe9c0797",
            "46e1f89e3b78414c8e191cdd942b589b",
            "5d6cc7c973eb47308a063b9d686f9562",
            "1b7f486fb0504f768815be0bebb5d603",
            "ad434b03e7ff4d138df37ebc5942f286",
            "6c738b4de124438abf2558879c3d7dc2",
            "962be31c2c2c44bfb9a0290bc9929065",
            "8b444b280db64844b5242c8964b60f13",
            "bbda5e69ffef472b9d361701f507e7a5",
            "d74dc0d8381e4f9082dac5587a54fbeb",
            "ee3c118a96ad4cd59af5da81cde0f233",
            "e51f8ddc90254bff885281f8fd27aab3",
            "5ac030c53bfd40258b49c20b2ca5b068",
            "2f7ad31d03794db2a57ded4f0590e874",
            "887b8c925e36496eb05b92f1eab19f45",
            "d5931ed4f6db4c1d84abb133abbd24a6",
            "c2ebb7e2bcd646dfb6b28935e4c79021",
            "7f22547077f944eab0b66e9c2ec279ff",
            "31156e7183d84a9d9c28d0b2ff03ccd3",
            "3a255fe720334bfcbc8e7b83f018138d",
            "4b1c4c65ff5744f3babe93337751193a",
            "d95669ae893d4c4696336b73db108a90"
          ],
          "height": 0
        },
        "id": "1xRG94uDfaBV",
        "outputId": "b01c5a56-df22-40b5-cec6-06b8a8d028e1"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/500 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "a09331114a3e4dc7b82fd818fe9c0797"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/500 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "e51f8ddc90254bff885281f8fd27aab3"
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "from tqdm.notebook import tqdm\n",
        "stop_words = set(stopwords.words('english'))\n",
        "remove_limit = 5\n",
        "\n",
        "original_word_freq = {}  # to remove rare words\n",
        "for sentence in tqdm(sentences):\n",
        "    temp = preprocess_str(sentence)\n",
        "    word_list = tokenize_str(temp)[:512] #Manual truncation\n",
        "    for word in word_list:\n",
        "        if word in original_word_freq:\n",
        "            original_word_freq[word] += 1\n",
        "        else:\n",
        "            original_word_freq[word] = 1\n",
        "\n",
        "tokenize_sentences = []\n",
        "word_list_dict = {}\n",
        "for sentence in tqdm(sentences):\n",
        "    temp = preprocess_str(sentence)\n",
        "    word_list_temp = tokenize_str(temp)[:512] #Manual truncation\n",
        "    doc_words = []\n",
        "    for word in word_list_temp:\n",
        "        #NOTE: Including stopwords\n",
        "        # if word in original_word_freq and word not in stop_words and original_word_freq[word] >= remove_limit:\n",
        "        if word in original_word_freq and original_word_freq[word] >= remove_limit:\n",
        "            doc_words.append(word)\n",
        "            word_list_dict[word] = 1\n",
        "    tokenize_sentences.append(doc_words)\n",
        "word_list = list(word_list_dict.keys())\n",
        "vocab_length = len(word_list)\n",
        "\n",
        "#word to id dict\n",
        "word_id_map = {}\n",
        "for i in range(vocab_length):\n",
        "    word_id_map[word_list[i]] = i\n",
        "\n",
        "#Convert tokens to ids\n",
        "tokenize_sentences_tokenIds = []\n",
        "for tokens in tokenize_sentences:\n",
        "  sent_token_ids = []\n",
        "  for token in tokens:\n",
        "    sent_token_ids.append(word_id_map[token])\n",
        "  tokenize_sentences_tokenIds.append(sent_token_ids)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 147,
      "metadata": {
        "id": "dqLUncB2Pn_L"
      },
      "outputs": [],
      "source": [
        "node_size = train_size + vocab_length"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JWPxVGNeAPf7"
      },
      "source": [
        "## Document-Emotion Label Encoding"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 148,
      "metadata": {
        "id": "ZRcB__qSFYwB"
      },
      "outputs": [],
      "source": [
        "#Encode document emotions (multi)\n",
        "def encodeDocEmotions(lexTokens, lexEmotions, tokenized_sentences):\n",
        "\n",
        "  if len(lexTokens) != len(lexEmotions):\n",
        "    raise Exception(\"Tokens and labels must match in length.\")\n",
        "\n",
        "  labels_doc_emo = []\n",
        "  for sentence in tokenized_sentences:\n",
        "    matchTokens = set(lexTokens) & set(sentence)\n",
        "\n",
        "    sentence_emotions = lexEmotions[np.sum(np.array([lexTokens == token for token in matchTokens]), axis = 0) > 0]\n",
        "    if len(sentence_emotions) == 0:\n",
        "      sentence_emotions = np.zeros(lexEmotions.shape[1]).astype(int)\n",
        "    else:\n",
        "      sentence_emotions = (np.sum(sentence_emotions, axis = 0) > 0).astype(int)\n",
        "\n",
        "    labels_doc_emo.append(sentence_emotions)\n",
        "\n",
        "  return np.stack(labels_doc_emo), lexEmotions.shape[1]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g0o8wcXgrTiD"
      },
      "source": [
        "# Model input"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 150,
      "metadata": {
        "id": "EZbRV2wYxY1U"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from tqdm.notebook import tqdm"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "znJ7Grz7fQ2L"
      },
      "source": [
        "## Build Graph"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 151,
      "metadata": {
        "id": "-BSg1uNgV3_7"
      },
      "outputs": [],
      "source": [
        "from math import log\n",
        "row = []\n",
        "col = []\n",
        "weight = []"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QESQPT88AqsI"
      },
      "source": [
        "### word-word: PMI"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 152,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "referenced_widgets": [
            "d22cabc301f24cba8d562308d4467148",
            "362215065fc5406bb37ff377ad4e3210",
            "4e5b0df2ded74685b2a8da4d6d90def1",
            "657da52bf0b7428fbadb1e8f629fc156",
            "9fda2e44284b40a49b722151b0b31b44",
            "285dcbae20f34e09aa13a77c4c08e7ce",
            "db94baa55dbe4867ae3100eff5fe556a",
            "39aa61b334be4a63b11a0f6e8de01259",
            "cfa0fb88dbe642ad8f697d6e5b0f6196",
            "ea83dccc30884aef85979303a6c9ef14",
            "38b339df01f44995b066111f0daf6db6"
          ],
          "height": 0
        },
        "id": "KNlJoLFagXhv",
        "outputId": "bdcfb88b-48f5-4669-c6ca-d822000bc6f6"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/500 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "d22cabc301f24cba8d562308d4467148"
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "if EDGE >= 1:\n",
        "    window_size = 20\n",
        "    total_W = 0\n",
        "    word_occurrence = {}\n",
        "    word_pair_occurrence = {}\n",
        "\n",
        "    def ordered_word_pair(a, b):\n",
        "        if a > b:\n",
        "            return b, a\n",
        "        else:\n",
        "            return a, b\n",
        "\n",
        "    def update_word_and_word_pair_occurrence(q):\n",
        "        unique_q = list(set(q))\n",
        "        for i in unique_q:\n",
        "            try:\n",
        "                word_occurrence[i] += 1\n",
        "            except:\n",
        "                word_occurrence[i] = 1\n",
        "        for i in range(len(unique_q)):\n",
        "            for j in range(i+1, len(unique_q)):\n",
        "                word1 = unique_q[i]\n",
        "                word2 = unique_q[j]\n",
        "                word1, word2 = ordered_word_pair(word1, word2)\n",
        "                try:\n",
        "                    word_pair_occurrence[(word1, word2)] += 1\n",
        "                except:\n",
        "                    word_pair_occurrence[(word1, word2)] = 1\n",
        "\n",
        "\n",
        "    for ind in tqdm(range(train_size+test_size)):\n",
        "        words = tokenize_sentences[ind]\n",
        "\n",
        "        q = []\n",
        "        # push the first (window_size) words into a queue\n",
        "        for i in range(min(window_size, len(words))):\n",
        "            q += [word_id_map[words[i]]]\n",
        "        # update the total number of the sliding windows\n",
        "        total_W += 1\n",
        "        # update the number of sliding windows that contain each word and word pair\n",
        "        update_word_and_word_pair_occurrence(q)\n",
        "\n",
        "        now_next_word_index = window_size\n",
        "        # pop the first word out and let the next word in, keep doing this until the end of the document\n",
        "        while now_next_word_index<len(words):\n",
        "            q.pop(0)\n",
        "            q += [word_id_map[words[now_next_word_index]]]\n",
        "            now_next_word_index += 1\n",
        "            # update the total number of the sliding windows\n",
        "            total_W += 1\n",
        "            # update the number of sliding windows that contain each word and word pair\n",
        "            update_word_and_word_pair_occurrence(q)\n",
        "\n",
        "    for word_pair in word_pair_occurrence:\n",
        "        i = word_pair[0]\n",
        "        j = word_pair[1]\n",
        "        count = word_pair_occurrence[word_pair]\n",
        "        word_freq_i = word_occurrence[i]\n",
        "        word_freq_j = word_occurrence[j]\n",
        "        pmi = log((count * total_W) / (word_freq_i * word_freq_j))\n",
        "        if pmi <=0:\n",
        "            continue\n",
        "        row.append(train_size + i)\n",
        "        col.append(train_size + j)\n",
        "        weight.append(pmi)\n",
        "        row.append(train_size + j)\n",
        "        col.append(train_size + i)\n",
        "        weight.append(pmi)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hynLnT3a33kW"
      },
      "source": [
        "### doc-word: Tf-idf"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 153,
      "metadata": {
        "id": "BnSPqhg1lHps"
      },
      "outputs": [],
      "source": [
        "#get each word appears in which document\n",
        "word_doc_list = {}\n",
        "for word in word_list:\n",
        "    word_doc_list[word]=[]\n",
        "\n",
        "for i in range(len(tokenize_sentences)):\n",
        "    doc_words = tokenize_sentences[i]\n",
        "    unique_words = set(doc_words)\n",
        "    for word in unique_words:\n",
        "        exsit_list = word_doc_list[word]\n",
        "        exsit_list.append(i)\n",
        "        word_doc_list[word] = exsit_list\n",
        "\n",
        "#document frequency\n",
        "word_doc_freq = {}\n",
        "for word, doc_list in word_doc_list.items():\n",
        "    word_doc_freq[word] = len(doc_list)\n",
        "\n",
        "# term frequency\n",
        "doc_word_freq = {}\n",
        "\n",
        "for doc_id in range(len(tokenize_sentences)):\n",
        "    words = tokenize_sentences[doc_id]\n",
        "    for word in words:\n",
        "        word_id = word_id_map[word]\n",
        "        doc_word_str = str(doc_id) + ',' + str(word_id)\n",
        "        if doc_word_str in doc_word_freq:\n",
        "            doc_word_freq[doc_word_str] += 1\n",
        "        else:\n",
        "            doc_word_freq[doc_word_str] = 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 154,
      "metadata": {
        "id": "Z6elPPFO_sXp"
      },
      "outputs": [],
      "source": [
        "for i in range(len(tokenize_sentences)):\n",
        "    words = tokenize_sentences[i]\n",
        "    doc_word_set = set()\n",
        "    for word in words:\n",
        "        if word in doc_word_set:\n",
        "            continue\n",
        "        j = word_id_map[word]\n",
        "        key = str(i) + ',' + str(j)\n",
        "        freq = doc_word_freq[key]\n",
        "        if i < train_size:\n",
        "            row.append(i)\n",
        "        else:\n",
        "            row.append(i + vocab_length)\n",
        "        col.append(train_size + j)\n",
        "        idf = log(1.0 * len(tokenize_sentences) / word_doc_freq[word_list[j]])\n",
        "        weight.append(freq * idf)\n",
        "        doc_word_set.add(word)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FAr6ygKhWTc-"
      },
      "source": [
        "### doc-doc: jaccard"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 155,
      "metadata": {
        "id": "T4-EH15oWWSX",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "referenced_widgets": [
            "a5d7757e709c42f789253a8d26674c2b",
            "026eb4e8446a48bd953f5fb3aa419593",
            "d7046fde62c345acbf63fd0b54679d7c",
            "b29321930db841c0ac8b895c500a23ef",
            "fac2526914124391a0e4a192616f4b6a",
            "ca0a1c5d01fd43beac670245cf3a4ef7",
            "288c8578cbc1437587d424390ecfcc4a",
            "483b4dd656744f70aa33dab28328a052",
            "486416b80c7f4a64ad9ca2bfac222a2e",
            "5de050a8934a451d9fd95b82f7c71ada",
            "3608b7a9b5434da59f3a7a67bd91bd03"
          ],
          "height": 0
        },
        "outputId": "349505cc-5175-4b86-9648-efb14caad220"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/500 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "a5d7757e709c42f789253a8d26674c2b"
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "import nltk\n",
        "\n",
        "if EDGE>=2:\n",
        "    tokenize_sentences_set = [set(s) for s in tokenize_sentences]\n",
        "    jaccard_threshold = 0.2\n",
        "    for i in tqdm(range(len(tokenize_sentences))):\n",
        "        for j in range(i+1, len(tokenize_sentences)):\n",
        "\n",
        "            #NOTE: RINA EDIT\n",
        "            #Jaccard distance is throwing an error when both sets are empty\n",
        "            if (len(tokenize_sentences_set[i]) == 0) & (len(tokenize_sentences_set[j]) == 0):\n",
        "              continue\n",
        "\n",
        "            jaccard_w = 1 - nltk.jaccard_distance(tokenize_sentences_set[i], tokenize_sentences_set[j])\n",
        "            if jaccard_w > jaccard_threshold:\n",
        "                if i < train_size:\n",
        "                    row.append(i)\n",
        "                else:\n",
        "                    row.append(i + vocab_length)\n",
        "                if j < train_size:\n",
        "                    col.append(j)\n",
        "                else:\n",
        "                    col.append(vocab_length + j)\n",
        "                weight.append(jaccard_w)\n",
        "                if j < train_size:\n",
        "                    row.append(j)\n",
        "                else:\n",
        "                    row.append(j + vocab_length)\n",
        "                if i < train_size:\n",
        "                    col.append(i)\n",
        "                else:\n",
        "                    col.append(vocab_length + i)\n",
        "                weight.append(jaccard_w)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uIkGgB2aZDk7"
      },
      "source": [
        "### Adjacent matrix"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 156,
      "metadata": {
        "id": "C0O1Ucdhod9a"
      },
      "outputs": [],
      "source": [
        "import scipy.sparse as sp\n",
        "adj = sp.csr_matrix((weight, (row, col)), shape=(node_size, node_size))\n",
        "\n",
        "# build symmetric adjacency matrix\n",
        "adj = adj + adj.T.multiply(adj.T > adj) - adj.multiply(adj.T > adj)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 157,
      "metadata": {
        "id": "ivyuexATkQFW"
      },
      "outputs": [],
      "source": [
        "def normalize_adj(adj):\n",
        "    \"\"\"Symmetrically normalize adjacency matrix.\"\"\"\n",
        "    adj = sp.coo_matrix(adj)\n",
        "    rowsum = np.array(adj.sum(1))\n",
        "    d_inv_sqrt = np.power(rowsum, -0.5).flatten()\n",
        "    d_inv_sqrt[np.isinf(d_inv_sqrt)] = 0.\n",
        "    d_mat_inv_sqrt = sp.diags(d_inv_sqrt)\n",
        "    return adj.dot(d_mat_inv_sqrt).transpose().dot(d_mat_inv_sqrt).tocoo(), d_inv_sqrt\n",
        "\n",
        "adj, norm_item = normalize_adj(adj + sp.eye(adj.shape[0]))\n",
        "\n",
        "\n",
        "def sparse_mx_to_torch_sparse_tensor(sparse_mx):\n",
        "    \"\"\"Convert a scipy sparse matrix to a torch sparse tensor.\"\"\"\n",
        "    sparse_mx = sparse_mx.tocoo().astype(np.float32)\n",
        "    indices = torch.from_numpy(\n",
        "        np.vstack((sparse_mx.row, sparse_mx.col)).astype(np.int64))\n",
        "    values = torch.from_numpy(sparse_mx.data)\n",
        "    shape = torch.Size(sparse_mx.shape)\n",
        "    return torch.sparse.FloatTensor(indices, values, shape).to(device)\n",
        "\n",
        "adj = sparse_mx_to_torch_sparse_tensor(adj)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pMgbhTstMSUA"
      },
      "source": [
        "## Features"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 158,
      "metadata": {
        "id": "jLk4WlqGm2nC"
      },
      "outputs": [],
      "source": [
        "#LOAD GLOVE\n",
        "gloveFilePath = \"resources/glove.twitter.27B.100d.txt\"\n",
        "\n",
        "def getGloveModel():\n",
        "  #Convert Glove format to Word2Vec format\n",
        "  import gensim\n",
        "  from gensim.test.utils import datapath, get_tmpfile\n",
        "  from gensim.models import KeyedVectors\n",
        "  from gensim.scripts.glove2word2vec import glove2word2vec\n",
        "\n",
        "  # https://radimrehurek.com/gensim/scripts/glove2word2vec.html\n",
        "  tmp_file = get_tmpfile(\"test_word2vec.txt\")\n",
        "  glove2word2vec(gloveFilePath, tmp_file)\n",
        "  print(\"Converted glove to word2vec format\")\n",
        "\n",
        "  gloveModel = KeyedVectors.load_word2vec_format(tmp_file)\n",
        "  gloveDim = gloveModel.vector_size\n",
        "  print(\"Loaded pretrained glove model\")\n",
        "\n",
        "  return gloveModel, gloveDim"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 159,
      "metadata": {
        "id": "mP9dqCskOrXT",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0,
          "referenced_widgets": [
            "f8acffe7c2174ad8a7c83d92085c1f8e",
            "86a7081bb8b6496dbc4a55d792e22bf9",
            "32eb260f8aa44627b6dfd31c47706411",
            "68eae634396649c48be47a5e0a855d29",
            "3206873d6ade4ce2a2af982beecee3a2",
            "902ca8fb17d143b7840b7af112edb5b8",
            "311a915b3b284c9bb7a775b2b027cfe3",
            "0d83c8b157b54de1a5ced74cf5156da0",
            "8edb55c069504913b73150b5c78f962d",
            "856a23f5f19342b2a502c10d8790f96a",
            "5f56360c36314fab8015fc2fde6cd246"
          ]
        },
        "outputId": "e10a8fda-5b53-4ff1-ec17-b893a8f9cc14"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipykernel_328771/3734385828.py:13: DeprecationWarning: Call to deprecated `glove2word2vec` (KeyedVectors.load_word2vec_format(.., binary=False, no_header=True) loads GLoVE text vectors.).\n",
            "  glove2word2vec(gloveFilePath, tmp_file)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Converted glove to word2vec format\n",
            "Loaded pretrained glove model\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/500 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "f8acffe7c2174ad8a7c83d92085c1f8e"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipykernel_328771/1014936044.py:78: RuntimeWarning: divide by zero encountered in power\n",
            "  r_inv = np.power(rowsum, -1).flatten()\n"
          ]
        }
      ],
      "source": [
        "if NODE == 0:\n",
        "    features = np.arange(node_size)\n",
        "    features = torch.FloatTensor(features).to(device)\n",
        "\n",
        "elif NODE == 1:\n",
        "\n",
        "    import flair\n",
        "    from flair.embeddings import TransformerDocumentEmbeddings, TransformerWordEmbeddings\n",
        "    from flair.data import Sentence\n",
        "\n",
        "    doc_embedding = TransformerDocumentEmbeddings(\"bert-base-uncased\", fine_tune=False)\n",
        "    word_embedding = TransformerWordEmbeddings(\"bert-base-uncased\", layers='-1',subtoken_pooling=\"mean\")\n",
        "\n",
        "    sent_embs = []\n",
        "    word_embs = {}\n",
        "\n",
        "    for ind in tqdm(range(train_size+test_size)):\n",
        "        sent = tokenize_sentences[ind]\n",
        "        if len(sent) > 0:\n",
        "          sentence = Sentence(\" \".join(sent[:512]),use_tokenizer=False)\n",
        "          doc_embedding.embed(sentence)\n",
        "          sent_embs.append(sentence.get_embedding().tolist())\n",
        "          words = Sentence(\" \".join(sent[:512]),use_tokenizer=False)\n",
        "          word_embedding.embed(words)\n",
        "          for token in words:\n",
        "              word = token.text\n",
        "              embedding = token.embedding.tolist()\n",
        "              if word not in word_embs:\n",
        "                  word_embs[word] = embedding\n",
        "              else:\n",
        "                  word_embs[word] = np.minimum(word_embs[word], embedding)\n",
        "        else:\n",
        "          sent_embs.append([0] * 768)\n",
        "\n",
        "    word_embs_list = []\n",
        "    for word in word_list:\n",
        "      word_embs_list.append(word_embs[word])\n",
        "\n",
        "    features = sent_embs[:train_size] + word_embs_list + sent_embs[train_size:]\n",
        "\n",
        "\n",
        "elif NODE == 2:\n",
        "  gloveModel, gloveDim = getGloveModel()\n",
        "  gloveVocab = gloveModel.index_to_key\n",
        "\n",
        "  #SENTENCE EMBEDDINGS\n",
        "  sentence_emb = []\n",
        "  for idx in tqdm(range(train_size + test_size)):\n",
        "    sentence = tokenize_sentences[idx]\n",
        "    if len(sentence) > 0:\n",
        "      sentence_wEmb = []\n",
        "      for idx_token, token in enumerate(sentence):\n",
        "        if token in gloveVocab:\n",
        "          sentence_wEmb.append(gloveModel[token])\n",
        "        else:\n",
        "          sentence_wEmb.append(np.zeros(gloveDim)) #UNKNOWN: set to 0s\n",
        "\n",
        "      sentence_emb.append(np.mean(sentence_wEmb, axis = 0)) #SENTENCE EMBEDDING: average\n",
        "    else:\n",
        "      #Append 0s if sentence is empty after tokenization\n",
        "      sentence_emb.append(np.zeros(gloveDim))\n",
        "\n",
        "\n",
        "  #WORD EMBEDDINGS\n",
        "  word_embs_list = []\n",
        "  for word in word_list:\n",
        "    if word in gloveVocab:\n",
        "      word_embs_list.append(gloveModel[word])\n",
        "    else:\n",
        "      word_embs_list.append(np.zeros(gloveDim))\n",
        "\n",
        "  features = sentence_emb[:train_size] + word_embs_list + sentence_emb[train_size:]\n",
        "\n",
        "import scipy.sparse as sp\n",
        "def preprocess_features(features):\n",
        "  \"\"\"Row-normalize feature matrix and convert to tuple representation\"\"\"\n",
        "  rowsum = np.array(features.sum(1))\n",
        "  r_inv = np.power(rowsum, -1).flatten()\n",
        "  r_inv[np.isinf(r_inv)] = 0.\n",
        "  r_mat_inv = sp.diags(r_inv)\n",
        "  features = r_mat_inv.dot(features)\n",
        "  return features\n",
        "\n",
        "features = preprocess_features(sp.csr_matrix(features)).todense()\n",
        "features = torch.FloatTensor(features).to(device)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pdx6RrUvjbF0"
      },
      "source": [
        "# Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "39Kj8NQujiDH"
      },
      "source": [
        "## GCN Layer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 160,
      "metadata": {
        "id": "jNVkA-h7b3sP"
      },
      "outputs": [],
      "source": [
        "class GraphConvolution(Module):\n",
        "    \"\"\"\n",
        "    Simple GCN layer, similar to https://arxiv.org/abs/1609.02907\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, in_features, out_features,  drop_out = 0, activation=None, bias=True):\n",
        "        super(GraphConvolution, self).__init__()\n",
        "        self.in_features = in_features\n",
        "        self.out_features = out_features\n",
        "        self.weight = Parameter(torch.FloatTensor(in_features, out_features))\n",
        "        if bias:\n",
        "            self.bias = Parameter(torch.zeros(1, out_features))\n",
        "        else:\n",
        "            self.register_parameter('bias', None)\n",
        "        self.reset_parameters(in_features, out_features)\n",
        "        self.dropout = torch.nn.Dropout(drop_out)\n",
        "        self.activation =  activation\n",
        "\n",
        "    def reset_parameters(self,in_features, out_features):\n",
        "        stdv = np.sqrt(6.0/(in_features+out_features))\n",
        "        # stdv = 1. / math.sqrt(self.weight.size(1))\n",
        "        self.weight.data.uniform_(-stdv, stdv)\n",
        "        # if self.bias is not None:\n",
        "        #     torch.nn.init.zeros_(self.bias)\n",
        "            # self.bias.data.uniform_(-stdv, stdv)\n",
        "\n",
        "\n",
        "    def forward(self, input, adj, feature_less = False):\n",
        "        if feature_less:\n",
        "            support = self.weight\n",
        "            support = self.dropout(support)\n",
        "        else:\n",
        "            input = self.dropout(input)\n",
        "            support = torch.mm(input, self.weight)\n",
        "        output = torch.spmm(adj, support)\n",
        "        if self.bias is not None:\n",
        "            output = output + self.bias\n",
        "        if self.activation is not None:\n",
        "            output = self.activation(output)\n",
        "        return output\n",
        "\n",
        "    def __repr__(self):\n",
        "        return self.__class__.__name__ + ' (' \\\n",
        "               + str(self.in_features) + ' -> ' \\\n",
        "               + str(self.out_features) + ')'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k57M4sz4s4Md"
      },
      "source": [
        "## GCN Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 161,
      "metadata": {
        "id": "PqQ6fOxsXGEl"
      },
      "outputs": [],
      "source": [
        "class GCN(nn.Module):\n",
        "  def __init__(self, nfeat, nhid, nclass, emb_dim, dropout, n_layers = 2):\n",
        "    super(GCN, self).__init__()\n",
        "    self.n_layers = n_layers\n",
        "    self.gc_list = []\n",
        "    if n_layers >= 2:\n",
        "      self.gc1 = GraphConvolution(nfeat, nhid, dropout, activation = nn.ReLU())\n",
        "      self.gc_list = nn.ModuleList([GraphConvolution(nhid, nhid, dropout, activation = nn.Relu()) for _ in range(self.n_layers-2)])\n",
        "\n",
        "      #Rina edits:\n",
        "      #Final GCN output shaped to required embedding dimension\n",
        "      #Added Linear layer for predictions\n",
        "      self.gcf = GraphConvolution(nhid, emb_dim, dropout)\n",
        "      self.l1 = nn.Linear(emb_dim, nclass)\n",
        "    else:\n",
        "      self.gc1 = GraphConvolution(nfeat, nhid, dropout)\n",
        "\n",
        "  def forward(self, x, adj):\n",
        "    if self.n_layers >= 2:\n",
        "      x = self.gc1(x, adj, feature_less = True)\n",
        "      for i in range(self.n_layers - 2):\n",
        "        x = self.gc_list[i](x, adj)\n",
        "      x = self.gcf(x, adj)\n",
        "      x = self.l1(x)\n",
        "    else:\n",
        "      x = self.gc1(x, adj, feature_less = True)\n",
        "    return x"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qbmfFDiOdwSd"
      },
      "source": [
        "##BERT Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 162,
      "metadata": {
        "id": "QPpTCZxbys_k"
      },
      "outputs": [],
      "source": [
        "class BERT(nn.Module):\n",
        "  def __init__(self, config, nclass, weight_matrix, dropout):\n",
        "    super(BERT, self).__init__()\n",
        "\n",
        "    self.l1 = transformers.BertModel(config)\n",
        "\n",
        "    #Manually set word embeddings\n",
        "    #https://discuss.pytorch.org/t/set-weights-for-embedding-layer/56097\n",
        "    vocab_size, embedding_dim = weight_matrix.shape\n",
        "    self.l1.embeddings.word_embeddings = nn.Embedding(vocab_size, embedding_dim)\n",
        "    self.l1.embeddings.word_embeddings.weights = nn.Parameter(weight_matrix)\n",
        "\n",
        "    self.l2 = torch.nn.Dropout(dropout)\n",
        "    self.l3 = torch.nn.Linear(768, nclass)\n",
        "\n",
        "  def forward(self, ids, attention_mask, token_type_ids,):\n",
        "    _, x = self.l1(input_ids = ids,\n",
        "                   attention_mask = attention_mask,\n",
        "                   token_type_ids = token_type_ids,\n",
        "                   return_dict = False)\n",
        "    x = self.l2(x)\n",
        "    x = self.l3(x)\n",
        "    return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 163,
      "metadata": {
        "id": "ntgBsK84zmEk"
      },
      "outputs": [],
      "source": [
        "class BERTWPCustomDataset(torch.utils.data.Dataset):\n",
        "\n",
        "    def __init__(self, seq_ids, targets, attention_masks = None, token_type_ids = None):\n",
        "      self.seq_ids = seq_ids\n",
        "      self.attention_masks = attention_masks\n",
        "      self.token_type_ids = token_type_ids\n",
        "      self.targets = targets\n",
        "\n",
        "    def __len__(self):\n",
        "      return len(self.seq_ids)\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "\n",
        "      item = {\n",
        "            'input_ids': self.seq_ids[index],\n",
        "            'targets': self.targets[index]\n",
        "        }\n",
        "      if self.attention_masks is not None:\n",
        "        item[\"attention_masks\"] = self.attention_masks[index]\n",
        "\n",
        "      if self.token_type_ids is not None:\n",
        "        item[\"token_type_ids\"] = self.token_type_ids[index]\n",
        "\n",
        "      return item\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zEE4JxeUthCb"
      },
      "source": [
        "# Training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 164,
      "metadata": {
        "id": "hdNsgxMG-Wwu"
      },
      "outputs": [],
      "source": [
        "#Register hook to get output of 2nd gcn layer\n",
        "#https://discuss.pytorch.org/t/how-can-i-extract-intermediate-layer-output-from-loaded-cnn-model/77301/2\n",
        "activation = {}\n",
        "def get_activation(name, bertOutput = False):\n",
        "    def hook(model, input, output):\n",
        "        if bertOutput:\n",
        "          activation[name] = output[1].detach()\n",
        "        else:\n",
        "          activation[name] = output.detach()\n",
        "    return hook"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 165,
      "metadata": {
        "id": "0Cf4iqDRFVrL"
      },
      "outputs": [],
      "source": [
        "def generate_train_val_gcn(train_pro = 0.9):\n",
        "  real_train_size = int(train_pro * train_size)\n",
        "  val_size = train_size - real_train_size\n",
        "\n",
        "  idx_train = np.random.choice(range(train_size), real_train_size, replace = False)\n",
        "  idx_train.sort()\n",
        "  idx_val = []\n",
        "  pointer = 0\n",
        "  for v in range(train_size):\n",
        "      if pointer<len(idx_train) and idx_train[pointer] == v:\n",
        "          pointer +=1\n",
        "      else:\n",
        "          idx_val.append(v)\n",
        "  idx_val = np.array(idx_val)\n",
        "\n",
        "  return idx_train, idx_val#, idx_test\n",
        "\n",
        "idx_train, idx_val = generate_train_val_gcn()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 166,
      "metadata": {
        "id": "YnteOAdsbFld"
      },
      "outputs": [],
      "source": [
        "def train_gcn(gcnModel, goldLabels, gcnOptimizer, gcnEpochs, gcnCriterion, show_result = True):\n",
        "  start = time.time()\n",
        "  val_loss = []\n",
        "  for epoch in range(gcnEpochs):\n",
        "    t = time.time()\n",
        "    gcnModel.train()\n",
        "    gcnOptimizer.zero_grad()\n",
        "    output = gcnModel(features, adj)\n",
        "    loss_train = gcnCriterion(output[idx_train], goldLabels[idx_train])\n",
        "    acc_train = cal_accuracy(output[idx_train], goldLabels[idx_train], multiLabel = True)\n",
        "    hloss_train = cal_hammingloss(output[idx_train], goldLabels[idx_train])\n",
        "    loss_train.backward()\n",
        "    gcnOptimizer.step()\n",
        "\n",
        "    gcnModel.eval()\n",
        "    output = gcnModel(features, adj)\n",
        "\n",
        "    loss_val = gcnCriterion(output[idx_val], goldLabels[idx_val])\n",
        "    val_loss.append(loss_val.item())\n",
        "    acc_val = cal_accuracy(output[idx_val], goldLabels[idx_val], multiLabel = True)\n",
        "    hloss_val = cal_hammingloss(output[idx_val], goldLabels[idx_val])\n",
        "\n",
        "    if show_result:\n",
        "      print(  'Epoch: {:04d}'.format(epoch+1),\n",
        "              'loss_train: {:.4f}'.format(loss_train.item()),\n",
        "              'acc_train: {:.4f}'.format(acc_train),\n",
        "              'hloss_train: {:.4f}'.format(hloss_train),\n",
        "              'loss_val: {:.4f}'.format(loss_val.item()),\n",
        "              'acc_val: {:.4f}'.format(acc_val),\n",
        "              'hloss_val: {:.4f}'.format(hloss_val),\n",
        "              'time: {:.4f}s'.format(time.time() - t))\n",
        "\n",
        "    if epoch > EARLY_STOPPING and np.min(val_loss[-EARLY_STOPPING:]) > np.min(val_loss[:-EARLY_STOPPING]) :\n",
        "      if show_result:\n",
        "        print(\"Early Stopping...\")\n",
        "      break\n",
        "\n",
        "  print(\"Total train time: {:.4f}s\".format(time.time() - start) )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 167,
      "metadata": {
        "id": "Yjo9Wj_O_drE"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "def train_bert(model, train_loader, val_loader, optimizer, criterion, epochs, early_stop = None, show_result = True,\n",
        "               save_model_path = \"\", upload_freq = 0):\n",
        "  start = time.time()\n",
        "  val_loss = []\n",
        "  for epoch in range(epochs):\n",
        "    t = time.time()\n",
        "\n",
        "    #Training\n",
        "    model.train()\n",
        "    batch_loss_train = []\n",
        "    batch_acc_train = []\n",
        "    batch_hloss_train = []\n",
        "    for data in train_loader:\n",
        "      ids = data[\"input_ids\"].to(device)\n",
        "      goldLabels_train = data[\"targets\"]\n",
        "\n",
        "      att_mask = data[\"attention_masks\"].to(device) if \"attention_masks\" in data else None\n",
        "      token_type_ids = data[\"token_type_ids\"].to(device) if \"token_type_ids\" in data else None\n",
        "\n",
        "      optimizer.zero_grad()\n",
        "      output = model(ids, att_mask, token_type_ids)\n",
        "\n",
        "      loss_train = criterion(output, goldLabels_train)\n",
        "      acc_train = cal_accuracy(output, goldLabels_train, multiLabel = True)\n",
        "      hloss_train = cal_hammingloss(output, goldLabels_train)\n",
        "\n",
        "      batch_loss_train.append(loss_train.item())\n",
        "      batch_acc_train.append(acc_train)\n",
        "      batch_hloss_train.append(hloss_train)\n",
        "\n",
        "      loss_train.backward()\n",
        "      optimizer.step()\n",
        "\n",
        "    #Validation\n",
        "    model.eval()\n",
        "    batch_loss_val = []\n",
        "    batch_acc_val = []\n",
        "    batch_hloss_val = []\n",
        "    with torch.no_grad():\n",
        "      for _, data in enumerate(val_loader, 0):\n",
        "        ids = data[\"input_ids\"].to(device)\n",
        "        goldLabels_val = data[\"targets\"]\n",
        "\n",
        "        att_mask = data[\"attention_masks\"].to(device) if \"attention_masks\" in data else None\n",
        "        token_type_ids = data[\"token_type_ids\"].to(device) if \"token_type_ids\" in data else None\n",
        "\n",
        "        output = model(ids, att_mask, token_type_ids)\n",
        "\n",
        "        loss_val = criterion(output, goldLabels_val)\n",
        "        acc_val = cal_accuracy(output, goldLabels_val, multiLabel = True)\n",
        "        hloss_val = cal_hammingloss(output, goldLabels_val)\n",
        "\n",
        "        batch_loss_val.append(loss_val.item())\n",
        "        batch_acc_val.append(acc_val)\n",
        "        batch_hloss_val.append(hloss_val)\n",
        "\n",
        "    val_loss.append(np.mean(batch_loss_val))\n",
        "    if early_stop != None and epoch > early_stop and np.min(val_loss[-early_stop:]) > np.min(val_loss[:-early_stop]) :\n",
        "      if show_result:\n",
        "          print(\"Early Stopping...\")\n",
        "      break\n",
        "\n",
        "    if show_result:\n",
        "      print(  'Epoch: {:04d}'.format(epoch+1),\n",
        "              'loss_train: {:.4f}'.format(np.mean(batch_loss_train)),\n",
        "              'acc_train: {:.4f}'.format(np.mean(batch_acc_train)),\n",
        "              'hloss_train: {:.4f}'.format(np.mean(batch_hloss_train)),\n",
        "              'loss_val: {:.4f}'.format(np.mean(batch_loss_val)),\n",
        "              'acc_val: {:.4f}'.format(np.mean(batch_acc_val)),\n",
        "              'hloss_val: {:.4f}'.format(np.mean(batch_hloss_val)),\n",
        "              'time: {:.4f}s'.format(time.time() - t))\n",
        "\n",
        "    if save_model_path != \"\":\n",
        "      os.makedirs(os.path.dirname(save_model_path), exist_ok = True)\n",
        "      state = {\"last_epoch\": epoch,\n",
        "               \"val_losses\": val_loss,\n",
        "               \"model_state\": model.state_dict(),\n",
        "               \"optimizer_state\": optimizer.state_dict()}\n",
        "      torch.save(state, save_model_path)\n",
        "\n",
        "  print(\"Total train time: {:.4f}s\".format(time.time() - start) )\n",
        "\n",
        "  #Save final model\n",
        "  if save_model_path != \"\":\n",
        "    os.makedirs(os.path.dirname(save_model_path), exist_ok = True)\n",
        "    state = {\"last_epoch\": epoch,\n",
        "              \"val_losses\": val_loss,\n",
        "              \"model_state\": model.state_dict(),\n",
        "              \"optimizer_state\": optimizer.state_dict()}\n",
        "    torch.save(state, save_model_path)\n",
        "\n",
        "def test_bert(model, test_loader):\n",
        "  model.eval()\n",
        "  with torch.no_grad():\n",
        "    batch_targets = []\n",
        "    batch_outputs = []\n",
        "    batch_pooledOutputs = []\n",
        "    for _, data in enumerate(test_loader, 0):\n",
        "      ids = data[\"input_ids\"].to(device)\n",
        "      targets = data[\"targets\"]\n",
        "\n",
        "      att_mask = data[\"attention_masks\"].to(device) if \"attention_masks\" in data else None\n",
        "      token_type_ids = data[\"token_type_ids\"].to(device) if \"token_type_ids\" in data else None\n",
        "\n",
        "\n",
        "      output = model(ids, att_mask, token_type_ids)\n",
        "\n",
        "      batch_targets.extend(targets.cpu().detach().numpy().tolist())\n",
        "      batch_outputs.extend(output.cpu().detach().numpy().tolist())\n",
        "      batch_pooledOutputs.extend(activation[\"l1.pooled\"].cpu().detach().numpy())\n",
        "\n",
        "  return batch_outputs, batch_targets, np.stack(batch_pooledOutputs)\n",
        "\n",
        "\n",
        "def build_bert_inputs(sentence_tokenIds, max_len, embeddings):\n",
        "  pad_id = 0\n",
        "  cls_id = 1\n",
        "  sep_id = 2\n",
        "  max_seq_length = min(max([len(tokens) for tokens in sentence_tokenIds]) + 2, max_len)                   #Add 2 for [CLS] & [SEP]\n",
        "  input_ids = [list(np.array(x) + 3) for x in sentence_tokenIds]                                          #Adjust ids to add special tokens\n",
        "  input_ids = [[cls_id] + x + [sep_id] for x in input_ids]                                                #Insert CLS and SEP at beginning and end\n",
        "  # input_ids = pad_sequences(input_ids, max_seq_length, value = pad_id, padding = \"post\", truncating = \"post\")\n",
        "  input_ids = [input + [pad_id] * max(0, max_seq_length - len(input)) if len(input) < max_seq_length else input[:max_seq_length] for input in input_ids]\n",
        "  emb_matrix = torch.cat((torch.zeros((3, embeddings.shape[1])),\n",
        "                          embeddings),\n",
        "                        dim = 0)\n",
        "\n",
        "  return np.array(input_ids), emb_matrix, max_seq_length"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 168,
      "metadata": {
        "id": "qmhOG1yG--Ji"
      },
      "outputs": [],
      "source": [
        "def cal_accuracy(predictions, labels, multiLabel = False):\n",
        "  if multiLabel:\n",
        "    predictions = predictions.cpu().detach().numpy() >= 0.5\n",
        "  else:\n",
        "    predictions = torch.argmax(predictions,-1).cpu().tolist()\n",
        "\n",
        "  labels = labels.cpu().tolist()\n",
        "\n",
        "  return accuracy_score(predictions, labels)\n",
        "\n",
        "def cal_hammingloss(predictions, labels):\n",
        "  predictions = predictions.cpu().detach().numpy() >= 0.5\n",
        "  labels = labels.cpu().tolist()\n",
        "\n",
        "  return hamming_loss(predictions, labels)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 169,
      "metadata": {
        "id": "OBgnrjWtuMKY"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import f1_score, accuracy_score, precision_score, recall_score\n",
        "def evaluate_output(outputs, targets, targetLabels, title = \"\", show_results = True, multiLabel = False, return_results = False):\n",
        "\n",
        "    if multiLabel:\n",
        "      outputs = np.array(outputs) >= 0.5\n",
        "    else:\n",
        "      outputs = np.argmax(outputs, axis = 1)\n",
        "\n",
        "    accuracy = accuracy_score(targets, outputs)\n",
        "    f1_score_micro = f1_score(targets, outputs, average='micro')\n",
        "    f1_score_macro = f1_score(targets, outputs, average='macro')\n",
        "    f1_score_weighted = f1_score(targets, outputs, average=\"weighted\")\n",
        "\n",
        "    if show_results:\n",
        "      print()\n",
        "      print(\"=\" * 50)\n",
        "      print(title)\n",
        "      print(\"=\" * 50)\n",
        "      print(\"Accuracy Score: %.4f\" % (accuracy))\n",
        "      print(\"F1 Score (Micro): %.4f\" % (f1_score_micro))\n",
        "      print(\"F1 Score (Macro): %.4f\" % (f1_score_macro))\n",
        "      print(\"F1 Score (Weighted): %.4f\" % (f1_score_weighted))\n",
        "\n",
        "      if multiLabel:\n",
        "        ham_loss = hamming_loss(targets, outputs)\n",
        "        print(\"Hamming Loss: %.4f\" % (ham_loss))\n",
        "\n",
        "\n",
        "      print(classification_report(targets, outputs, target_names = targetLabels, digits = 4))\n",
        "\n",
        "    if return_results:\n",
        "      results = {\"Accuracy\": accuracy,\n",
        "              \"F1_Micro\": f1_score_micro,\n",
        "              \"F1_Macro\": f1_score_macro,\n",
        "              \"F1_Weighted\": f1_score_weighted,\n",
        "              \"Class Precision\": precision_score(targets, outputs, average = None),\n",
        "              \"Class Recall\": recall_score(targets, outputs, average = None),\n",
        "              \"Class F1\": f1_score(targets, outputs, average = None)\n",
        "      }\n",
        "\n",
        "      return results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 170,
      "metadata": {
        "id": "_pAYz8R7O4Jj"
      },
      "outputs": [],
      "source": [
        "def saveWeights(fileName, text, doc_weights, doc_emoLabels, doc_labels, emo_classNames):\n",
        "\n",
        "  import pickle as pkl\n",
        "  import os\n",
        "\n",
        "  os.makedirs(os.path.dirname(fileName), exist_ok = True)\n",
        "  with open(fileName, \"wb\") as file:\n",
        "    pkl.dump({\"text\": text,\n",
        "              \"doc_embeddings\": doc_weights,\n",
        "              \"doc_emoLabels\": doc_emoLabels,\n",
        "              \"emo_classNames\": emo_classNames,\n",
        "              \"doc_labels\": doc_labels\n",
        "              }, file)\n",
        "\n",
        "def saveWordEmbeddings(fileName, vocab_map, weights):\n",
        "  import pickle as pkl\n",
        "  import os\n",
        "\n",
        "  if len(vocab_map) != len(weights):\n",
        "    raise Exception(\"Vocab and Weights are not similar in shape.\")\n",
        "\n",
        "  os.makedirs(os.path.dirname(fileName), exist_ok = True)\n",
        "  with open(fileName, \"wb\") as file:\n",
        "    pkl.dump({\"vocab_map\": vocab_map,\n",
        "             \"weights\": weights}, file)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 171,
      "metadata": {
        "id": "2o6Nt2bwtrU-"
      },
      "outputs": [],
      "source": [
        "def train_GCNBert(save_model_path = \"\", upload_freq = 0):\n",
        "  ###\n",
        "  #GCN\n",
        "  ###\n",
        "\n",
        "  #Build model\n",
        "  gcnModel = GCN(nfeat = node_size, nhid = HIDDEN_DIM, nclass = num_emoClass, emb_dim = 768, dropout = DROP_OUT, n_layers = NUM_LAYERS).to(device)\n",
        "  optimizer = optim.Adam(gcnModel.parameters(), lr = LR, weight_decay = WEIGHT_DECAY)\n",
        "  gcnModel.gcf.register_forward_hook(get_activation(\"gcf\"))\n",
        "\n",
        "  #Training\n",
        "  train_gcn(gcnModel, emoLabels, optimizer, GCN_EPOCHS, nn.BCEWithLogitsLoss())\n",
        "\n",
        "  #Evaluate training\n",
        "  gcnModel.eval()\n",
        "  output = gcnModel(features, adj)\n",
        "  evaluate_output(output[:train_size].cpu().detach().numpy(), emoLabels.cpu(), lexClassNames, title = title1, multiLabel = True)\n",
        "\n",
        "  #Extract embeddings\n",
        "  # trained_doc_embeddings = activation[\"gcf\"][:train_size].cpu()\n",
        "  trained_word_embeddings = activation[\"gcf\"][train_size:].cpu()\n",
        "\n",
        "\n",
        "  ###\n",
        "  #BERT\n",
        "  ###\n",
        "\n",
        "  bertConfig = transformers.BertConfig()\n",
        "  bert_max_length = bertConfig.max_position_embeddings\n",
        "\n",
        "  if TOKEN_TYPE == \"wp\":\n",
        "    #Align new weights with bert embeddings\n",
        "    tempBert = transformers.BertModel(bertConfig)\n",
        "    tempBert.resize_token_embeddings(len(tokenizer))\n",
        "    emb_matrix = tempBert.embeddings.word_embeddings.weight.data.detach()\n",
        "    bert_map = tokenizer.get_vocab()\n",
        "    for wp, idx in word_id_map.items():\n",
        "      emb_matrix[bert_map[wp]] = trained_word_embeddings[idx]\n",
        "\n",
        "    #Build BERT inputs\n",
        "    clean_sentences = [preprocess_str(text) for text in original_train_sentences]\n",
        "    inputs = tokenizer(clean_sentences, padding = True, truncation = True, max_length = MAX_LENGTH)\n",
        "    input_ids = np.array(inputs[\"input_ids\"])\n",
        "    token_type_ids = np.array(inputs[\"token_type_ids\"])\n",
        "    attention_mask = np.array(inputs[\"attention_mask\"])\n",
        "\n",
        "    #Build data loader\n",
        "    train_set = BERTWPCustomDataset(input_ids[idx_train], emoLabels[idx_train], attention_masks = attention_mask[idx_train], token_type_ids = token_type_ids[idx_train])\n",
        "    val_set = BERTWPCustomDataset(input_ids[idx_val], emoLabels[idx_val], attention_masks = attention_mask[idx_val], token_type_ids = token_type_ids[idx_val])\n",
        "    test_set = BERTWPCustomDataset(input_ids, emoLabels, attention_masks = attention_mask, token_type_ids = token_type_ids)\n",
        "\n",
        "  elif TOKEN_TYPE == \"ws\":\n",
        "    #Build BERT inputs\n",
        "    if MAX_LENGTH == None:\n",
        "      truncate_len = bert_max_length\n",
        "    else:\n",
        "      truncate_len = min(MAX_LENGTH, bert_max_length)\n",
        "    input_ids, emb_matrix, max_seq_length = build_bert_inputs(tokenize_sentences_tokenIds, truncate_len, trained_word_embeddings)\n",
        "    print(\"Max sequence length:\", max_seq_length)\n",
        "\n",
        "    #Build data loader\n",
        "    train_set = BERTWPCustomDataset(input_ids[idx_train], emoLabels[idx_train])\n",
        "    val_set = BERTWPCustomDataset(input_ids[idx_val], emoLabels[idx_val])\n",
        "    test_set = BERTWPCustomDataset(input_ids, emoLabels)\n",
        "\n",
        "  else:\n",
        "    raise Exception(\"Invalid Token Type.\")\n",
        "\n",
        "  train_loader = torch.utils.data.DataLoader(train_set, **train_params)\n",
        "  val_loader = torch.utils.data.DataLoader(val_set, **train_params)\n",
        "  test_loader = torch.utils.data.DataLoader(test_set, **test_params)\n",
        "\n",
        "  #Build Model\n",
        "  bertModel = BERT(bertConfig, num_emoClass, emb_matrix, BERT_DROPOUT).to(device)\n",
        "  bertModel.l1.register_forward_hook(get_activation(\"l1.pooled\", bertOutput = True))\n",
        "  optimizer = optim.Adam(bertModel.parameters(), lr = BERT_LR)\n",
        "  criterion = nn.BCEWithLogitsLoss()\n",
        "\n",
        "\n",
        "  #Train\n",
        "  train_bert(bertModel, train_loader, val_loader, optimizer, criterion, BERT_EPOCHS, early_stop = BERT_EARLYSTOP,\n",
        "             save_model_path = save_model_path, upload_freq = upload_freq)\n",
        "\n",
        "  #Evaluate and extract document embeddings\n",
        "  outputs, targets, doc_embeddings = test_bert(bertModel, test_loader)\n",
        "  new_embeddings = bertModel.l1.embeddings.word_embeddings.weight.detach().cpu()\n",
        "  evaluate_output(outputs, targets, lexClassNames, title = title2, multiLabel = True)\n",
        "\n",
        "  return doc_embeddings, new_embeddings"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6d750OCFrgn8"
      },
      "source": [
        "#Generate MM-EMOG Embeddings"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 176,
      "metadata": {
        "id": "WipHGHCesMv8"
      },
      "outputs": [],
      "source": [
        "train_params = {'batch_size': BATCH_SIZE,\n",
        "          'shuffle': True,\n",
        "          'num_workers': 0\n",
        "          }\n",
        "test_params = {'batch_size': BATCH_SIZE,\n",
        "          'shuffle': False,\n",
        "          'num_workers': 0\n",
        "          }\n",
        "\n",
        "if TOKEN_TYPE == \"wp\":\n",
        "  vocab = tokenizer.get_vocab()\n",
        "elif TOKEN_TYPE == \"ws\":\n",
        "  vocab = {k: v + 3 for k, v in word_id_map.items()} #Adjust by 3 to add BERT tokens\n",
        "  vocab[\"[PAD]\"] = 0\n",
        "  vocab[\"[CLS]\"] = 1\n",
        "  vocab[\"[SEP]\"] = 2\n",
        "else:\n",
        "  raise Exception(\"Invalid token type.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ldFHJrHWrjD1"
      },
      "source": [
        "##EmoLex"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 178,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MzVPUC5Yk5UV",
        "outputId": "696ba8cd-550b-4e3a-f420-492f04f95426"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 0001 loss_train: 0.6900 acc_train: 0.2667 hloss_train: 0.3403 loss_val: 0.6190 acc_val: 0.2600 hloss_val: 0.3086 time: 0.0102s\n",
            "Epoch: 0002 loss_train: 0.6266 acc_train: 0.2667 hloss_train: 0.3403 loss_val: 0.8035 acc_val: 0.1000 hloss_val: 0.2686 time: 0.0096s\n",
            "Epoch: 0003 loss_train: 0.8483 acc_train: 0.1156 hloss_train: 0.2952 loss_val: 0.5622 acc_val: 0.1000 hloss_val: 0.2686 time: 0.0094s\n",
            "Epoch: 0004 loss_train: 0.5889 acc_train: 0.1156 hloss_train: 0.2956 loss_val: 0.6123 acc_val: 0.2600 hloss_val: 0.3000 time: 0.0096s\n",
            "Epoch: 0005 loss_train: 0.6213 acc_train: 0.2556 hloss_train: 0.3387 loss_val: 0.6294 acc_val: 0.2600 hloss_val: 0.3086 time: 0.0095s\n",
            "Epoch: 0006 loss_train: 0.6332 acc_train: 0.2600 hloss_train: 0.3413 loss_val: 0.6081 acc_val: 0.2600 hloss_val: 0.3086 time: 0.0095s\n",
            "Epoch: 0007 loss_train: 0.6109 acc_train: 0.2667 hloss_train: 0.3403 loss_val: 0.5757 acc_val: 0.2600 hloss_val: 0.3086 time: 0.0094s\n",
            "Epoch: 0008 loss_train: 0.5806 acc_train: 0.2667 hloss_train: 0.3403 loss_val: 0.5441 acc_val: 0.1200 hloss_val: 0.2800 time: 0.0095s\n",
            "Epoch: 0009 loss_train: 0.5556 acc_train: 0.2444 hloss_train: 0.2930 loss_val: 0.5313 acc_val: 0.1600 hloss_val: 0.2600 time: 0.0095s\n",
            "Epoch: 0010 loss_train: 0.5578 acc_train: 0.2267 hloss_train: 0.2797 loss_val: 0.5234 acc_val: 0.1600 hloss_val: 0.2629 time: 0.0095s\n",
            "Epoch: 0011 loss_train: 0.5530 acc_train: 0.2378 hloss_train: 0.2829 loss_val: 0.5170 acc_val: 0.1600 hloss_val: 0.2629 time: 0.0095s\n",
            "Epoch: 0012 loss_train: 0.5389 acc_train: 0.2222 hloss_train: 0.2816 loss_val: 0.5206 acc_val: 0.1600 hloss_val: 0.2600 time: 0.0095s\n",
            "Epoch: 0013 loss_train: 0.5305 acc_train: 0.2311 hloss_train: 0.2803 loss_val: 0.5288 acc_val: 0.1600 hloss_val: 0.2600 time: 0.0095s\n",
            "Epoch: 0014 loss_train: 0.5296 acc_train: 0.2244 hloss_train: 0.2806 loss_val: 0.5338 acc_val: 0.1600 hloss_val: 0.2600 time: 0.0095s\n",
            "Epoch: 0015 loss_train: 0.5306 acc_train: 0.2267 hloss_train: 0.2806 loss_val: 0.5303 acc_val: 0.1600 hloss_val: 0.2600 time: 0.0095s\n",
            "Epoch: 0016 loss_train: 0.5263 acc_train: 0.2289 hloss_train: 0.2806 loss_val: 0.5196 acc_val: 0.1600 hloss_val: 0.2600 time: 0.0095s\n",
            "Epoch: 0017 loss_train: 0.5196 acc_train: 0.2356 hloss_train: 0.2797 loss_val: 0.5111 acc_val: 0.1800 hloss_val: 0.2600 time: 0.0096s\n",
            "Epoch: 0018 loss_train: 0.5210 acc_train: 0.2511 hloss_train: 0.2797 loss_val: 0.5087 acc_val: 0.1600 hloss_val: 0.2629 time: 0.0097s\n",
            "Epoch: 0019 loss_train: 0.5144 acc_train: 0.2378 hloss_train: 0.2787 loss_val: 0.5086 acc_val: 0.1600 hloss_val: 0.2600 time: 0.0095s\n",
            "Epoch: 0020 loss_train: 0.5071 acc_train: 0.2378 hloss_train: 0.2794 loss_val: 0.5075 acc_val: 0.1800 hloss_val: 0.2571 time: 0.0095s\n",
            "Epoch: 0021 loss_train: 0.4946 acc_train: 0.2422 hloss_train: 0.2765 loss_val: 0.5045 acc_val: 0.2600 hloss_val: 0.2286 time: 0.0095s\n",
            "Epoch: 0022 loss_train: 0.4844 acc_train: 0.3067 hloss_train: 0.2527 loss_val: 0.4921 acc_val: 0.2400 hloss_val: 0.2429 time: 0.0095s\n",
            "Epoch: 0023 loss_train: 0.4755 acc_train: 0.3022 hloss_train: 0.2543 loss_val: 0.4862 acc_val: 0.2000 hloss_val: 0.2457 time: 0.0102s\n",
            "Epoch: 0024 loss_train: 0.4648 acc_train: 0.2622 hloss_train: 0.2619 loss_val: 0.4922 acc_val: 0.2400 hloss_val: 0.2286 time: 0.0097s\n",
            "Epoch: 0025 loss_train: 0.4514 acc_train: 0.3089 hloss_train: 0.2327 loss_val: 0.4962 acc_val: 0.2400 hloss_val: 0.2257 time: 0.0096s\n",
            "Epoch: 0026 loss_train: 0.4413 acc_train: 0.3556 hloss_train: 0.2124 loss_val: 0.4830 acc_val: 0.3000 hloss_val: 0.2400 time: 0.0095s\n",
            "Epoch: 0027 loss_train: 0.4275 acc_train: 0.3667 hloss_train: 0.2276 loss_val: 0.4954 acc_val: 0.2600 hloss_val: 0.2286 time: 0.0095s\n",
            "Epoch: 0028 loss_train: 0.4181 acc_train: 0.3667 hloss_train: 0.1946 loss_val: 0.4980 acc_val: 0.2400 hloss_val: 0.2286 time: 0.0096s\n",
            "Epoch: 0029 loss_train: 0.4073 acc_train: 0.3711 hloss_train: 0.1946 loss_val: 0.5043 acc_val: 0.2800 hloss_val: 0.2200 time: 0.0096s\n",
            "Epoch: 0030 loss_train: 0.3924 acc_train: 0.3956 hloss_train: 0.1959 loss_val: 0.5705 acc_val: 0.2600 hloss_val: 0.2714 time: 0.0096s\n",
            "Epoch: 0031 loss_train: 0.4184 acc_train: 0.3689 hloss_train: 0.1975 loss_val: 0.5393 acc_val: 0.3200 hloss_val: 0.2257 time: 0.0096s\n",
            "Epoch: 0032 loss_train: 0.4741 acc_train: 0.3756 hloss_train: 0.2267 loss_val: 0.5514 acc_val: 0.2400 hloss_val: 0.2486 time: 0.0095s\n",
            "Epoch: 0033 loss_train: 0.3914 acc_train: 0.3667 hloss_train: 0.1841 loss_val: 0.6215 acc_val: 0.2800 hloss_val: 0.2800 time: 0.0095s\n",
            "Epoch: 0034 loss_train: 0.4232 acc_train: 0.3956 hloss_train: 0.1860 loss_val: 0.5288 acc_val: 0.2800 hloss_val: 0.2314 time: 0.0094s\n",
            "Epoch: 0035 loss_train: 0.3768 acc_train: 0.4222 hloss_train: 0.1851 loss_val: 0.5646 acc_val: 0.3200 hloss_val: 0.2457 time: 0.0094s\n",
            "Epoch: 0036 loss_train: 0.4439 acc_train: 0.3667 hloss_train: 0.2337 loss_val: 0.5122 acc_val: 0.2800 hloss_val: 0.2257 time: 0.0094s\n",
            "Early Stopping...\n",
            "Total train time: 0.3451s\n",
            "\n",
            "==================================================\n",
            "TextGCN x EmoLex\n",
            "==================================================\n",
            "Accuracy Score: 0.4100\n",
            "F1 Score (Micro): 0.7168\n",
            "F1 Score (Macro): 0.5104\n",
            "F1 Score (Weighted): 0.6427\n",
            "Hamming Loss: 0.1723\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "       anger     0.7421    0.6782    0.7087       174\n",
            "     disgust     0.6486    0.2609    0.3721        92\n",
            "        fear     0.7764    0.7576    0.7669       165\n",
            "     sadness     0.7826    0.8372    0.8090       215\n",
            "    surprise     0.0000    0.0000    0.0000        51\n",
            "    negative     0.8729    0.9634    0.9159       328\n",
            "       other     0.0000    0.0000    0.0000       155\n",
            "\n",
            "   micro avg     0.8040    0.6466    0.7168      1180\n",
            "   macro avg     0.5461    0.4996    0.5104      1180\n",
            "weighted avg     0.6538    0.6466    0.6427      1180\n",
            " samples avg     0.5733    0.4658    0.4930      1180\n",
            "\n",
            "Max sequence length: 84\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/home/rcmcabral/.local/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/home/rcmcabral/.local/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in samples with no predicted labels. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/home/rcmcabral/.local/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in samples with no true labels. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 0001 loss_train: 0.6128 acc_train: 0.1354 hloss_train: 0.3259 loss_val: 0.5333 acc_val: 0.2448 hloss_val: 0.2800 time: 2.2102s\n",
            "Epoch: 0002 loss_train: 0.5758 acc_train: 0.1583 hloss_train: 0.2914 loss_val: 0.5625 acc_val: 0.0781 hloss_val: 0.2897 time: 2.2164s\n",
            "Epoch: 0003 loss_train: 0.5741 acc_train: 0.1812 hloss_train: 0.3012 loss_val: 0.5403 acc_val: 0.1649 hloss_val: 0.2865 time: 2.2207s\n",
            "Epoch: 0004 loss_train: 0.5674 acc_train: 0.2375 hloss_train: 0.3039 loss_val: 0.5213 acc_val: 0.2014 hloss_val: 0.2718 time: 2.2286s\n",
            "Epoch: 0005 loss_train: 0.5860 acc_train: 0.1729 hloss_train: 0.3259 loss_val: 0.5306 acc_val: 0.2292 hloss_val: 0.2366 time: 2.2338s\n",
            "Epoch: 0006 loss_train: 0.5652 acc_train: 0.2458 hloss_train: 0.2821 loss_val: 0.5027 acc_val: 0.2448 hloss_val: 0.2753 time: 2.2374s\n",
            "Epoch: 0007 loss_train: 0.5570 acc_train: 0.2354 hloss_train: 0.2908 loss_val: 0.5124 acc_val: 0.1615 hloss_val: 0.2550 time: 2.2382s\n",
            "Epoch: 0008 loss_train: 0.5655 acc_train: 0.1917 hloss_train: 0.2946 loss_val: 0.4984 acc_val: 0.2205 hloss_val: 0.2440 time: 2.2290s\n",
            "Epoch: 0009 loss_train: 0.5585 acc_train: 0.2250 hloss_train: 0.2946 loss_val: 0.5073 acc_val: 0.2170 hloss_val: 0.2686 time: 2.2308s\n",
            "Epoch: 0010 loss_train: 0.5420 acc_train: 0.1938 hloss_train: 0.2845 loss_val: 0.4928 acc_val: 0.2049 hloss_val: 0.2612 time: 2.2365s\n",
            "Epoch: 0011 loss_train: 0.5897 acc_train: 0.1833 hloss_train: 0.3134 loss_val: 0.5127 acc_val: 0.1736 hloss_val: 0.2386 time: 2.2425s\n",
            "Epoch: 0012 loss_train: 0.5418 acc_train: 0.1979 hloss_train: 0.2827 loss_val: 0.4853 acc_val: 0.1684 hloss_val: 0.2624 time: 2.2471s\n",
            "Epoch: 0013 loss_train: 0.5421 acc_train: 0.2021 hloss_train: 0.2911 loss_val: 0.4787 acc_val: 0.1892 hloss_val: 0.2346 time: 2.2505s\n",
            "Epoch: 0014 loss_train: 0.5177 acc_train: 0.2104 hloss_train: 0.2664 loss_val: 0.4501 acc_val: 0.2083 hloss_val: 0.1964 time: 2.2533s\n",
            "Epoch: 0015 loss_train: 0.4828 acc_train: 0.3000 hloss_train: 0.2182 loss_val: 0.4212 acc_val: 0.2083 hloss_val: 0.1895 time: 2.2585s\n",
            "Epoch: 0016 loss_train: 0.4245 acc_train: 0.3458 hloss_train: 0.1937 loss_val: 0.4014 acc_val: 0.1806 hloss_val: 0.2041 time: 2.2629s\n",
            "Epoch: 0017 loss_train: 0.4461 acc_train: 0.3021 hloss_train: 0.2143 loss_val: 0.4588 acc_val: 0.2118 hloss_val: 0.1959 time: 2.2594s\n",
            "Epoch: 0018 loss_train: 0.4072 acc_train: 0.3354 hloss_train: 0.1884 loss_val: 0.3937 acc_val: 0.2795 hloss_val: 0.1977 time: 2.2610s\n",
            "Epoch: 0019 loss_train: 0.4205 acc_train: 0.3521 hloss_train: 0.1940 loss_val: 0.4152 acc_val: 0.2951 hloss_val: 0.1761 time: 2.2663s\n",
            "Epoch: 0020 loss_train: 0.3970 acc_train: 0.3292 hloss_train: 0.1786 loss_val: 0.4251 acc_val: 0.3038 hloss_val: 0.1699 time: 2.2715s\n",
            "Epoch: 0021 loss_train: 0.3621 acc_train: 0.3479 hloss_train: 0.1640 loss_val: 0.3799 acc_val: 0.2396 hloss_val: 0.1840 time: 2.2807s\n",
            "Epoch: 0022 loss_train: 0.3396 acc_train: 0.4146 hloss_train: 0.1494 loss_val: 0.3709 acc_val: 0.2830 hloss_val: 0.1768 time: 2.2831s\n",
            "Epoch: 0023 loss_train: 0.3541 acc_train: 0.3688 hloss_train: 0.1598 loss_val: 0.3794 acc_val: 0.2917 hloss_val: 0.1637 time: 2.2886s\n",
            "Epoch: 0024 loss_train: 0.3146 acc_train: 0.4396 hloss_train: 0.1417 loss_val: 0.3249 acc_val: 0.3576 hloss_val: 0.1496 time: 2.2949s\n",
            "Epoch: 0025 loss_train: 0.3048 acc_train: 0.4833 hloss_train: 0.1262 loss_val: 0.3586 acc_val: 0.3420 hloss_val: 0.1657 time: 2.2985s\n",
            "Epoch: 0026 loss_train: 0.3058 acc_train: 0.4479 hloss_train: 0.1310 loss_val: 0.3587 acc_val: 0.4045 hloss_val: 0.1515 time: 2.3007s\n",
            "Epoch: 0027 loss_train: 0.2825 acc_train: 0.4833 hloss_train: 0.1232 loss_val: 0.3419 acc_val: 0.5243 hloss_val: 0.1317 time: 2.3051s\n",
            "Epoch: 0028 loss_train: 0.2539 acc_train: 0.5604 hloss_train: 0.0997 loss_val: 0.3077 acc_val: 0.4757 hloss_val: 0.1334 time: 2.3081s\n",
            "Epoch: 0029 loss_train: 0.2586 acc_train: 0.5646 hloss_train: 0.1048 loss_val: 0.3015 acc_val: 0.4531 hloss_val: 0.1213 time: 2.3162s\n",
            "Epoch: 0030 loss_train: 0.2354 acc_train: 0.5417 hloss_train: 0.0929 loss_val: 0.3022 acc_val: 0.5590 hloss_val: 0.1096 time: 2.3151s\n",
            "Epoch: 0031 loss_train: 0.2106 acc_train: 0.6687 hloss_train: 0.0723 loss_val: 0.2512 acc_val: 0.5677 hloss_val: 0.1049 time: 2.3220s\n",
            "Epoch: 0032 loss_train: 0.2093 acc_train: 0.5854 hloss_train: 0.0813 loss_val: 0.3092 acc_val: 0.4201 hloss_val: 0.1148 time: 2.3212s\n",
            "Epoch: 0033 loss_train: 0.1946 acc_train: 0.6708 hloss_train: 0.0652 loss_val: 0.2544 acc_val: 0.4878 hloss_val: 0.1081 time: 2.3256s\n",
            "Epoch: 0034 loss_train: 0.1959 acc_train: 0.6646 hloss_train: 0.0768 loss_val: 0.3085 acc_val: 0.5035 hloss_val: 0.1064 time: 2.3284s\n",
            "Epoch: 0035 loss_train: 0.1930 acc_train: 0.6458 hloss_train: 0.0708 loss_val: 0.2220 acc_val: 0.4601 hloss_val: 0.1064 time: 2.3277s\n",
            "Epoch: 0036 loss_train: 0.1638 acc_train: 0.7312 hloss_train: 0.0509 loss_val: 0.2123 acc_val: 0.5903 hloss_val: 0.0856 time: 2.3312s\n",
            "Epoch: 0037 loss_train: 0.1549 acc_train: 0.7208 hloss_train: 0.0512 loss_val: 0.1912 acc_val: 0.6059 hloss_val: 0.0776 time: 2.3351s\n",
            "Epoch: 0038 loss_train: 0.1413 acc_train: 0.7646 hloss_train: 0.0402 loss_val: 0.1964 acc_val: 0.6615 hloss_val: 0.0771 time: 2.3337s\n",
            "Epoch: 0039 loss_train: 0.1266 acc_train: 0.7875 hloss_train: 0.0366 loss_val: 0.1859 acc_val: 0.6337 hloss_val: 0.0732 time: 2.3368s\n",
            "Epoch: 0040 loss_train: 0.1221 acc_train: 0.8000 hloss_train: 0.0330 loss_val: 0.2086 acc_val: 0.6493 hloss_val: 0.0682 time: 2.3390s\n",
            "Epoch: 0041 loss_train: 0.1258 acc_train: 0.7625 hloss_train: 0.0393 loss_val: 0.1688 acc_val: 0.6649 hloss_val: 0.0675 time: 2.3400s\n",
            "Epoch: 0042 loss_train: 0.1464 acc_train: 0.7937 hloss_train: 0.0372 loss_val: 0.1638 acc_val: 0.7170 hloss_val: 0.0561 time: 2.3400s\n",
            "Epoch: 0043 loss_train: 0.1230 acc_train: 0.8125 hloss_train: 0.0310 loss_val: 0.1862 acc_val: 0.6927 hloss_val: 0.0687 time: 2.3434s\n",
            "Epoch: 0044 loss_train: 0.1140 acc_train: 0.8229 hloss_train: 0.0277 loss_val: 0.1635 acc_val: 0.7083 hloss_val: 0.0590 time: 2.3462s\n",
            "Epoch: 0045 loss_train: 0.1035 acc_train: 0.8271 hloss_train: 0.0271 loss_val: 0.1750 acc_val: 0.6962 hloss_val: 0.0655 time: 2.3457s\n",
            "Epoch: 0046 loss_train: 0.1022 acc_train: 0.8208 hloss_train: 0.0265 loss_val: 0.1604 acc_val: 0.7205 hloss_val: 0.0546 time: 2.3437s\n",
            "Epoch: 0047 loss_train: 0.1302 acc_train: 0.8042 hloss_train: 0.0345 loss_val: 0.1964 acc_val: 0.6684 hloss_val: 0.0603 time: 2.3485s\n",
            "Epoch: 0048 loss_train: 0.1018 acc_train: 0.8354 hloss_train: 0.0268 loss_val: 0.1334 acc_val: 0.7483 hloss_val: 0.0449 time: 2.3474s\n",
            "Epoch: 0049 loss_train: 0.0880 acc_train: 0.9021 hloss_train: 0.0161 loss_val: 0.1366 acc_val: 0.7483 hloss_val: 0.0511 time: 2.3478s\n",
            "Epoch: 0050 loss_train: 0.0813 acc_train: 0.8917 hloss_train: 0.0173 loss_val: 0.1288 acc_val: 0.7483 hloss_val: 0.0466 time: 2.3519s\n",
            "Epoch: 0051 loss_train: 0.0798 acc_train: 0.8938 hloss_train: 0.0167 loss_val: 0.1249 acc_val: 0.7396 hloss_val: 0.0474 time: 2.3531s\n",
            "Epoch: 0052 loss_train: 0.0765 acc_train: 0.8896 hloss_train: 0.0164 loss_val: 0.1154 acc_val: 0.7795 hloss_val: 0.0399 time: 2.3500s\n",
            "Epoch: 0053 loss_train: 0.0784 acc_train: 0.9167 hloss_train: 0.0125 loss_val: 0.1204 acc_val: 0.7917 hloss_val: 0.0444 time: 2.3519s\n",
            "Epoch: 0054 loss_train: 0.0731 acc_train: 0.9062 hloss_train: 0.0137 loss_val: 0.1261 acc_val: 0.7830 hloss_val: 0.0451 time: 2.3538s\n",
            "Epoch: 0055 loss_train: 0.0726 acc_train: 0.8958 hloss_train: 0.0152 loss_val: 0.1203 acc_val: 0.8698 hloss_val: 0.0288 time: 2.3551s\n",
            "Epoch: 0056 loss_train: 0.0677 acc_train: 0.9250 hloss_train: 0.0110 loss_val: 0.1029 acc_val: 0.8854 hloss_val: 0.0265 time: 2.3555s\n",
            "Epoch: 0057 loss_train: 0.0656 acc_train: 0.9396 hloss_train: 0.0089 loss_val: 0.1078 acc_val: 0.7865 hloss_val: 0.0424 time: 2.3569s\n",
            "Epoch: 0058 loss_train: 0.0668 acc_train: 0.9187 hloss_train: 0.0128 loss_val: 0.0903 acc_val: 0.8507 hloss_val: 0.0298 time: 2.3574s\n",
            "Epoch: 0059 loss_train: 0.0629 acc_train: 0.9313 hloss_train: 0.0101 loss_val: 0.0859 acc_val: 0.8229 hloss_val: 0.0320 time: 2.3560s\n",
            "Epoch: 0060 loss_train: 0.0567 acc_train: 0.9521 hloss_train: 0.0068 loss_val: 0.0962 acc_val: 0.8420 hloss_val: 0.0288 time: 2.3552s\n",
            "Epoch: 0061 loss_train: 0.0578 acc_train: 0.9583 hloss_train: 0.0060 loss_val: 0.0871 acc_val: 0.8819 hloss_val: 0.0253 time: 2.3557s\n",
            "Epoch: 0062 loss_train: 0.0548 acc_train: 0.9521 hloss_train: 0.0077 loss_val: 0.0810 acc_val: 0.8542 hloss_val: 0.0293 time: 2.3563s\n",
            "Epoch: 0063 loss_train: 0.0544 acc_train: 0.9417 hloss_train: 0.0086 loss_val: 0.0750 acc_val: 0.9375 hloss_val: 0.0112 time: 2.3590s\n",
            "Epoch: 0064 loss_train: 0.0548 acc_train: 0.9604 hloss_train: 0.0060 loss_val: 0.0762 acc_val: 0.9288 hloss_val: 0.0164 time: 2.3613s\n",
            "Epoch: 0065 loss_train: 0.0505 acc_train: 0.9708 hloss_train: 0.0045 loss_val: 0.0757 acc_val: 0.8698 hloss_val: 0.0265 time: 2.3577s\n",
            "Epoch: 0066 loss_train: 0.0461 acc_train: 0.9792 hloss_train: 0.0030 loss_val: 0.0709 acc_val: 0.8542 hloss_val: 0.0270 time: 2.3588s\n",
            "Epoch: 0067 loss_train: 0.0450 acc_train: 0.9812 hloss_train: 0.0027 loss_val: 0.0610 acc_val: 0.9097 hloss_val: 0.0174 time: 2.3623s\n",
            "Epoch: 0068 loss_train: 0.0449 acc_train: 0.9792 hloss_train: 0.0030 loss_val: 0.0671 acc_val: 0.8976 hloss_val: 0.0208 time: 2.3586s\n",
            "Epoch: 0069 loss_train: 0.0452 acc_train: 0.9812 hloss_train: 0.0027 loss_val: 0.0650 acc_val: 0.9410 hloss_val: 0.0146 time: 2.3554s\n",
            "Epoch: 0070 loss_train: 0.0423 acc_train: 0.9854 hloss_train: 0.0021 loss_val: 0.0608 acc_val: 0.9132 hloss_val: 0.0164 time: 2.3648s\n",
            "Epoch: 0071 loss_train: 0.0397 acc_train: 0.9875 hloss_train: 0.0018 loss_val: 0.0644 acc_val: 0.8733 hloss_val: 0.0221 time: 2.3595s\n",
            "Epoch: 0072 loss_train: 0.0394 acc_train: 0.9833 hloss_train: 0.0024 loss_val: 0.0572 acc_val: 0.9132 hloss_val: 0.0164 time: 2.3594s\n",
            "Epoch: 0073 loss_train: 0.0376 acc_train: 0.9875 hloss_train: 0.0018 loss_val: 0.0558 acc_val: 0.8889 hloss_val: 0.0198 time: 2.3610s\n",
            "Epoch: 0074 loss_train: 0.0381 acc_train: 0.9875 hloss_train: 0.0018 loss_val: 0.0516 acc_val: 0.8976 hloss_val: 0.0169 time: 2.3613s\n",
            "Epoch: 0075 loss_train: 0.0384 acc_train: 0.9938 hloss_train: 0.0009 loss_val: 0.0512 acc_val: 0.9097 hloss_val: 0.0174 time: 2.3618s\n",
            "Epoch: 0076 loss_train: 0.0375 acc_train: 0.9875 hloss_train: 0.0018 loss_val: 0.0511 acc_val: 0.9132 hloss_val: 0.0186 time: 2.3647s\n",
            "Epoch: 0077 loss_train: 0.0346 acc_train: 0.9896 hloss_train: 0.0018 loss_val: 0.0495 acc_val: 0.9722 hloss_val: 0.0079 time: 2.3630s\n",
            "Epoch: 0078 loss_train: 0.0339 acc_train: 0.9917 hloss_train: 0.0012 loss_val: 0.0475 acc_val: 0.9410 hloss_val: 0.0107 time: 2.3633s\n",
            "Epoch: 0079 loss_train: 0.0342 acc_train: 0.9896 hloss_train: 0.0015 loss_val: 0.0471 acc_val: 0.9288 hloss_val: 0.0124 time: 2.3616s\n",
            "Epoch: 0080 loss_train: 0.0339 acc_train: 0.9938 hloss_train: 0.0012 loss_val: 0.0411 acc_val: 0.9844 hloss_val: 0.0045 time: 2.3655s\n",
            "Epoch: 0081 loss_train: 0.0327 acc_train: 0.9958 hloss_train: 0.0006 loss_val: 0.0396 acc_val: 0.9531 hloss_val: 0.0089 time: 2.3641s\n",
            "Epoch: 0082 loss_train: 0.0335 acc_train: 0.9938 hloss_train: 0.0009 loss_val: 0.0458 acc_val: 0.9253 hloss_val: 0.0129 time: 2.3636s\n",
            "Epoch: 0083 loss_train: 0.0326 acc_train: 0.9958 hloss_train: 0.0006 loss_val: 0.0440 acc_val: 0.9253 hloss_val: 0.0146 time: 2.3637s\n",
            "Epoch: 0084 loss_train: 0.0306 acc_train: 0.9875 hloss_train: 0.0018 loss_val: 0.0437 acc_val: 0.9219 hloss_val: 0.0134 time: 2.3632s\n",
            "Epoch: 0085 loss_train: 0.0305 acc_train: 1.0000 hloss_train: 0.0000 loss_val: 0.0398 acc_val: 0.9688 hloss_val: 0.0067 time: 2.3636s\n",
            "Epoch: 0086 loss_train: 0.0294 acc_train: 0.9958 hloss_train: 0.0006 loss_val: 0.0407 acc_val: 0.9253 hloss_val: 0.0107 time: 2.3683s\n",
            "Epoch: 0087 loss_train: 0.0293 acc_train: 0.9958 hloss_train: 0.0006 loss_val: 0.0396 acc_val: 0.9844 hloss_val: 0.0022 time: 2.3639s\n",
            "Epoch: 0088 loss_train: 0.0296 acc_train: 0.9938 hloss_train: 0.0009 loss_val: 0.0404 acc_val: 0.9722 hloss_val: 0.0040 time: 2.3673s\n",
            "Epoch: 0089 loss_train: 0.0312 acc_train: 0.9958 hloss_train: 0.0006 loss_val: 0.0417 acc_val: 0.9288 hloss_val: 0.0124 time: 2.3644s\n",
            "Epoch: 0090 loss_train: 0.0309 acc_train: 0.9896 hloss_train: 0.0018 loss_val: 0.0369 acc_val: 0.9531 hloss_val: 0.0089 time: 2.3638s\n",
            "Epoch: 0091 loss_train: 0.0281 acc_train: 0.9875 hloss_train: 0.0018 loss_val: 0.0379 acc_val: 0.9722 hloss_val: 0.0040 time: 2.3666s\n",
            "Epoch: 0092 loss_train: 0.0267 acc_train: 0.9979 hloss_train: 0.0003 loss_val: 0.0345 acc_val: 0.9722 hloss_val: 0.0079 time: 2.3672s\n",
            "Epoch: 0093 loss_train: 0.0263 acc_train: 0.9958 hloss_train: 0.0006 loss_val: 0.0320 acc_val: 0.9566 hloss_val: 0.0062 time: 2.3680s\n",
            "Epoch: 0094 loss_train: 0.0264 acc_train: 0.9938 hloss_train: 0.0009 loss_val: 0.0342 acc_val: 0.9844 hloss_val: 0.0022 time: 2.3684s\n",
            "Epoch: 0095 loss_train: 0.0269 acc_train: 0.9979 hloss_train: 0.0003 loss_val: 0.0345 acc_val: 0.9566 hloss_val: 0.0102 time: 2.3667s\n",
            "Epoch: 0096 loss_train: 0.0264 acc_train: 0.9979 hloss_train: 0.0003 loss_val: 0.0325 acc_val: 0.9688 hloss_val: 0.0067 time: 2.3668s\n",
            "Epoch: 0097 loss_train: 0.0243 acc_train: 1.0000 hloss_train: 0.0000 loss_val: 0.0339 acc_val: 0.9531 hloss_val: 0.0067 time: 2.3673s\n",
            "Epoch: 0098 loss_train: 0.0242 acc_train: 0.9979 hloss_train: 0.0003 loss_val: 0.0310 acc_val: 0.9844 hloss_val: 0.0022 time: 2.3667s\n",
            "Epoch: 0099 loss_train: 0.0261 acc_train: 0.9979 hloss_train: 0.0003 loss_val: 0.0318 acc_val: 0.9844 hloss_val: 0.0022 time: 2.3668s\n",
            "Epoch: 0100 loss_train: 0.0241 acc_train: 1.0000 hloss_train: 0.0000 loss_val: 0.0289 acc_val: 0.9566 hloss_val: 0.0062 time: 2.3666s\n",
            "Epoch: 0101 loss_train: 0.0245 acc_train: 0.9979 hloss_train: 0.0003 loss_val: 0.0332 acc_val: 0.9566 hloss_val: 0.0102 time: 2.3677s\n",
            "Epoch: 0102 loss_train: 0.0238 acc_train: 0.9979 hloss_train: 0.0003 loss_val: 0.0306 acc_val: 0.9688 hloss_val: 0.0067 time: 2.3699s\n",
            "Epoch: 0103 loss_train: 0.0232 acc_train: 1.0000 hloss_train: 0.0000 loss_val: 0.0305 acc_val: 0.9688 hloss_val: 0.0045 time: 2.3657s\n",
            "Epoch: 0104 loss_train: 0.0222 acc_train: 1.0000 hloss_train: 0.0000 loss_val: 0.0269 acc_val: 1.0000 hloss_val: 0.0000 time: 2.3691s\n",
            "Epoch: 0105 loss_train: 0.0220 acc_train: 0.9979 hloss_train: 0.0003 loss_val: 0.0270 acc_val: 1.0000 hloss_val: 0.0000 time: 2.3671s\n",
            "Epoch: 0106 loss_train: 0.0224 acc_train: 0.9979 hloss_train: 0.0003 loss_val: 0.0266 acc_val: 0.9844 hloss_val: 0.0022 time: 2.3728s\n",
            "Epoch: 0107 loss_train: 0.0208 acc_train: 0.9979 hloss_train: 0.0003 loss_val: 0.0279 acc_val: 0.9688 hloss_val: 0.0067 time: 2.3681s\n",
            "Epoch: 0108 loss_train: 0.0215 acc_train: 0.9979 hloss_train: 0.0003 loss_val: 0.0295 acc_val: 0.9688 hloss_val: 0.0067 time: 2.3666s\n",
            "Epoch: 0109 loss_train: 0.0224 acc_train: 1.0000 hloss_train: 0.0000 loss_val: 0.0269 acc_val: 0.9844 hloss_val: 0.0045 time: 2.3670s\n",
            "Epoch: 0110 loss_train: 0.0210 acc_train: 0.9979 hloss_train: 0.0003 loss_val: 0.0303 acc_val: 0.9722 hloss_val: 0.0040 time: 2.3666s\n",
            "Epoch: 0111 loss_train: 0.0214 acc_train: 1.0000 hloss_train: 0.0000 loss_val: 0.0279 acc_val: 0.9844 hloss_val: 0.0045 time: 2.3700s\n",
            "Epoch: 0112 loss_train: 0.0195 acc_train: 1.0000 hloss_train: 0.0000 loss_val: 0.0316 acc_val: 0.9410 hloss_val: 0.0107 time: 2.3652s\n",
            "Epoch: 0113 loss_train: 0.0201 acc_train: 0.9979 hloss_train: 0.0003 loss_val: 0.0272 acc_val: 0.9844 hloss_val: 0.0045 time: 2.3693s\n",
            "Epoch: 0114 loss_train: 0.0202 acc_train: 1.0000 hloss_train: 0.0000 loss_val: 0.0279 acc_val: 0.9722 hloss_val: 0.0040 time: 2.3678s\n",
            "Epoch: 0115 loss_train: 0.0186 acc_train: 1.0000 hloss_train: 0.0000 loss_val: 0.0242 acc_val: 0.9844 hloss_val: 0.0045 time: 2.3681s\n",
            "Epoch: 0116 loss_train: 0.0196 acc_train: 1.0000 hloss_train: 0.0000 loss_val: 0.0257 acc_val: 0.9844 hloss_val: 0.0022 time: 2.3701s\n",
            "Epoch: 0117 loss_train: 0.0196 acc_train: 0.9979 hloss_train: 0.0003 loss_val: 0.0228 acc_val: 1.0000 hloss_val: 0.0000 time: 2.3666s\n",
            "Epoch: 0118 loss_train: 0.0193 acc_train: 1.0000 hloss_train: 0.0000 loss_val: 0.0243 acc_val: 0.9844 hloss_val: 0.0022 time: 2.3669s\n",
            "Epoch: 0119 loss_train: 0.0198 acc_train: 0.9979 hloss_train: 0.0003 loss_val: 0.0237 acc_val: 0.9844 hloss_val: 0.0022 time: 2.3667s\n",
            "Epoch: 0120 loss_train: 0.0207 acc_train: 0.9979 hloss_train: 0.0003 loss_val: 0.0244 acc_val: 0.9844 hloss_val: 0.0022 time: 2.3709s\n",
            "Epoch: 0121 loss_train: 0.0190 acc_train: 0.9979 hloss_train: 0.0003 loss_val: 0.0219 acc_val: 1.0000 hloss_val: 0.0000 time: 2.3668s\n",
            "Epoch: 0122 loss_train: 0.0181 acc_train: 1.0000 hloss_train: 0.0000 loss_val: 0.0227 acc_val: 1.0000 hloss_val: 0.0000 time: 2.3672s\n",
            "Epoch: 0123 loss_train: 0.0178 acc_train: 1.0000 hloss_train: 0.0000 loss_val: 0.0221 acc_val: 1.0000 hloss_val: 0.0000 time: 2.3700s\n",
            "Epoch: 0124 loss_train: 0.0180 acc_train: 1.0000 hloss_train: 0.0000 loss_val: 0.0240 acc_val: 1.0000 hloss_val: 0.0000 time: 2.3688s\n",
            "Epoch: 0125 loss_train: 0.0172 acc_train: 0.9979 hloss_train: 0.0003 loss_val: 0.0194 acc_val: 1.0000 hloss_val: 0.0000 time: 2.3705s\n",
            "Epoch: 0126 loss_train: 0.0173 acc_train: 1.0000 hloss_train: 0.0000 loss_val: 0.0210 acc_val: 1.0000 hloss_val: 0.0000 time: 2.3713s\n",
            "Epoch: 0127 loss_train: 0.0166 acc_train: 1.0000 hloss_train: 0.0000 loss_val: 0.0226 acc_val: 0.9722 hloss_val: 0.0040 time: 2.3698s\n",
            "Epoch: 0128 loss_train: 0.0195 acc_train: 1.0000 hloss_train: 0.0000 loss_val: 0.0214 acc_val: 0.9722 hloss_val: 0.0040 time: 2.3695s\n",
            "Epoch: 0129 loss_train: 0.0196 acc_train: 0.9917 hloss_train: 0.0015 loss_val: 0.0258 acc_val: 0.9566 hloss_val: 0.0062 time: 2.3715s\n",
            "Epoch: 0130 loss_train: 0.0179 acc_train: 0.9958 hloss_train: 0.0009 loss_val: 0.0211 acc_val: 1.0000 hloss_val: 0.0000 time: 2.3705s\n",
            "Epoch: 0131 loss_train: 0.0158 acc_train: 0.9979 hloss_train: 0.0003 loss_val: 0.0192 acc_val: 1.0000 hloss_val: 0.0000 time: 2.3721s\n",
            "Epoch: 0132 loss_train: 0.0162 acc_train: 1.0000 hloss_train: 0.0000 loss_val: 0.0195 acc_val: 0.9844 hloss_val: 0.0022 time: 2.3702s\n",
            "Epoch: 0133 loss_train: 0.0156 acc_train: 0.9979 hloss_train: 0.0003 loss_val: 0.0189 acc_val: 1.0000 hloss_val: 0.0000 time: 2.3697s\n",
            "Epoch: 0134 loss_train: 0.0155 acc_train: 1.0000 hloss_train: 0.0000 loss_val: 0.0195 acc_val: 1.0000 hloss_val: 0.0000 time: 2.3714s\n",
            "Epoch: 0135 loss_train: 0.0154 acc_train: 1.0000 hloss_train: 0.0000 loss_val: 0.0174 acc_val: 1.0000 hloss_val: 0.0000 time: 2.3723s\n",
            "Epoch: 0136 loss_train: 0.0146 acc_train: 1.0000 hloss_train: 0.0000 loss_val: 0.0171 acc_val: 1.0000 hloss_val: 0.0000 time: 2.3692s\n",
            "Epoch: 0137 loss_train: 0.0147 acc_train: 1.0000 hloss_train: 0.0000 loss_val: 0.0189 acc_val: 1.0000 hloss_val: 0.0000 time: 2.3696s\n",
            "Epoch: 0138 loss_train: 0.0157 acc_train: 1.0000 hloss_train: 0.0000 loss_val: 0.0172 acc_val: 1.0000 hloss_val: 0.0000 time: 2.3699s\n",
            "Epoch: 0139 loss_train: 0.0149 acc_train: 1.0000 hloss_train: 0.0000 loss_val: 0.0165 acc_val: 1.0000 hloss_val: 0.0000 time: 2.3709s\n",
            "Epoch: 0140 loss_train: 0.0144 acc_train: 1.0000 hloss_train: 0.0000 loss_val: 0.0161 acc_val: 1.0000 hloss_val: 0.0000 time: 2.3690s\n",
            "Epoch: 0141 loss_train: 0.0143 acc_train: 0.9979 hloss_train: 0.0003 loss_val: 0.0154 acc_val: 1.0000 hloss_val: 0.0000 time: 2.3693s\n",
            "Epoch: 0142 loss_train: 0.0139 acc_train: 1.0000 hloss_train: 0.0000 loss_val: 0.0154 acc_val: 1.0000 hloss_val: 0.0000 time: 2.3726s\n",
            "Epoch: 0143 loss_train: 0.0136 acc_train: 1.0000 hloss_train: 0.0000 loss_val: 0.0157 acc_val: 1.0000 hloss_val: 0.0000 time: 2.3791s\n",
            "Epoch: 0144 loss_train: 0.0139 acc_train: 1.0000 hloss_train: 0.0000 loss_val: 0.0159 acc_val: 1.0000 hloss_val: 0.0000 time: 2.3718s\n",
            "Epoch: 0145 loss_train: 0.0142 acc_train: 1.0000 hloss_train: 0.0000 loss_val: 0.0149 acc_val: 1.0000 hloss_val: 0.0000 time: 2.3737s\n",
            "Epoch: 0146 loss_train: 0.0142 acc_train: 1.0000 hloss_train: 0.0000 loss_val: 0.0156 acc_val: 1.0000 hloss_val: 0.0000 time: 2.3698s\n",
            "Epoch: 0147 loss_train: 0.0129 acc_train: 1.0000 hloss_train: 0.0000 loss_val: 0.0155 acc_val: 1.0000 hloss_val: 0.0000 time: 2.3716s\n",
            "Epoch: 0148 loss_train: 0.0130 acc_train: 1.0000 hloss_train: 0.0000 loss_val: 0.0139 acc_val: 1.0000 hloss_val: 0.0000 time: 2.3735s\n",
            "Epoch: 0149 loss_train: 0.0137 acc_train: 1.0000 hloss_train: 0.0000 loss_val: 0.0140 acc_val: 1.0000 hloss_val: 0.0000 time: 2.3696s\n",
            "Epoch: 0150 loss_train: 0.0128 acc_train: 1.0000 hloss_train: 0.0000 loss_val: 0.0144 acc_val: 1.0000 hloss_val: 0.0000 time: 2.3707s\n",
            "Epoch: 0151 loss_train: 0.0123 acc_train: 1.0000 hloss_train: 0.0000 loss_val: 0.0142 acc_val: 1.0000 hloss_val: 0.0000 time: 2.3704s\n",
            "Epoch: 0152 loss_train: 0.0129 acc_train: 1.0000 hloss_train: 0.0000 loss_val: 0.0149 acc_val: 1.0000 hloss_val: 0.0000 time: 2.3700s\n",
            "Epoch: 0153 loss_train: 0.0123 acc_train: 1.0000 hloss_train: 0.0000 loss_val: 0.0139 acc_val: 1.0000 hloss_val: 0.0000 time: 2.3677s\n",
            "Epoch: 0154 loss_train: 0.0120 acc_train: 1.0000 hloss_train: 0.0000 loss_val: 0.0151 acc_val: 1.0000 hloss_val: 0.0000 time: 2.3680s\n",
            "Epoch: 0155 loss_train: 0.0142 acc_train: 1.0000 hloss_train: 0.0000 loss_val: 0.0142 acc_val: 1.0000 hloss_val: 0.0000 time: 2.3672s\n",
            "Epoch: 0156 loss_train: 0.0131 acc_train: 1.0000 hloss_train: 0.0000 loss_val: 0.0135 acc_val: 1.0000 hloss_val: 0.0000 time: 2.3727s\n",
            "Epoch: 0157 loss_train: 0.0129 acc_train: 1.0000 hloss_train: 0.0000 loss_val: 0.0132 acc_val: 1.0000 hloss_val: 0.0000 time: 2.3720s\n",
            "Epoch: 0158 loss_train: 0.0123 acc_train: 1.0000 hloss_train: 0.0000 loss_val: 0.0143 acc_val: 1.0000 hloss_val: 0.0000 time: 2.3683s\n",
            "Epoch: 0159 loss_train: 0.0117 acc_train: 1.0000 hloss_train: 0.0000 loss_val: 0.0140 acc_val: 1.0000 hloss_val: 0.0000 time: 2.3705s\n",
            "Epoch: 0160 loss_train: 0.0120 acc_train: 1.0000 hloss_train: 0.0000 loss_val: 0.0132 acc_val: 1.0000 hloss_val: 0.0000 time: 2.3723s\n",
            "Epoch: 0161 loss_train: 0.0121 acc_train: 1.0000 hloss_train: 0.0000 loss_val: 0.0121 acc_val: 1.0000 hloss_val: 0.0000 time: 2.3715s\n",
            "Epoch: 0162 loss_train: 0.0122 acc_train: 1.0000 hloss_train: 0.0000 loss_val: 0.0123 acc_val: 1.0000 hloss_val: 0.0000 time: 2.3692s\n",
            "Epoch: 0163 loss_train: 0.0114 acc_train: 1.0000 hloss_train: 0.0000 loss_val: 0.0141 acc_val: 1.0000 hloss_val: 0.0000 time: 2.3708s\n",
            "Epoch: 0164 loss_train: 0.0123 acc_train: 1.0000 hloss_train: 0.0000 loss_val: 0.0132 acc_val: 1.0000 hloss_val: 0.0000 time: 2.3688s\n",
            "Epoch: 0165 loss_train: 0.0123 acc_train: 1.0000 hloss_train: 0.0000 loss_val: 0.0124 acc_val: 1.0000 hloss_val: 0.0000 time: 2.3696s\n",
            "Epoch: 0166 loss_train: 0.0110 acc_train: 1.0000 hloss_train: 0.0000 loss_val: 0.0123 acc_val: 1.0000 hloss_val: 0.0000 time: 2.3700s\n",
            "Epoch: 0167 loss_train: 0.0110 acc_train: 1.0000 hloss_train: 0.0000 loss_val: 0.0117 acc_val: 1.0000 hloss_val: 0.0000 time: 2.3701s\n",
            "Epoch: 0168 loss_train: 0.0108 acc_train: 1.0000 hloss_train: 0.0000 loss_val: 0.0124 acc_val: 1.0000 hloss_val: 0.0000 time: 2.3682s\n",
            "Epoch: 0169 loss_train: 0.0108 acc_train: 1.0000 hloss_train: 0.0000 loss_val: 0.0117 acc_val: 1.0000 hloss_val: 0.0000 time: 2.3705s\n",
            "Epoch: 0170 loss_train: 0.0106 acc_train: 1.0000 hloss_train: 0.0000 loss_val: 0.0118 acc_val: 1.0000 hloss_val: 0.0000 time: 2.3708s\n",
            "Epoch: 0171 loss_train: 0.0107 acc_train: 1.0000 hloss_train: 0.0000 loss_val: 0.0123 acc_val: 1.0000 hloss_val: 0.0000 time: 2.3715s\n",
            "Epoch: 0172 loss_train: 0.0103 acc_train: 1.0000 hloss_train: 0.0000 loss_val: 0.0109 acc_val: 1.0000 hloss_val: 0.0000 time: 2.3696s\n",
            "Epoch: 0173 loss_train: 0.0103 acc_train: 1.0000 hloss_train: 0.0000 loss_val: 0.0110 acc_val: 1.0000 hloss_val: 0.0000 time: 2.3671s\n",
            "Epoch: 0174 loss_train: 0.0100 acc_train: 1.0000 hloss_train: 0.0000 loss_val: 0.0110 acc_val: 1.0000 hloss_val: 0.0000 time: 2.3703s\n",
            "Epoch: 0175 loss_train: 0.0101 acc_train: 1.0000 hloss_train: 0.0000 loss_val: 0.0114 acc_val: 1.0000 hloss_val: 0.0000 time: 2.3699s\n",
            "Epoch: 0176 loss_train: 0.0105 acc_train: 1.0000 hloss_train: 0.0000 loss_val: 0.0106 acc_val: 1.0000 hloss_val: 0.0000 time: 2.3684s\n",
            "Epoch: 0177 loss_train: 0.0097 acc_train: 1.0000 hloss_train: 0.0000 loss_val: 0.0108 acc_val: 1.0000 hloss_val: 0.0000 time: 2.3682s\n",
            "Epoch: 0178 loss_train: 0.0096 acc_train: 1.0000 hloss_train: 0.0000 loss_val: 0.0103 acc_val: 1.0000 hloss_val: 0.0000 time: 2.3698s\n",
            "Epoch: 0179 loss_train: 0.0094 acc_train: 1.0000 hloss_train: 0.0000 loss_val: 0.0105 acc_val: 1.0000 hloss_val: 0.0000 time: 2.3670s\n",
            "Epoch: 0180 loss_train: 0.0101 acc_train: 1.0000 hloss_train: 0.0000 loss_val: 0.0104 acc_val: 1.0000 hloss_val: 0.0000 time: 2.3702s\n",
            "Epoch: 0181 loss_train: 0.0096 acc_train: 0.9979 hloss_train: 0.0003 loss_val: 0.0108 acc_val: 1.0000 hloss_val: 0.0000 time: 2.3688s\n",
            "Epoch: 0182 loss_train: 0.0095 acc_train: 1.0000 hloss_train: 0.0000 loss_val: 0.0118 acc_val: 1.0000 hloss_val: 0.0000 time: 2.3913s\n",
            "Epoch: 0183 loss_train: 0.0099 acc_train: 1.0000 hloss_train: 0.0000 loss_val: 0.0106 acc_val: 1.0000 hloss_val: 0.0000 time: 2.3683s\n",
            "Epoch: 0184 loss_train: 0.0096 acc_train: 1.0000 hloss_train: 0.0000 loss_val: 0.0101 acc_val: 1.0000 hloss_val: 0.0000 time: 2.3692s\n",
            "Epoch: 0185 loss_train: 0.0093 acc_train: 1.0000 hloss_train: 0.0000 loss_val: 0.0104 acc_val: 1.0000 hloss_val: 0.0000 time: 2.3673s\n",
            "Epoch: 0186 loss_train: 0.0090 acc_train: 1.0000 hloss_train: 0.0000 loss_val: 0.0098 acc_val: 1.0000 hloss_val: 0.0000 time: 2.3690s\n",
            "Epoch: 0187 loss_train: 0.0089 acc_train: 1.0000 hloss_train: 0.0000 loss_val: 0.0102 acc_val: 1.0000 hloss_val: 0.0000 time: 2.3693s\n",
            "Epoch: 0188 loss_train: 0.0090 acc_train: 1.0000 hloss_train: 0.0000 loss_val: 0.0093 acc_val: 1.0000 hloss_val: 0.0000 time: 2.3698s\n",
            "Epoch: 0189 loss_train: 0.0091 acc_train: 1.0000 hloss_train: 0.0000 loss_val: 0.0102 acc_val: 1.0000 hloss_val: 0.0000 time: 2.3693s\n",
            "Epoch: 0190 loss_train: 0.0089 acc_train: 1.0000 hloss_train: 0.0000 loss_val: 0.0102 acc_val: 1.0000 hloss_val: 0.0000 time: 2.3665s\n",
            "Epoch: 0191 loss_train: 0.0095 acc_train: 1.0000 hloss_train: 0.0000 loss_val: 0.0105 acc_val: 1.0000 hloss_val: 0.0000 time: 2.3699s\n",
            "Epoch: 0192 loss_train: 0.0091 acc_train: 1.0000 hloss_train: 0.0000 loss_val: 0.0105 acc_val: 1.0000 hloss_val: 0.0000 time: 2.3994s\n",
            "Epoch: 0193 loss_train: 0.0093 acc_train: 1.0000 hloss_train: 0.0000 loss_val: 0.0107 acc_val: 1.0000 hloss_val: 0.0000 time: 2.3684s\n",
            "Epoch: 0194 loss_train: 0.0085 acc_train: 1.0000 hloss_train: 0.0000 loss_val: 0.0095 acc_val: 1.0000 hloss_val: 0.0000 time: 2.3681s\n",
            "Epoch: 0195 loss_train: 0.0083 acc_train: 1.0000 hloss_train: 0.0000 loss_val: 0.0093 acc_val: 1.0000 hloss_val: 0.0000 time: 2.3689s\n",
            "Epoch: 0196 loss_train: 0.0088 acc_train: 1.0000 hloss_train: 0.0000 loss_val: 0.0097 acc_val: 1.0000 hloss_val: 0.0000 time: 2.3697s\n",
            "Epoch: 0197 loss_train: 0.0086 acc_train: 1.0000 hloss_train: 0.0000 loss_val: 0.0096 acc_val: 1.0000 hloss_val: 0.0000 time: 2.3699s\n",
            "Epoch: 0198 loss_train: 0.0089 acc_train: 1.0000 hloss_train: 0.0000 loss_val: 0.0086 acc_val: 1.0000 hloss_val: 0.0000 time: 2.3678s\n",
            "Epoch: 0199 loss_train: 0.0081 acc_train: 1.0000 hloss_train: 0.0000 loss_val: 0.0096 acc_val: 1.0000 hloss_val: 0.0000 time: 2.3663s\n",
            "Epoch: 0200 loss_train: 0.0080 acc_train: 1.0000 hloss_train: 0.0000 loss_val: 0.0090 acc_val: 1.0000 hloss_val: 0.0000 time: 2.3682s\n",
            "Total train time: 469.6866s\n",
            "\n",
            "==================================================\n",
            "TextGCN->BERT x EmoLex\n",
            "==================================================\n",
            "Accuracy Score: 1.0000\n",
            "F1 Score (Micro): 1.0000\n",
            "F1 Score (Macro): 1.0000\n",
            "F1 Score (Weighted): 1.0000\n",
            "Hamming Loss: 0.0000\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "       anger     1.0000    1.0000    1.0000       174\n",
            "     disgust     1.0000    1.0000    1.0000        92\n",
            "        fear     1.0000    1.0000    1.0000       165\n",
            "     sadness     1.0000    1.0000    1.0000       215\n",
            "    surprise     1.0000    1.0000    1.0000        51\n",
            "    negative     1.0000    1.0000    1.0000       328\n",
            "       other     1.0000    1.0000    1.0000       155\n",
            "\n",
            "   micro avg     1.0000    1.0000    1.0000      1180\n",
            "   macro avg     1.0000    1.0000    1.0000      1180\n",
            "weighted avg     1.0000    1.0000    1.0000      1180\n",
            " samples avg     0.7340    0.7340    0.7340      1180\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/home/rcmcabral/.local/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in samples with no predicted labels. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/home/rcmcabral/.local/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in samples with no true labels. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        }
      ],
      "source": [
        "lexName = \"EmoLex\"\n",
        "title1 = \"TextGCN x \" + lexName\n",
        "title2 = \"TextGCN->BERT x \" + lexName\n",
        "texts = original_train_sentences\n",
        "\n",
        "lexTokens = emoLex_allTokens\n",
        "lexLabels = emoLex_allEmotions\n",
        "lexClassNames = emoLex_labels\n",
        "\n",
        "#Populate document multilabel emotions\n",
        "emoLabels, num_emoClass = encodeDocEmotions(lexTokens, lexLabels, tokenize_sentences)\n",
        "original_emoLabels_train = emoLabels[:train_size]\n",
        "emoLabels = torch.FloatTensor(emoLabels).to(device)\n",
        "\n",
        "doc_embeddings, word_embeddings = train_GCNBert()\n",
        "\n",
        "# saveWeights(\"./_OUTPUT/DocEmbeddings_\" + tokenTitle + \"Embeddings.pkl\", texts, doc_embeddings, lexLabels, original_train_labels, lexClassNames)   #Document embeddings\n",
        "saveWordEmbeddings(\"./_OUTPUT/MMEMOG_\" + tokenTitle + \"Embeddings_\" + lexName + \".pkl\", vocab, word_embeddings)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bphsHbY4v1tW"
      },
      "source": [
        "##TEC"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 179,
      "metadata": {
        "id": "90rJcNZJv1tW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "aa543410-eedc-4627-adb6-50c3b2c1a5df"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 0001 loss_train: 0.6939 acc_train: 0.2311 hloss_train: 0.2285 loss_val: 0.6230 acc_val: 0.2400 hloss_val: 0.2233 time: 0.0100s\n",
            "Epoch: 0002 loss_train: 0.6182 acc_train: 0.2311 hloss_train: 0.2285 loss_val: 0.6457 acc_val: 0.2400 hloss_val: 0.2233 time: 0.0094s\n",
            "Epoch: 0003 loss_train: 0.6312 acc_train: 0.2311 hloss_train: 0.2285 loss_val: 0.5429 acc_val: 0.2400 hloss_val: 0.2233 time: 0.0091s\n",
            "Epoch: 0004 loss_train: 0.5193 acc_train: 0.2311 hloss_train: 0.2285 loss_val: 0.5543 acc_val: 0.2400 hloss_val: 0.2233 time: 0.0091s\n",
            "Epoch: 0005 loss_train: 0.5269 acc_train: 0.2311 hloss_train: 0.2285 loss_val: 0.5674 acc_val: 0.2400 hloss_val: 0.2233 time: 0.0092s\n",
            "Epoch: 0006 loss_train: 0.5412 acc_train: 0.2311 hloss_train: 0.2285 loss_val: 0.5455 acc_val: 0.2400 hloss_val: 0.2233 time: 0.0091s\n",
            "Epoch: 0007 loss_train: 0.5184 acc_train: 0.2311 hloss_train: 0.2285 loss_val: 0.5239 acc_val: 0.2400 hloss_val: 0.2233 time: 0.0091s\n",
            "Epoch: 0008 loss_train: 0.4925 acc_train: 0.2311 hloss_train: 0.2285 loss_val: 0.5225 acc_val: 0.2400 hloss_val: 0.2233 time: 0.0091s\n",
            "Epoch: 0009 loss_train: 0.4899 acc_train: 0.2311 hloss_train: 0.2285 loss_val: 0.5204 acc_val: 0.2400 hloss_val: 0.2233 time: 0.0099s\n",
            "Epoch: 0010 loss_train: 0.4930 acc_train: 0.2311 hloss_train: 0.2285 loss_val: 0.5108 acc_val: 0.2400 hloss_val: 0.2233 time: 0.0100s\n",
            "Epoch: 0011 loss_train: 0.4854 acc_train: 0.2311 hloss_train: 0.2285 loss_val: 0.5063 acc_val: 0.2400 hloss_val: 0.2233 time: 0.0104s\n",
            "Epoch: 0012 loss_train: 0.4789 acc_train: 0.2311 hloss_train: 0.2285 loss_val: 0.5084 acc_val: 0.2400 hloss_val: 0.2233 time: 0.0096s\n",
            "Epoch: 0013 loss_train: 0.4782 acc_train: 0.2311 hloss_train: 0.2285 loss_val: 0.5112 acc_val: 0.2400 hloss_val: 0.2233 time: 0.0093s\n",
            "Epoch: 0014 loss_train: 0.4796 acc_train: 0.2311 hloss_train: 0.2285 loss_val: 0.5113 acc_val: 0.2400 hloss_val: 0.2233 time: 0.0093s\n",
            "Epoch: 0015 loss_train: 0.4764 acc_train: 0.2311 hloss_train: 0.2285 loss_val: 0.5094 acc_val: 0.2400 hloss_val: 0.2233 time: 0.0093s\n",
            "Epoch: 0016 loss_train: 0.4745 acc_train: 0.2311 hloss_train: 0.2285 loss_val: 0.5058 acc_val: 0.2400 hloss_val: 0.2233 time: 0.0092s\n",
            "Epoch: 0017 loss_train: 0.4736 acc_train: 0.2311 hloss_train: 0.2285 loss_val: 0.4992 acc_val: 0.2400 hloss_val: 0.2233 time: 0.0092s\n",
            "Epoch: 0018 loss_train: 0.4725 acc_train: 0.2311 hloss_train: 0.2285 loss_val: 0.4951 acc_val: 0.2400 hloss_val: 0.2233 time: 0.0093s\n",
            "Epoch: 0019 loss_train: 0.4709 acc_train: 0.2311 hloss_train: 0.2285 loss_val: 0.4940 acc_val: 0.2400 hloss_val: 0.2233 time: 0.0092s\n",
            "Epoch: 0020 loss_train: 0.4676 acc_train: 0.2311 hloss_train: 0.2285 loss_val: 0.4952 acc_val: 0.2400 hloss_val: 0.2233 time: 0.0093s\n",
            "Epoch: 0021 loss_train: 0.4666 acc_train: 0.2311 hloss_train: 0.2285 loss_val: 0.4968 acc_val: 0.2400 hloss_val: 0.2233 time: 0.0100s\n",
            "Epoch: 0022 loss_train: 0.4648 acc_train: 0.2311 hloss_train: 0.2285 loss_val: 0.4927 acc_val: 0.2400 hloss_val: 0.2233 time: 0.0095s\n",
            "Epoch: 0023 loss_train: 0.4616 acc_train: 0.2311 hloss_train: 0.2285 loss_val: 0.4870 acc_val: 0.2400 hloss_val: 0.2233 time: 0.0100s\n",
            "Epoch: 0024 loss_train: 0.4573 acc_train: 0.2311 hloss_train: 0.2285 loss_val: 0.4838 acc_val: 0.2400 hloss_val: 0.2233 time: 0.0095s\n",
            "Epoch: 0025 loss_train: 0.4543 acc_train: 0.2311 hloss_train: 0.2285 loss_val: 0.4833 acc_val: 0.2400 hloss_val: 0.2233 time: 0.0093s\n",
            "Epoch: 0026 loss_train: 0.4504 acc_train: 0.2311 hloss_train: 0.2285 loss_val: 0.4815 acc_val: 0.2400 hloss_val: 0.2233 time: 0.0094s\n",
            "Epoch: 0027 loss_train: 0.4475 acc_train: 0.2333 hloss_train: 0.2285 loss_val: 0.4759 acc_val: 0.2400 hloss_val: 0.2233 time: 0.0094s\n",
            "Epoch: 0028 loss_train: 0.4427 acc_train: 0.2333 hloss_train: 0.2281 loss_val: 0.4713 acc_val: 0.2400 hloss_val: 0.2233 time: 0.0093s\n",
            "Epoch: 0029 loss_train: 0.4369 acc_train: 0.2333 hloss_train: 0.2278 loss_val: 0.4674 acc_val: 0.2400 hloss_val: 0.2233 time: 0.0094s\n",
            "Epoch: 0030 loss_train: 0.4333 acc_train: 0.2356 hloss_train: 0.2267 loss_val: 0.4666 acc_val: 0.2800 hloss_val: 0.2100 time: 0.0094s\n",
            "Epoch: 0031 loss_train: 0.4249 acc_train: 0.2511 hloss_train: 0.2215 loss_val: 0.4639 acc_val: 0.3000 hloss_val: 0.2067 time: 0.0093s\n",
            "Epoch: 0032 loss_train: 0.4194 acc_train: 0.2756 hloss_train: 0.2178 loss_val: 0.4533 acc_val: 0.3000 hloss_val: 0.2033 time: 0.0093s\n",
            "Epoch: 0033 loss_train: 0.4181 acc_train: 0.2600 hloss_train: 0.2204 loss_val: 0.4721 acc_val: 0.3200 hloss_val: 0.2067 time: 0.0091s\n",
            "Epoch: 0034 loss_train: 0.4206 acc_train: 0.3111 hloss_train: 0.2070 loss_val: 0.4507 acc_val: 0.3200 hloss_val: 0.2067 time: 0.0091s\n",
            "Epoch: 0035 loss_train: 0.4083 acc_train: 0.2911 hloss_train: 0.2137 loss_val: 0.4543 acc_val: 0.3400 hloss_val: 0.2033 time: 0.0091s\n",
            "Epoch: 0036 loss_train: 0.3973 acc_train: 0.3067 hloss_train: 0.2093 loss_val: 0.4737 acc_val: 0.3000 hloss_val: 0.1900 time: 0.0091s\n",
            "Epoch: 0037 loss_train: 0.4111 acc_train: 0.3533 hloss_train: 0.1878 loss_val: 0.4463 acc_val: 0.3200 hloss_val: 0.2000 time: 0.0091s\n",
            "Epoch: 0038 loss_train: 0.4040 acc_train: 0.3133 hloss_train: 0.2041 loss_val: 0.4552 acc_val: 0.3000 hloss_val: 0.2000 time: 0.0091s\n",
            "Epoch: 0039 loss_train: 0.4100 acc_train: 0.2911 hloss_train: 0.2107 loss_val: 0.4783 acc_val: 0.3200 hloss_val: 0.1767 time: 0.0092s\n",
            "Epoch: 0040 loss_train: 0.3951 acc_train: 0.3511 hloss_train: 0.1841 loss_val: 0.4810 acc_val: 0.3200 hloss_val: 0.1767 time: 0.0092s\n",
            "Epoch: 0041 loss_train: 0.3923 acc_train: 0.3822 hloss_train: 0.1719 loss_val: 0.4458 acc_val: 0.3200 hloss_val: 0.2033 time: 0.0092s\n",
            "Epoch: 0042 loss_train: 0.3880 acc_train: 0.3356 hloss_train: 0.1841 loss_val: 0.4362 acc_val: 0.3600 hloss_val: 0.1933 time: 0.0091s\n",
            "Epoch: 0043 loss_train: 0.4015 acc_train: 0.2911 hloss_train: 0.2081 loss_val: 0.4292 acc_val: 0.3600 hloss_val: 0.1900 time: 0.0089s\n",
            "Epoch: 0044 loss_train: 0.3671 acc_train: 0.3311 hloss_train: 0.1863 loss_val: 0.4500 acc_val: 0.3800 hloss_val: 0.1633 time: 0.0090s\n",
            "Epoch: 0045 loss_train: 0.3705 acc_train: 0.3711 hloss_train: 0.1726 loss_val: 0.4589 acc_val: 0.3800 hloss_val: 0.1667 time: 0.0096s\n",
            "Epoch: 0046 loss_train: 0.3754 acc_train: 0.4000 hloss_train: 0.1667 loss_val: 0.4293 acc_val: 0.3400 hloss_val: 0.1800 time: 0.0093s\n",
            "Epoch: 0047 loss_train: 0.3532 acc_train: 0.4022 hloss_train: 0.1693 loss_val: 0.4113 acc_val: 0.3600 hloss_val: 0.1700 time: 0.0090s\n",
            "Epoch: 0048 loss_train: 0.3561 acc_train: 0.3600 hloss_train: 0.1800 loss_val: 0.4049 acc_val: 0.3600 hloss_val: 0.1700 time: 0.0091s\n",
            "Epoch: 0049 loss_train: 0.3470 acc_train: 0.3778 hloss_train: 0.1726 loss_val: 0.3980 acc_val: 0.3200 hloss_val: 0.1767 time: 0.0090s\n",
            "Epoch: 0050 loss_train: 0.3466 acc_train: 0.3733 hloss_train: 0.1770 loss_val: 0.4026 acc_val: 0.3600 hloss_val: 0.1733 time: 0.0090s\n",
            "Epoch: 0051 loss_train: 0.3349 acc_train: 0.4556 hloss_train: 0.1493 loss_val: 0.4207 acc_val: 0.2800 hloss_val: 0.1933 time: 0.0093s\n",
            "Epoch: 0052 loss_train: 0.3532 acc_train: 0.4556 hloss_train: 0.1474 loss_val: 0.3995 acc_val: 0.4000 hloss_val: 0.1733 time: 0.0091s\n",
            "Epoch: 0053 loss_train: 0.3331 acc_train: 0.4267 hloss_train: 0.1593 loss_val: 0.3924 acc_val: 0.4000 hloss_val: 0.1667 time: 0.0091s\n",
            "Epoch: 0054 loss_train: 0.3292 acc_train: 0.4111 hloss_train: 0.1596 loss_val: 0.3933 acc_val: 0.3600 hloss_val: 0.1733 time: 0.0091s\n",
            "Epoch: 0055 loss_train: 0.3256 acc_train: 0.4222 hloss_train: 0.1537 loss_val: 0.3995 acc_val: 0.4000 hloss_val: 0.1667 time: 0.0090s\n",
            "Epoch: 0056 loss_train: 0.3228 acc_train: 0.4444 hloss_train: 0.1500 loss_val: 0.3937 acc_val: 0.4000 hloss_val: 0.1667 time: 0.0090s\n",
            "Epoch: 0057 loss_train: 0.3232 acc_train: 0.4244 hloss_train: 0.1589 loss_val: 0.3921 acc_val: 0.3200 hloss_val: 0.1767 time: 0.0090s\n",
            "Epoch: 0058 loss_train: 0.3156 acc_train: 0.4622 hloss_train: 0.1456 loss_val: 0.3925 acc_val: 0.4000 hloss_val: 0.1667 time: 0.0090s\n",
            "Epoch: 0059 loss_train: 0.2918 acc_train: 0.4822 hloss_train: 0.1385 loss_val: 0.4058 acc_val: 0.3600 hloss_val: 0.1733 time: 0.0090s\n",
            "Epoch: 0060 loss_train: 0.2897 acc_train: 0.4956 hloss_train: 0.1300 loss_val: 0.4164 acc_val: 0.3600 hloss_val: 0.1767 time: 0.0090s\n",
            "Epoch: 0061 loss_train: 0.3000 acc_train: 0.5022 hloss_train: 0.1241 loss_val: 0.3954 acc_val: 0.4400 hloss_val: 0.1567 time: 0.0090s\n",
            "Epoch: 0062 loss_train: 0.2915 acc_train: 0.4733 hloss_train: 0.1411 loss_val: 0.4021 acc_val: 0.4000 hloss_val: 0.1733 time: 0.0090s\n",
            "Epoch: 0063 loss_train: 0.3393 acc_train: 0.4000 hloss_train: 0.1637 loss_val: 0.4296 acc_val: 0.3000 hloss_val: 0.1933 time: 0.0090s\n",
            "Epoch: 0064 loss_train: 0.3051 acc_train: 0.5022 hloss_train: 0.1326 loss_val: 0.4515 acc_val: 0.3600 hloss_val: 0.1867 time: 0.0090s\n",
            "Epoch: 0065 loss_train: 0.3167 acc_train: 0.4444 hloss_train: 0.1419 loss_val: 0.4313 acc_val: 0.3400 hloss_val: 0.1900 time: 0.0089s\n",
            "Epoch: 0066 loss_train: 0.2799 acc_train: 0.5378 hloss_train: 0.1144 loss_val: 0.3989 acc_val: 0.3800 hloss_val: 0.1700 time: 0.0089s\n",
            "Epoch: 0067 loss_train: 0.2702 acc_train: 0.5022 hloss_train: 0.1237 loss_val: 0.4120 acc_val: 0.3600 hloss_val: 0.1800 time: 0.0089s\n",
            "Early Stopping...\n",
            "Total train time: 0.6217s\n",
            "\n",
            "==================================================\n",
            "TextGCN x TEC\n",
            "==================================================\n",
            "Accuracy Score: 0.5060\n",
            "F1 Score (Micro): 0.6493\n",
            "F1 Score (Macro): 0.4486\n",
            "F1 Score (Weighted): 0.5894\n",
            "Hamming Loss: 0.1253\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "       anger     0.9901    0.5814    0.7326       172\n",
            "     disgust     1.0000    0.0270    0.0526        37\n",
            "        fear     0.6250    0.0746    0.1333        67\n",
            "     sadness     0.9038    0.8650    0.8840       163\n",
            "    surprise     0.8333    0.1031    0.1835        97\n",
            "       other     0.8273    0.6149    0.7054       148\n",
            "\n",
            "   micro avg     0.8969    0.5088    0.6493       684\n",
            "   macro avg     0.8633    0.3777    0.4486       684\n",
            "weighted avg     0.8769    0.5088    0.5894       684\n",
            " samples avg     0.5185    0.4188    0.4474       684\n",
            "\n",
            "Max sequence length: 84\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/home/rcmcabral/.local/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in samples with no predicted labels. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/home/rcmcabral/.local/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in samples with no true labels. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 0001 loss_train: 0.5390 acc_train: 0.2104 hloss_train: 0.2424 loss_val: 0.5428 acc_val: 0.2604 hloss_val: 0.2190 time: 2.2293s\n",
            "Epoch: 0002 loss_train: 0.4979 acc_train: 0.2771 hloss_train: 0.2142 loss_val: 0.5099 acc_val: 0.2726 hloss_val: 0.2190 time: 2.2318s\n",
            "Epoch: 0003 loss_train: 0.5083 acc_train: 0.2167 hloss_train: 0.2299 loss_val: 0.5109 acc_val: 0.2361 hloss_val: 0.2231 time: 2.2259s\n",
            "Epoch: 0004 loss_train: 0.5062 acc_train: 0.2500 hloss_train: 0.2243 loss_val: 0.5006 acc_val: 0.2361 hloss_val: 0.2231 time: 2.2303s\n",
            "Epoch: 0005 loss_train: 0.4921 acc_train: 0.2479 hloss_train: 0.2198 loss_val: 0.4933 acc_val: 0.2483 hloss_val: 0.2190 time: 2.2352s\n",
            "Epoch: 0006 loss_train: 0.4962 acc_train: 0.2458 hloss_train: 0.2250 loss_val: 0.5005 acc_val: 0.2604 hloss_val: 0.2170 time: 2.2412s\n",
            "Epoch: 0007 loss_train: 0.5151 acc_train: 0.2188 hloss_train: 0.2444 loss_val: 0.4879 acc_val: 0.2483 hloss_val: 0.2231 time: 2.2444s\n",
            "Epoch: 0008 loss_train: 0.5022 acc_train: 0.2208 hloss_train: 0.2337 loss_val: 0.5081 acc_val: 0.2118 hloss_val: 0.2332 time: 2.2508s\n",
            "Epoch: 0009 loss_train: 0.4889 acc_train: 0.2188 hloss_train: 0.2271 loss_val: 0.5021 acc_val: 0.2240 hloss_val: 0.2292 time: 2.2545s\n",
            "Epoch: 0010 loss_train: 0.5164 acc_train: 0.2146 hloss_train: 0.2424 loss_val: 0.4929 acc_val: 0.2205 hloss_val: 0.2364 time: 2.2564s\n",
            "Epoch: 0011 loss_train: 0.4752 acc_train: 0.2167 hloss_train: 0.2233 loss_val: 0.4737 acc_val: 0.2483 hloss_val: 0.2170 time: 2.2546s\n",
            "Epoch: 0012 loss_train: 0.4702 acc_train: 0.2458 hloss_train: 0.2194 loss_val: 0.4847 acc_val: 0.2205 hloss_val: 0.2144 time: 2.2593s\n",
            "Epoch: 0013 loss_train: 0.4918 acc_train: 0.2479 hloss_train: 0.2274 loss_val: 0.4666 acc_val: 0.2326 hloss_val: 0.2196 time: 2.2660s\n",
            "Epoch: 0014 loss_train: 0.4596 acc_train: 0.2458 hloss_train: 0.2174 loss_val: 0.4814 acc_val: 0.2240 hloss_val: 0.2271 time: 2.2718s\n",
            "Epoch: 0015 loss_train: 0.4723 acc_train: 0.2458 hloss_train: 0.2323 loss_val: 0.4952 acc_val: 0.2361 hloss_val: 0.2266 time: 2.2793s\n",
            "Epoch: 0016 loss_train: 0.4617 acc_train: 0.2896 hloss_train: 0.2038 loss_val: 0.4921 acc_val: 0.2951 hloss_val: 0.2193 time: 2.2824s\n",
            "Epoch: 0017 loss_train: 0.4622 acc_train: 0.2188 hloss_train: 0.2201 loss_val: 0.4784 acc_val: 0.2205 hloss_val: 0.2153 time: 2.2870s\n",
            "Epoch: 0018 loss_train: 0.4457 acc_train: 0.2750 hloss_train: 0.2087 loss_val: 0.4705 acc_val: 0.2882 hloss_val: 0.1921 time: 2.2923s\n",
            "Epoch: 0019 loss_train: 0.4320 acc_train: 0.2646 hloss_train: 0.2045 loss_val: 0.4147 acc_val: 0.3628 hloss_val: 0.1716 time: 2.2999s\n",
            "Epoch: 0020 loss_train: 0.4121 acc_train: 0.3250 hloss_train: 0.1865 loss_val: 0.4845 acc_val: 0.3542 hloss_val: 0.2135 time: 2.3021s\n",
            "Epoch: 0021 loss_train: 0.3792 acc_train: 0.4208 hloss_train: 0.1514 loss_val: 0.4246 acc_val: 0.3698 hloss_val: 0.1869 time: 2.3067s\n",
            "Epoch: 0022 loss_train: 0.3688 acc_train: 0.4021 hloss_train: 0.1590 loss_val: 0.3791 acc_val: 0.4497 hloss_val: 0.1363 time: 2.3115s\n",
            "Epoch: 0023 loss_train: 0.3530 acc_train: 0.3979 hloss_train: 0.1528 loss_val: 0.3440 acc_val: 0.3819 hloss_val: 0.1496 time: 2.3182s\n",
            "Epoch: 0024 loss_train: 0.3130 acc_train: 0.4542 hloss_train: 0.1267 loss_val: 0.3431 acc_val: 0.4531 hloss_val: 0.1418 time: 2.3210s\n",
            "Epoch: 0025 loss_train: 0.3257 acc_train: 0.4500 hloss_train: 0.1264 loss_val: 0.3182 acc_val: 0.4531 hloss_val: 0.1403 time: 2.3215s\n",
            "Epoch: 0026 loss_train: 0.3046 acc_train: 0.4854 hloss_train: 0.1247 loss_val: 0.3592 acc_val: 0.4878 hloss_val: 0.1386 time: 2.3246s\n",
            "Epoch: 0027 loss_train: 0.3040 acc_train: 0.4938 hloss_train: 0.1101 loss_val: 0.3269 acc_val: 0.4479 hloss_val: 0.1308 time: 2.3282s\n",
            "Epoch: 0028 loss_train: 0.2544 acc_train: 0.5687 hloss_train: 0.0965 loss_val: 0.3261 acc_val: 0.5000 hloss_val: 0.1262 time: 2.3322s\n",
            "Epoch: 0029 loss_train: 0.2412 acc_train: 0.5583 hloss_train: 0.0913 loss_val: 0.3077 acc_val: 0.5312 hloss_val: 0.1169 time: 2.3317s\n",
            "Epoch: 0030 loss_train: 0.2313 acc_train: 0.5646 hloss_train: 0.0872 loss_val: 0.2842 acc_val: 0.5399 hloss_val: 0.0995 time: 2.3356s\n",
            "Epoch: 0031 loss_train: 0.2276 acc_train: 0.5729 hloss_train: 0.0865 loss_val: 0.3041 acc_val: 0.5590 hloss_val: 0.1071 time: 2.3396s\n",
            "Epoch: 0032 loss_train: 0.2092 acc_train: 0.6083 hloss_train: 0.0802 loss_val: 0.2767 acc_val: 0.5399 hloss_val: 0.1010 time: 2.3465s\n",
            "Epoch: 0033 loss_train: 0.2037 acc_train: 0.6583 hloss_train: 0.0691 loss_val: 0.3006 acc_val: 0.4722 hloss_val: 0.1117 time: 2.3426s\n",
            "Epoch: 0034 loss_train: 0.1952 acc_train: 0.6583 hloss_train: 0.0705 loss_val: 0.2551 acc_val: 0.5833 hloss_val: 0.0825 time: 2.3454s\n",
            "Epoch: 0035 loss_train: 0.1844 acc_train: 0.6771 hloss_train: 0.0615 loss_val: 0.2393 acc_val: 0.5590 hloss_val: 0.0885 time: 2.3453s\n",
            "Epoch: 0036 loss_train: 0.1571 acc_train: 0.7354 hloss_train: 0.0490 loss_val: 0.2289 acc_val: 0.5903 hloss_val: 0.0807 time: 2.3459s\n",
            "Epoch: 0037 loss_train: 0.1413 acc_train: 0.7604 hloss_train: 0.0441 loss_val: 0.2542 acc_val: 0.5538 hloss_val: 0.0909 time: 2.3491s\n",
            "Epoch: 0038 loss_train: 0.1353 acc_train: 0.7812 hloss_train: 0.0392 loss_val: 0.2240 acc_val: 0.6059 hloss_val: 0.0802 time: 2.3501s\n",
            "Epoch: 0039 loss_train: 0.1259 acc_train: 0.7562 hloss_train: 0.0431 loss_val: 0.2139 acc_val: 0.5938 hloss_val: 0.0796 time: 2.3506s\n",
            "Epoch: 0040 loss_train: 0.1277 acc_train: 0.7917 hloss_train: 0.0361 loss_val: 0.1967 acc_val: 0.6337 hloss_val: 0.0709 time: 2.3484s\n",
            "Epoch: 0041 loss_train: 0.1152 acc_train: 0.8208 hloss_train: 0.0316 loss_val: 0.2011 acc_val: 0.6892 hloss_val: 0.0616 time: 2.3543s\n",
            "Epoch: 0042 loss_train: 0.1064 acc_train: 0.8458 hloss_train: 0.0278 loss_val: 0.2056 acc_val: 0.6649 hloss_val: 0.0631 time: 2.3557s\n",
            "Epoch: 0043 loss_train: 0.0999 acc_train: 0.8500 hloss_train: 0.0264 loss_val: 0.1932 acc_val: 0.6771 hloss_val: 0.0657 time: 2.3534s\n",
            "Epoch: 0044 loss_train: 0.0972 acc_train: 0.8667 hloss_train: 0.0236 loss_val: 0.1587 acc_val: 0.7292 hloss_val: 0.0477 time: 2.3570s\n",
            "Epoch: 0045 loss_train: 0.0884 acc_train: 0.8750 hloss_train: 0.0215 loss_val: 0.1558 acc_val: 0.7049 hloss_val: 0.0518 time: 2.3559s\n",
            "Epoch: 0046 loss_train: 0.0821 acc_train: 0.9000 hloss_train: 0.0170 loss_val: 0.1332 acc_val: 0.7726 hloss_val: 0.0405 time: 2.3772s\n",
            "Epoch: 0047 loss_train: 0.0771 acc_train: 0.9167 hloss_train: 0.0139 loss_val: 0.1413 acc_val: 0.7986 hloss_val: 0.0454 time: 2.3573s\n",
            "Epoch: 0048 loss_train: 0.0771 acc_train: 0.9042 hloss_train: 0.0163 loss_val: 0.1701 acc_val: 0.7951 hloss_val: 0.0440 time: 2.3594s\n",
            "Epoch: 0049 loss_train: 0.0874 acc_train: 0.8812 hloss_train: 0.0201 loss_val: 0.1498 acc_val: 0.7865 hloss_val: 0.0475 time: 2.3582s\n",
            "Epoch: 0050 loss_train: 0.0725 acc_train: 0.9271 hloss_train: 0.0122 loss_val: 0.1331 acc_val: 0.7951 hloss_val: 0.0414 time: 2.3644s\n",
            "Epoch: 0051 loss_train: 0.0673 acc_train: 0.9542 hloss_train: 0.0076 loss_val: 0.1141 acc_val: 0.7517 hloss_val: 0.0512 time: 2.3635s\n",
            "Epoch: 0052 loss_train: 0.0614 acc_train: 0.9646 hloss_train: 0.0059 loss_val: 0.1075 acc_val: 0.7951 hloss_val: 0.0394 time: 2.3604s\n",
            "Epoch: 0053 loss_train: 0.0583 acc_train: 0.9688 hloss_train: 0.0052 loss_val: 0.1191 acc_val: 0.8108 hloss_val: 0.0362 time: 2.3612s\n",
            "Epoch: 0054 loss_train: 0.0569 acc_train: 0.9708 hloss_train: 0.0052 loss_val: 0.1021 acc_val: 0.8698 hloss_val: 0.0263 time: 2.3654s\n",
            "Epoch: 0055 loss_train: 0.0543 acc_train: 0.9771 hloss_train: 0.0038 loss_val: 0.1062 acc_val: 0.8264 hloss_val: 0.0336 time: 2.3646s\n",
            "Epoch: 0056 loss_train: 0.0514 acc_train: 0.9729 hloss_train: 0.0045 loss_val: 0.1022 acc_val: 0.8663 hloss_val: 0.0275 time: 2.3666s\n",
            "Epoch: 0057 loss_train: 0.0484 acc_train: 0.9833 hloss_train: 0.0028 loss_val: 0.0863 acc_val: 0.8507 hloss_val: 0.0321 time: 2.3659s\n",
            "Epoch: 0058 loss_train: 0.0496 acc_train: 0.9833 hloss_train: 0.0028 loss_val: 0.0824 acc_val: 0.8976 hloss_val: 0.0171 time: 2.3662s\n",
            "Epoch: 0059 loss_train: 0.0457 acc_train: 0.9708 hloss_train: 0.0049 loss_val: 0.0910 acc_val: 0.8663 hloss_val: 0.0321 time: 2.3663s\n",
            "Epoch: 0060 loss_train: 0.0465 acc_train: 0.9854 hloss_train: 0.0024 loss_val: 0.0872 acc_val: 0.8385 hloss_val: 0.0269 time: 2.3686s\n",
            "Epoch: 0061 loss_train: 0.0424 acc_train: 0.9833 hloss_train: 0.0028 loss_val: 0.0874 acc_val: 0.8576 hloss_val: 0.0237 time: 2.3671s\n",
            "Epoch: 0062 loss_train: 0.0423 acc_train: 0.9917 hloss_train: 0.0014 loss_val: 0.0771 acc_val: 0.8976 hloss_val: 0.0171 time: 2.3651s\n",
            "Epoch: 0063 loss_train: 0.0414 acc_train: 0.9917 hloss_train: 0.0014 loss_val: 0.0806 acc_val: 0.8628 hloss_val: 0.0229 time: 2.3717s\n",
            "Epoch: 0064 loss_train: 0.0404 acc_train: 0.9896 hloss_train: 0.0017 loss_val: 0.0839 acc_val: 0.8542 hloss_val: 0.0289 time: 2.3673s\n",
            "Epoch: 0065 loss_train: 0.0395 acc_train: 0.9958 hloss_train: 0.0007 loss_val: 0.0783 acc_val: 0.8663 hloss_val: 0.0269 time: 2.3716s\n",
            "Epoch: 0066 loss_train: 0.0408 acc_train: 0.9854 hloss_train: 0.0024 loss_val: 0.0810 acc_val: 0.8854 hloss_val: 0.0237 time: 2.3761s\n",
            "Epoch: 0067 loss_train: 0.0366 acc_train: 0.9958 hloss_train: 0.0007 loss_val: 0.0672 acc_val: 0.9097 hloss_val: 0.0177 time: 2.3675s\n",
            "Epoch: 0068 loss_train: 0.0343 acc_train: 0.9958 hloss_train: 0.0007 loss_val: 0.0707 acc_val: 0.9097 hloss_val: 0.0150 time: 2.3681s\n",
            "Epoch: 0069 loss_train: 0.0338 acc_train: 0.9979 hloss_train: 0.0003 loss_val: 0.0794 acc_val: 0.8854 hloss_val: 0.0191 time: 2.3697s\n",
            "Epoch: 0070 loss_train: 0.0340 acc_train: 0.9958 hloss_train: 0.0007 loss_val: 0.0811 acc_val: 0.8698 hloss_val: 0.0217 time: 2.3672s\n",
            "Epoch: 0071 loss_train: 0.0348 acc_train: 0.9958 hloss_train: 0.0007 loss_val: 0.0671 acc_val: 0.9253 hloss_val: 0.0150 time: 2.3678s\n",
            "Epoch: 0072 loss_train: 0.0351 acc_train: 0.9979 hloss_train: 0.0003 loss_val: 0.0693 acc_val: 0.9219 hloss_val: 0.0130 time: 2.3670s\n",
            "Epoch: 0073 loss_train: 0.0355 acc_train: 0.9917 hloss_train: 0.0014 loss_val: 0.0730 acc_val: 0.8976 hloss_val: 0.0171 time: 2.3669s\n",
            "Epoch: 0074 loss_train: 0.0321 acc_train: 0.9938 hloss_train: 0.0010 loss_val: 0.0647 acc_val: 0.8976 hloss_val: 0.0171 time: 2.3657s\n",
            "Epoch: 0075 loss_train: 0.0302 acc_train: 0.9938 hloss_train: 0.0010 loss_val: 0.0683 acc_val: 0.9097 hloss_val: 0.0150 time: 2.3665s\n",
            "Epoch: 0076 loss_train: 0.0308 acc_train: 0.9938 hloss_train: 0.0010 loss_val: 0.0671 acc_val: 0.9097 hloss_val: 0.0150 time: 2.3702s\n",
            "Epoch: 0077 loss_train: 0.0298 acc_train: 0.9979 hloss_train: 0.0003 loss_val: 0.0728 acc_val: 0.8976 hloss_val: 0.0171 time: 2.3684s\n",
            "Epoch: 0078 loss_train: 0.0286 acc_train: 1.0000 hloss_train: 0.0000 loss_val: 0.0617 acc_val: 0.8819 hloss_val: 0.0197 time: 2.3699s\n",
            "Epoch: 0079 loss_train: 0.0283 acc_train: 0.9958 hloss_train: 0.0007 loss_val: 0.0695 acc_val: 0.8663 hloss_val: 0.0223 time: 2.3691s\n",
            "Epoch: 0080 loss_train: 0.0284 acc_train: 1.0000 hloss_train: 0.0000 loss_val: 0.0670 acc_val: 0.8976 hloss_val: 0.0171 time: 2.3691s\n",
            "Epoch: 0081 loss_train: 0.0271 acc_train: 1.0000 hloss_train: 0.0000 loss_val: 0.0659 acc_val: 0.9132 hloss_val: 0.0145 time: 2.3697s\n",
            "Epoch: 0082 loss_train: 0.0287 acc_train: 1.0000 hloss_train: 0.0000 loss_val: 0.0629 acc_val: 0.8698 hloss_val: 0.0217 time: 2.3698s\n",
            "Epoch: 0083 loss_train: 0.0271 acc_train: 0.9979 hloss_train: 0.0003 loss_val: 0.0739 acc_val: 0.8576 hloss_val: 0.0237 time: 2.3671s\n",
            "Epoch: 0084 loss_train: 0.0272 acc_train: 1.0000 hloss_train: 0.0000 loss_val: 0.0648 acc_val: 0.8698 hloss_val: 0.0217 time: 2.3701s\n",
            "Epoch: 0085 loss_train: 0.0258 acc_train: 1.0000 hloss_train: 0.0000 loss_val: 0.0567 acc_val: 0.9097 hloss_val: 0.0150 time: 2.3694s\n",
            "Epoch: 0086 loss_train: 0.0266 acc_train: 0.9979 hloss_train: 0.0003 loss_val: 0.0586 acc_val: 0.8976 hloss_val: 0.0171 time: 2.3689s\n",
            "Epoch: 0087 loss_train: 0.0253 acc_train: 0.9979 hloss_train: 0.0003 loss_val: 0.0579 acc_val: 0.9219 hloss_val: 0.0130 time: 2.3692s\n",
            "Epoch: 0088 loss_train: 0.0244 acc_train: 0.9979 hloss_train: 0.0003 loss_val: 0.0657 acc_val: 0.9010 hloss_val: 0.0165 time: 2.3715s\n",
            "Epoch: 0089 loss_train: 0.0245 acc_train: 1.0000 hloss_train: 0.0000 loss_val: 0.0582 acc_val: 0.9132 hloss_val: 0.0145 time: 2.3681s\n",
            "Epoch: 0090 loss_train: 0.0248 acc_train: 1.0000 hloss_train: 0.0000 loss_val: 0.0582 acc_val: 0.9097 hloss_val: 0.0150 time: 2.3742s\n",
            "Epoch: 0091 loss_train: 0.0250 acc_train: 1.0000 hloss_train: 0.0000 loss_val: 0.0670 acc_val: 0.8854 hloss_val: 0.0191 time: 2.3689s\n",
            "Epoch: 0092 loss_train: 0.0224 acc_train: 1.0000 hloss_train: 0.0000 loss_val: 0.0579 acc_val: 0.8976 hloss_val: 0.0171 time: 2.3689s\n",
            "Epoch: 0093 loss_train: 0.0221 acc_train: 1.0000 hloss_train: 0.0000 loss_val: 0.0644 acc_val: 0.8976 hloss_val: 0.0171 time: 2.3706s\n",
            "Epoch: 0094 loss_train: 0.0220 acc_train: 1.0000 hloss_train: 0.0000 loss_val: 0.0573 acc_val: 0.8976 hloss_val: 0.0171 time: 2.3712s\n",
            "Epoch: 0095 loss_train: 0.0210 acc_train: 1.0000 hloss_train: 0.0000 loss_val: 0.0531 acc_val: 0.8976 hloss_val: 0.0171 time: 2.3700s\n",
            "Epoch: 0096 loss_train: 0.0205 acc_train: 1.0000 hloss_train: 0.0000 loss_val: 0.0636 acc_val: 0.8854 hloss_val: 0.0191 time: 2.3695s\n",
            "Epoch: 0097 loss_train: 0.0222 acc_train: 1.0000 hloss_train: 0.0000 loss_val: 0.0640 acc_val: 0.8976 hloss_val: 0.0171 time: 2.3708s\n",
            "Epoch: 0098 loss_train: 0.0220 acc_train: 0.9979 hloss_train: 0.0003 loss_val: 0.0526 acc_val: 0.8976 hloss_val: 0.0171 time: 2.3703s\n",
            "Epoch: 0099 loss_train: 0.0209 acc_train: 0.9979 hloss_train: 0.0003 loss_val: 0.0542 acc_val: 0.9097 hloss_val: 0.0150 time: 2.3706s\n",
            "Epoch: 0100 loss_train: 0.0210 acc_train: 1.0000 hloss_train: 0.0000 loss_val: 0.0510 acc_val: 0.8733 hloss_val: 0.0211 time: 2.3709s\n",
            "Epoch: 0101 loss_train: 0.0208 acc_train: 0.9979 hloss_train: 0.0003 loss_val: 0.0502 acc_val: 0.8976 hloss_val: 0.0171 time: 2.3702s\n",
            "Epoch: 0102 loss_train: 0.0199 acc_train: 1.0000 hloss_train: 0.0000 loss_val: 0.0468 acc_val: 0.8976 hloss_val: 0.0171 time: 2.3718s\n",
            "Epoch: 0103 loss_train: 0.0200 acc_train: 0.9958 hloss_train: 0.0007 loss_val: 0.0463 acc_val: 0.9253 hloss_val: 0.0124 time: 2.3715s\n",
            "Epoch: 0104 loss_train: 0.0185 acc_train: 1.0000 hloss_train: 0.0000 loss_val: 0.0487 acc_val: 0.9132 hloss_val: 0.0145 time: 2.3713s\n",
            "Epoch: 0105 loss_train: 0.0185 acc_train: 1.0000 hloss_train: 0.0000 loss_val: 0.0396 acc_val: 0.9375 hloss_val: 0.0104 time: 2.3722s\n",
            "Epoch: 0106 loss_train: 0.0185 acc_train: 1.0000 hloss_train: 0.0000 loss_val: 0.0509 acc_val: 0.9132 hloss_val: 0.0145 time: 2.3721s\n",
            "Epoch: 0107 loss_train: 0.0184 acc_train: 1.0000 hloss_train: 0.0000 loss_val: 0.0470 acc_val: 0.8854 hloss_val: 0.0191 time: 2.3716s\n",
            "Epoch: 0108 loss_train: 0.0181 acc_train: 1.0000 hloss_train: 0.0000 loss_val: 0.0484 acc_val: 0.9132 hloss_val: 0.0145 time: 2.3710s\n",
            "Epoch: 0109 loss_train: 0.0184 acc_train: 1.0000 hloss_train: 0.0000 loss_val: 0.0415 acc_val: 0.9375 hloss_val: 0.0104 time: 2.3730s\n",
            "Epoch: 0110 loss_train: 0.0206 acc_train: 0.9958 hloss_train: 0.0007 loss_val: 0.0451 acc_val: 0.8819 hloss_val: 0.0197 time: 2.3720s\n",
            "Epoch: 0111 loss_train: 0.0189 acc_train: 1.0000 hloss_train: 0.0000 loss_val: 0.0504 acc_val: 0.8733 hloss_val: 0.0211 time: 2.3706s\n",
            "Epoch: 0112 loss_train: 0.0172 acc_train: 1.0000 hloss_train: 0.0000 loss_val: 0.0393 acc_val: 0.9097 hloss_val: 0.0150 time: 2.3714s\n",
            "Epoch: 0113 loss_train: 0.0170 acc_train: 1.0000 hloss_train: 0.0000 loss_val: 0.0388 acc_val: 0.9219 hloss_val: 0.0130 time: 2.3706s\n",
            "Epoch: 0114 loss_train: 0.0170 acc_train: 1.0000 hloss_train: 0.0000 loss_val: 0.0383 acc_val: 0.9253 hloss_val: 0.0124 time: 2.3700s\n",
            "Epoch: 0115 loss_train: 0.0180 acc_train: 1.0000 hloss_train: 0.0000 loss_val: 0.0432 acc_val: 0.8976 hloss_val: 0.0171 time: 2.3736s\n",
            "Epoch: 0116 loss_train: 0.0196 acc_train: 0.9938 hloss_train: 0.0010 loss_val: 0.0505 acc_val: 0.8819 hloss_val: 0.0197 time: 2.3696s\n",
            "Epoch: 0117 loss_train: 0.0169 acc_train: 1.0000 hloss_train: 0.0000 loss_val: 0.0413 acc_val: 0.9288 hloss_val: 0.0119 time: 2.3724s\n",
            "Epoch: 0118 loss_train: 0.0161 acc_train: 1.0000 hloss_train: 0.0000 loss_val: 0.0387 acc_val: 0.9132 hloss_val: 0.0145 time: 2.3738s\n",
            "Epoch: 0119 loss_train: 0.0160 acc_train: 1.0000 hloss_train: 0.0000 loss_val: 0.0435 acc_val: 0.8854 hloss_val: 0.0191 time: 2.3720s\n",
            "Epoch: 0120 loss_train: 0.0155 acc_train: 1.0000 hloss_train: 0.0000 loss_val: 0.0380 acc_val: 0.9132 hloss_val: 0.0145 time: 2.3729s\n",
            "Epoch: 0121 loss_train: 0.0158 acc_train: 1.0000 hloss_train: 0.0000 loss_val: 0.0373 acc_val: 0.9097 hloss_val: 0.0150 time: 2.3720s\n",
            "Epoch: 0122 loss_train: 0.0150 acc_train: 1.0000 hloss_train: 0.0000 loss_val: 0.0396 acc_val: 0.9132 hloss_val: 0.0145 time: 2.3714s\n",
            "Epoch: 0123 loss_train: 0.0161 acc_train: 1.0000 hloss_train: 0.0000 loss_val: 0.0359 acc_val: 0.9253 hloss_val: 0.0124 time: 2.3724s\n",
            "Epoch: 0124 loss_train: 0.0154 acc_train: 1.0000 hloss_train: 0.0000 loss_val: 0.0466 acc_val: 0.8854 hloss_val: 0.0191 time: 2.3709s\n",
            "Epoch: 0125 loss_train: 0.0153 acc_train: 1.0000 hloss_train: 0.0000 loss_val: 0.0388 acc_val: 0.9132 hloss_val: 0.0145 time: 2.3695s\n",
            "Epoch: 0126 loss_train: 0.0155 acc_train: 1.0000 hloss_train: 0.0000 loss_val: 0.0328 acc_val: 0.9253 hloss_val: 0.0124 time: 2.3705s\n",
            "Epoch: 0127 loss_train: 0.0141 acc_train: 1.0000 hloss_train: 0.0000 loss_val: 0.0401 acc_val: 0.8854 hloss_val: 0.0191 time: 2.3718s\n",
            "Epoch: 0128 loss_train: 0.0141 acc_train: 1.0000 hloss_train: 0.0000 loss_val: 0.0398 acc_val: 0.9288 hloss_val: 0.0119 time: 2.3718s\n",
            "Epoch: 0129 loss_train: 0.0144 acc_train: 1.0000 hloss_train: 0.0000 loss_val: 0.0368 acc_val: 0.9097 hloss_val: 0.0150 time: 2.3701s\n",
            "Epoch: 0130 loss_train: 0.0131 acc_train: 1.0000 hloss_train: 0.0000 loss_val: 0.0317 acc_val: 0.9688 hloss_val: 0.0052 time: 2.3721s\n",
            "Epoch: 0131 loss_train: 0.0141 acc_train: 1.0000 hloss_train: 0.0000 loss_val: 0.0364 acc_val: 0.9097 hloss_val: 0.0150 time: 2.3743s\n",
            "Epoch: 0132 loss_train: 0.0140 acc_train: 1.0000 hloss_train: 0.0000 loss_val: 0.0335 acc_val: 0.9253 hloss_val: 0.0124 time: 2.3728s\n",
            "Epoch: 0133 loss_train: 0.0136 acc_train: 1.0000 hloss_train: 0.0000 loss_val: 0.0338 acc_val: 0.9253 hloss_val: 0.0124 time: 2.3700s\n",
            "Epoch: 0134 loss_train: 0.0133 acc_train: 1.0000 hloss_train: 0.0000 loss_val: 0.0355 acc_val: 0.9132 hloss_val: 0.0145 time: 2.3713s\n",
            "Epoch: 0135 loss_train: 0.0131 acc_train: 1.0000 hloss_train: 0.0000 loss_val: 0.0380 acc_val: 0.8976 hloss_val: 0.0171 time: 2.3720s\n",
            "Epoch: 0136 loss_train: 0.0136 acc_train: 1.0000 hloss_train: 0.0000 loss_val: 0.0328 acc_val: 0.9253 hloss_val: 0.0124 time: 2.3735s\n",
            "Epoch: 0137 loss_train: 0.0132 acc_train: 1.0000 hloss_train: 0.0000 loss_val: 0.0298 acc_val: 0.9375 hloss_val: 0.0104 time: 2.3725s\n",
            "Epoch: 0138 loss_train: 0.0128 acc_train: 1.0000 hloss_train: 0.0000 loss_val: 0.0341 acc_val: 0.9253 hloss_val: 0.0124 time: 2.3714s\n",
            "Epoch: 0139 loss_train: 0.0130 acc_train: 1.0000 hloss_train: 0.0000 loss_val: 0.0355 acc_val: 0.8976 hloss_val: 0.0171 time: 2.3738s\n",
            "Epoch: 0140 loss_train: 0.0121 acc_train: 1.0000 hloss_train: 0.0000 loss_val: 0.0346 acc_val: 0.9253 hloss_val: 0.0124 time: 2.3730s\n",
            "Epoch: 0141 loss_train: 0.0122 acc_train: 1.0000 hloss_train: 0.0000 loss_val: 0.0363 acc_val: 0.9132 hloss_val: 0.0145 time: 2.3747s\n",
            "Epoch: 0142 loss_train: 0.0118 acc_train: 1.0000 hloss_train: 0.0000 loss_val: 0.0307 acc_val: 0.9375 hloss_val: 0.0104 time: 2.3714s\n",
            "Epoch: 0143 loss_train: 0.0120 acc_train: 1.0000 hloss_train: 0.0000 loss_val: 0.0355 acc_val: 0.9132 hloss_val: 0.0145 time: 2.3707s\n",
            "Epoch: 0144 loss_train: 0.0113 acc_train: 1.0000 hloss_train: 0.0000 loss_val: 0.0318 acc_val: 0.9253 hloss_val: 0.0124 time: 2.3716s\n",
            "Epoch: 0145 loss_train: 0.0120 acc_train: 1.0000 hloss_train: 0.0000 loss_val: 0.0336 acc_val: 0.9132 hloss_val: 0.0145 time: 2.3732s\n",
            "Epoch: 0146 loss_train: 0.0120 acc_train: 1.0000 hloss_train: 0.0000 loss_val: 0.0386 acc_val: 0.9010 hloss_val: 0.0165 time: 2.3700s\n",
            "Early Stopping...\n",
            "Total train time: 345.3841s\n",
            "\n",
            "==================================================\n",
            "TextGCN->BERT x TEC\n",
            "==================================================\n",
            "Accuracy Score: 0.9920\n",
            "F1 Score (Micro): 0.9971\n",
            "F1 Score (Macro): 0.9976\n",
            "F1 Score (Weighted): 0.9971\n",
            "Hamming Loss: 0.0013\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "       anger     1.0000    1.0000    1.0000       172\n",
            "     disgust     1.0000    1.0000    1.0000        37\n",
            "        fear     1.0000    1.0000    1.0000        67\n",
            "     sadness     0.9939    0.9939    0.9939       163\n",
            "    surprise     1.0000    0.9897    0.9948        97\n",
            "       other     0.9933    1.0000    0.9966       148\n",
            "\n",
            "   micro avg     0.9971    0.9971    0.9971       684\n",
            "   macro avg     0.9979    0.9973    0.9976       684\n",
            "weighted avg     0.9971    0.9971    0.9971       684\n",
            " samples avg     0.7663    0.7660    0.7656       684\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/home/rcmcabral/.local/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in samples with no predicted labels. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/home/rcmcabral/.local/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in samples with no true labels. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        }
      ],
      "source": [
        "lexName = \"TEC\"\n",
        "title1 = \"TextGCN x \" + lexName\n",
        "title2 = \"TextGCN->BERT x \" + lexName\n",
        "texts = original_train_sentences\n",
        "\n",
        "lexTokens = tec_allTokens\n",
        "lexLabels = tec_allEmotions\n",
        "lexClassNames = tec_labels\n",
        "\n",
        "#Populate document multilabel emotions\n",
        "emoLabels, num_emoClass = encodeDocEmotions(lexTokens, lexLabels, tokenize_sentences)\n",
        "original_emoLabels_train = emoLabels[:train_size]\n",
        "emoLabels = torch.FloatTensor(emoLabels).to(device)\n",
        "\n",
        "doc_embeddings, word_embeddings = train_GCNBert()\n",
        "\n",
        "# saveWeights(\"./_OUTPUT/DocEmbeddings_\" + tokenTitle + \"Embeddings\" +  \".pkl\", texts, doc_embeddings, lexLabels, original_train_labels, lexClassNames)\n",
        "saveWordEmbeddings(\"./_OUTPUT/MMEMOG_\" + tokenTitle + \"Embeddings_\" + lexName + \".pkl\", vocab, word_embeddings)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DVOKJR6EwZfM"
      },
      "source": [
        "##SenticNet"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 180,
      "metadata": {
        "id": "HKpoPezUwZfM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7ab081d9-20a8-477e-ee15-ccf557b95ace"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 0001 loss_train: 0.6891 acc_train: 0.3533 hloss_train: 0.2744 loss_val: 0.5905 acc_val: 0.5600 hloss_val: 0.1700 time: 0.0102s\n",
            "Epoch: 0002 loss_train: 0.6137 acc_train: 0.3533 hloss_train: 0.2744 loss_val: 0.4793 acc_val: 0.2200 hloss_val: 0.1967 time: 0.0098s\n",
            "Epoch: 0003 loss_train: 0.6613 acc_train: 0.2444 hloss_train: 0.2678 loss_val: 0.4243 acc_val: 0.5600 hloss_val: 0.1700 time: 0.0094s\n",
            "Epoch: 0004 loss_train: 0.5405 acc_train: 0.3533 hloss_train: 0.2744 loss_val: 0.5022 acc_val: 0.5600 hloss_val: 0.1700 time: 0.0093s\n",
            "Epoch: 0005 loss_train: 0.5483 acc_train: 0.3533 hloss_train: 0.2744 loss_val: 0.5265 acc_val: 0.5600 hloss_val: 0.1700 time: 0.0094s\n",
            "Epoch: 0006 loss_train: 0.5547 acc_train: 0.3533 hloss_train: 0.2744 loss_val: 0.4906 acc_val: 0.5600 hloss_val: 0.1700 time: 0.0093s\n",
            "Epoch: 0007 loss_train: 0.5324 acc_train: 0.3533 hloss_train: 0.2744 loss_val: 0.4333 acc_val: 0.5600 hloss_val: 0.1700 time: 0.0094s\n",
            "Epoch: 0008 loss_train: 0.5106 acc_train: 0.3533 hloss_train: 0.2744 loss_val: 0.4041 acc_val: 0.5600 hloss_val: 0.1700 time: 0.0093s\n",
            "Epoch: 0009 loss_train: 0.5075 acc_train: 0.3533 hloss_train: 0.2737 loss_val: 0.4101 acc_val: 0.4400 hloss_val: 0.1600 time: 0.0097s\n",
            "Epoch: 0010 loss_train: 0.5077 acc_train: 0.3889 hloss_train: 0.2433 loss_val: 0.4106 acc_val: 0.4600 hloss_val: 0.1600 time: 0.0101s\n",
            "Epoch: 0011 loss_train: 0.4962 acc_train: 0.4133 hloss_train: 0.2374 loss_val: 0.4124 acc_val: 0.5600 hloss_val: 0.1667 time: 0.0096s\n",
            "Epoch: 0012 loss_train: 0.4909 acc_train: 0.4200 hloss_train: 0.2519 loss_val: 0.4208 acc_val: 0.5600 hloss_val: 0.1700 time: 0.0094s\n",
            "Epoch: 0013 loss_train: 0.4931 acc_train: 0.3600 hloss_train: 0.2707 loss_val: 0.4286 acc_val: 0.5600 hloss_val: 0.1700 time: 0.0094s\n",
            "Epoch: 0014 loss_train: 0.4907 acc_train: 0.3711 hloss_train: 0.2678 loss_val: 0.4285 acc_val: 0.5800 hloss_val: 0.1667 time: 0.0096s\n",
            "Epoch: 0015 loss_train: 0.4841 acc_train: 0.4200 hloss_train: 0.2533 loss_val: 0.4213 acc_val: 0.5800 hloss_val: 0.1600 time: 0.0095s\n",
            "Epoch: 0016 loss_train: 0.4747 acc_train: 0.4911 hloss_train: 0.2222 loss_val: 0.4019 acc_val: 0.5400 hloss_val: 0.1600 time: 0.0095s\n",
            "Epoch: 0017 loss_train: 0.4694 acc_train: 0.4822 hloss_train: 0.2237 loss_val: 0.3960 acc_val: 0.5200 hloss_val: 0.1533 time: 0.0094s\n",
            "Epoch: 0018 loss_train: 0.4630 acc_train: 0.4822 hloss_train: 0.2204 loss_val: 0.3819 acc_val: 0.5800 hloss_val: 0.1500 time: 0.0094s\n",
            "Epoch: 0019 loss_train: 0.4537 acc_train: 0.4911 hloss_train: 0.2204 loss_val: 0.3859 acc_val: 0.5600 hloss_val: 0.1633 time: 0.0094s\n",
            "Epoch: 0020 loss_train: 0.4360 acc_train: 0.5089 hloss_train: 0.2167 loss_val: 0.3967 acc_val: 0.5600 hloss_val: 0.1500 time: 0.0094s\n",
            "Epoch: 0021 loss_train: 0.4214 acc_train: 0.4778 hloss_train: 0.2085 loss_val: 0.3806 acc_val: 0.5600 hloss_val: 0.1500 time: 0.0094s\n",
            "Epoch: 0022 loss_train: 0.4116 acc_train: 0.4778 hloss_train: 0.2056 loss_val: 0.3500 acc_val: 0.5400 hloss_val: 0.1533 time: 0.0094s\n",
            "Epoch: 0023 loss_train: 0.4107 acc_train: 0.4733 hloss_train: 0.2093 loss_val: 0.4906 acc_val: 0.3200 hloss_val: 0.1733 time: 0.0097s\n",
            "Epoch: 0024 loss_train: 0.4672 acc_train: 0.3267 hloss_train: 0.1959 loss_val: 0.3557 acc_val: 0.5600 hloss_val: 0.1633 time: 0.0097s\n",
            "Epoch: 0025 loss_train: 0.4094 acc_train: 0.4489 hloss_train: 0.2070 loss_val: 0.3750 acc_val: 0.5400 hloss_val: 0.1633 time: 0.0095s\n",
            "Epoch: 0026 loss_train: 0.4176 acc_train: 0.4133 hloss_train: 0.2078 loss_val: 0.4453 acc_val: 0.4600 hloss_val: 0.1533 time: 0.0095s\n",
            "Epoch: 0027 loss_train: 0.4023 acc_train: 0.4778 hloss_train: 0.1622 loss_val: 0.4093 acc_val: 0.4800 hloss_val: 0.1333 time: 0.0096s\n",
            "Epoch: 0028 loss_train: 0.3937 acc_train: 0.4733 hloss_train: 0.1619 loss_val: 0.3252 acc_val: 0.5600 hloss_val: 0.1400 time: 0.0095s\n",
            "Epoch: 0029 loss_train: 0.3857 acc_train: 0.5067 hloss_train: 0.1922 loss_val: 0.3237 acc_val: 0.5600 hloss_val: 0.1367 time: 0.0094s\n",
            "Epoch: 0030 loss_train: 0.3690 acc_train: 0.5044 hloss_train: 0.1689 loss_val: 0.3674 acc_val: 0.4800 hloss_val: 0.1433 time: 0.0093s\n",
            "Epoch: 0031 loss_train: 0.3758 acc_train: 0.4422 hloss_train: 0.1604 loss_val: 0.4029 acc_val: 0.4600 hloss_val: 0.1567 time: 0.0092s\n",
            "Epoch: 0032 loss_train: 0.3627 acc_train: 0.4778 hloss_train: 0.1504 loss_val: 0.3539 acc_val: 0.6000 hloss_val: 0.1167 time: 0.0092s\n",
            "Epoch: 0033 loss_train: 0.3416 acc_train: 0.5511 hloss_train: 0.1504 loss_val: 0.3439 acc_val: 0.5800 hloss_val: 0.1333 time: 0.0093s\n",
            "Epoch: 0034 loss_train: 0.3815 acc_train: 0.5222 hloss_train: 0.1848 loss_val: 0.3399 acc_val: 0.5800 hloss_val: 0.1167 time: 0.0092s\n",
            "Epoch: 0035 loss_train: 0.3263 acc_train: 0.5578 hloss_train: 0.1426 loss_val: 0.4085 acc_val: 0.4600 hloss_val: 0.1467 time: 0.0092s\n",
            "Epoch: 0036 loss_train: 0.3395 acc_train: 0.5089 hloss_train: 0.1370 loss_val: 0.3563 acc_val: 0.4800 hloss_val: 0.1400 time: 0.0092s\n",
            "Epoch: 0037 loss_train: 0.3190 acc_train: 0.5489 hloss_train: 0.1307 loss_val: 0.2980 acc_val: 0.5400 hloss_val: 0.1167 time: 0.0091s\n",
            "Epoch: 0038 loss_train: 0.3267 acc_train: 0.5533 hloss_train: 0.1426 loss_val: 0.2956 acc_val: 0.5400 hloss_val: 0.1200 time: 0.0092s\n",
            "Epoch: 0039 loss_train: 0.3215 acc_train: 0.5556 hloss_train: 0.1485 loss_val: 0.3843 acc_val: 0.5000 hloss_val: 0.1567 time: 0.0091s\n",
            "Epoch: 0040 loss_train: 0.3072 acc_train: 0.5267 hloss_train: 0.1326 loss_val: 0.4146 acc_val: 0.5000 hloss_val: 0.1567 time: 0.0091s\n",
            "Epoch: 0041 loss_train: 0.3157 acc_train: 0.5378 hloss_train: 0.1278 loss_val: 0.3204 acc_val: 0.5800 hloss_val: 0.1133 time: 0.0091s\n",
            "Epoch: 0042 loss_train: 0.2982 acc_train: 0.5844 hloss_train: 0.1337 loss_val: 0.3068 acc_val: 0.6000 hloss_val: 0.1167 time: 0.0091s\n",
            "Epoch: 0043 loss_train: 0.3009 acc_train: 0.5689 hloss_train: 0.1419 loss_val: 0.3384 acc_val: 0.5200 hloss_val: 0.1400 time: 0.0092s\n",
            "Epoch: 0044 loss_train: 0.2836 acc_train: 0.5600 hloss_train: 0.1337 loss_val: 0.3845 acc_val: 0.5400 hloss_val: 0.1500 time: 0.0091s\n",
            "Epoch: 0045 loss_train: 0.2854 acc_train: 0.5644 hloss_train: 0.1181 loss_val: 0.3376 acc_val: 0.5600 hloss_val: 0.1267 time: 0.0094s\n",
            "Epoch: 0046 loss_train: 0.2673 acc_train: 0.5800 hloss_train: 0.1137 loss_val: 0.2966 acc_val: 0.6000 hloss_val: 0.1167 time: 0.0095s\n",
            "Epoch: 0047 loss_train: 0.2810 acc_train: 0.5822 hloss_train: 0.1311 loss_val: 0.2984 acc_val: 0.5600 hloss_val: 0.1200 time: 0.0092s\n",
            "Epoch: 0048 loss_train: 0.2848 acc_train: 0.5978 hloss_train: 0.1326 loss_val: 0.3929 acc_val: 0.5000 hloss_val: 0.1433 time: 0.0093s\n",
            "Early Stopping...\n",
            "Total train time: 0.4533s\n",
            "\n",
            "==================================================\n",
            "TextGCN x SenticNet\n",
            "==================================================\n",
            "Accuracy Score: 0.5460\n",
            "F1 Score (Micro): 0.7698\n",
            "F1 Score (Macro): 0.5624\n",
            "F1 Score (Weighted): 0.7293\n",
            "Hamming Loss: 0.1170\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "       anger     0.5000    0.0303    0.0571        33\n",
            "     disgust     0.6429    0.3600    0.4615       100\n",
            "        fear     0.7222    0.1781    0.2857        73\n",
            "     sadness     0.7027    0.9353    0.8025       139\n",
            "    negative     0.7635    0.9583    0.8499       192\n",
            "       other     0.9654    0.8745    0.9177       255\n",
            "\n",
            "   micro avg     0.8008    0.7412    0.7698       792\n",
            "   macro avg     0.7161    0.5561    0.5624       792\n",
            "weighted avg     0.7878    0.7412    0.7293       792\n",
            " samples avg     0.4984    0.4786    0.4724       792\n",
            "\n",
            "Max sequence length: 84\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/home/rcmcabral/.local/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in samples with no predicted labels. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/home/rcmcabral/.local/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in samples with no true labels. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 0001 loss_train: 0.5427 acc_train: 0.3000 hloss_train: 0.2701 loss_val: 0.4014 acc_val: 0.5833 hloss_val: 0.1612 time: 2.3469s\n",
            "Epoch: 0002 loss_train: 0.5515 acc_train: 0.3104 hloss_train: 0.2885 loss_val: 0.4231 acc_val: 0.5469 hloss_val: 0.1713 time: 2.3539s\n",
            "Epoch: 0003 loss_train: 0.5354 acc_train: 0.3500 hloss_train: 0.2660 loss_val: 0.4221 acc_val: 0.5226 hloss_val: 0.1875 time: 2.3554s\n",
            "Epoch: 0004 loss_train: 0.5357 acc_train: 0.3750 hloss_train: 0.2601 loss_val: 0.4102 acc_val: 0.6181 hloss_val: 0.1296 time: 2.3596s\n",
            "Epoch: 0005 loss_train: 0.5361 acc_train: 0.3479 hloss_train: 0.2767 loss_val: 0.4061 acc_val: 0.5955 hloss_val: 0.1571 time: 2.3581s\n",
            "Epoch: 0006 loss_train: 0.5089 acc_train: 0.3979 hloss_train: 0.2510 loss_val: 0.4105 acc_val: 0.5747 hloss_val: 0.1490 time: 2.3586s\n",
            "Epoch: 0007 loss_train: 0.5122 acc_train: 0.3729 hloss_train: 0.2479 loss_val: 0.3852 acc_val: 0.5747 hloss_val: 0.1409 time: 2.3598s\n",
            "Epoch: 0008 loss_train: 0.5174 acc_train: 0.3875 hloss_train: 0.2500 loss_val: 0.4176 acc_val: 0.5122 hloss_val: 0.1476 time: 2.3599s\n",
            "Epoch: 0009 loss_train: 0.5211 acc_train: 0.3583 hloss_train: 0.2594 loss_val: 0.3845 acc_val: 0.5469 hloss_val: 0.1455 time: 2.3596s\n",
            "Epoch: 0010 loss_train: 0.5019 acc_train: 0.3312 hloss_train: 0.2396 loss_val: 0.3838 acc_val: 0.6458 hloss_val: 0.1392 time: 2.3617s\n",
            "Epoch: 0011 loss_train: 0.5122 acc_train: 0.3542 hloss_train: 0.2535 loss_val: 0.4248 acc_val: 0.3819 hloss_val: 0.1652 time: 2.3620s\n",
            "Epoch: 0012 loss_train: 0.5228 acc_train: 0.3292 hloss_train: 0.2573 loss_val: 0.3835 acc_val: 0.6024 hloss_val: 0.1403 time: 2.3602s\n",
            "Epoch: 0013 loss_train: 0.4874 acc_train: 0.3937 hloss_train: 0.2330 loss_val: 0.3827 acc_val: 0.6493 hloss_val: 0.1505 time: 2.3627s\n",
            "Epoch: 0014 loss_train: 0.5054 acc_train: 0.3479 hloss_train: 0.2465 loss_val: 0.3991 acc_val: 0.5208 hloss_val: 0.1386 time: 2.3647s\n",
            "Epoch: 0015 loss_train: 0.4777 acc_train: 0.4271 hloss_train: 0.2306 loss_val: 0.4096 acc_val: 0.4757 hloss_val: 0.1623 time: 2.3630s\n",
            "Epoch: 0016 loss_train: 0.4742 acc_train: 0.3896 hloss_train: 0.2354 loss_val: 0.3751 acc_val: 0.5278 hloss_val: 0.1508 time: 2.3670s\n",
            "Epoch: 0017 loss_train: 0.4658 acc_train: 0.3750 hloss_train: 0.2240 loss_val: 0.3814 acc_val: 0.4497 hloss_val: 0.1461 time: 2.3641s\n",
            "Epoch: 0018 loss_train: 0.4447 acc_train: 0.3833 hloss_train: 0.2128 loss_val: 0.3938 acc_val: 0.4167 hloss_val: 0.1531 time: 2.3636s\n",
            "Epoch: 0019 loss_train: 0.4257 acc_train: 0.3771 hloss_train: 0.1979 loss_val: 0.3124 acc_val: 0.6389 hloss_val: 0.1027 time: 2.3638s\n",
            "Epoch: 0020 loss_train: 0.4263 acc_train: 0.4021 hloss_train: 0.1924 loss_val: 0.3485 acc_val: 0.5781 hloss_val: 0.1241 time: 2.3669s\n",
            "Epoch: 0021 loss_train: 0.4470 acc_train: 0.3979 hloss_train: 0.1962 loss_val: 0.4345 acc_val: 0.4253 hloss_val: 0.1522 time: 2.3673s\n",
            "Epoch: 0022 loss_train: 0.4279 acc_train: 0.3771 hloss_train: 0.1972 loss_val: 0.3083 acc_val: 0.6615 hloss_val: 0.1149 time: 2.3693s\n",
            "Epoch: 0023 loss_train: 0.3980 acc_train: 0.4771 hloss_train: 0.1712 loss_val: 0.3259 acc_val: 0.6302 hloss_val: 0.1102 time: 2.3674s\n",
            "Epoch: 0024 loss_train: 0.3730 acc_train: 0.4562 hloss_train: 0.1583 loss_val: 0.3155 acc_val: 0.6424 hloss_val: 0.1128 time: 2.3665s\n",
            "Epoch: 0025 loss_train: 0.3531 acc_train: 0.4562 hloss_train: 0.1549 loss_val: 0.3489 acc_val: 0.4757 hloss_val: 0.1319 time: 2.3678s\n",
            "Epoch: 0026 loss_train: 0.3280 acc_train: 0.4917 hloss_train: 0.1458 loss_val: 0.2771 acc_val: 0.6458 hloss_val: 0.1030 time: 2.3690s\n",
            "Epoch: 0027 loss_train: 0.3166 acc_train: 0.4708 hloss_train: 0.1389 loss_val: 0.2573 acc_val: 0.6580 hloss_val: 0.0891 time: 2.3658s\n",
            "Epoch: 0028 loss_train: 0.3071 acc_train: 0.4604 hloss_train: 0.1424 loss_val: 0.4022 acc_val: 0.3785 hloss_val: 0.1369 time: 2.3674s\n",
            "Epoch: 0029 loss_train: 0.3428 acc_train: 0.4396 hloss_train: 0.1618 loss_val: 0.6218 acc_val: 0.3316 hloss_val: 0.2419 time: 2.3699s\n",
            "Epoch: 0030 loss_train: 0.3800 acc_train: 0.4333 hloss_train: 0.1580 loss_val: 0.3298 acc_val: 0.4601 hloss_val: 0.1117 time: 2.3677s\n",
            "Epoch: 0031 loss_train: 0.2829 acc_train: 0.4979 hloss_train: 0.1264 loss_val: 0.2774 acc_val: 0.5833 hloss_val: 0.0964 time: 2.3672s\n",
            "Epoch: 0032 loss_train: 0.2775 acc_train: 0.5188 hloss_train: 0.1156 loss_val: 0.2252 acc_val: 0.6181 hloss_val: 0.0854 time: 2.3694s\n",
            "Epoch: 0033 loss_train: 0.2538 acc_train: 0.5542 hloss_train: 0.1073 loss_val: 0.2001 acc_val: 0.7049 hloss_val: 0.0694 time: 2.3683s\n",
            "Epoch: 0034 loss_train: 0.2579 acc_train: 0.4938 hloss_train: 0.1187 loss_val: 0.2214 acc_val: 0.6528 hloss_val: 0.0723 time: 2.3697s\n",
            "Epoch: 0035 loss_train: 0.2333 acc_train: 0.6000 hloss_train: 0.0899 loss_val: 0.2187 acc_val: 0.6024 hloss_val: 0.0833 time: 2.3714s\n",
            "Epoch: 0036 loss_train: 0.2222 acc_train: 0.5958 hloss_train: 0.0858 loss_val: 0.2036 acc_val: 0.6059 hloss_val: 0.0735 time: 2.3698s\n",
            "Epoch: 0037 loss_train: 0.2088 acc_train: 0.5854 hloss_train: 0.0847 loss_val: 0.2115 acc_val: 0.6580 hloss_val: 0.0642 time: 2.3686s\n",
            "Epoch: 0038 loss_train: 0.1988 acc_train: 0.6312 hloss_train: 0.0740 loss_val: 0.1729 acc_val: 0.7882 hloss_val: 0.0379 time: 2.3682s\n",
            "Epoch: 0039 loss_train: 0.1795 acc_train: 0.6937 hloss_train: 0.0646 loss_val: 0.2418 acc_val: 0.6094 hloss_val: 0.0775 time: 2.3711s\n",
            "Epoch: 0040 loss_train: 0.1716 acc_train: 0.6937 hloss_train: 0.0604 loss_val: 0.2627 acc_val: 0.6302 hloss_val: 0.0781 time: 2.3683s\n",
            "Epoch: 0041 loss_train: 0.1498 acc_train: 0.7396 hloss_train: 0.0497 loss_val: 0.2200 acc_val: 0.6302 hloss_val: 0.0663 time: 2.3703s\n",
            "Epoch: 0042 loss_train: 0.1481 acc_train: 0.7063 hloss_train: 0.0542 loss_val: 0.2315 acc_val: 0.6892 hloss_val: 0.0637 time: 2.3720s\n",
            "Epoch: 0043 loss_train: 0.1426 acc_train: 0.7562 hloss_train: 0.0458 loss_val: 0.1906 acc_val: 0.7014 hloss_val: 0.0550 time: 2.3699s\n",
            "Epoch: 0044 loss_train: 0.1335 acc_train: 0.7458 hloss_train: 0.0465 loss_val: 0.1883 acc_val: 0.6806 hloss_val: 0.0558 time: 2.3691s\n",
            "Epoch: 0045 loss_train: 0.1227 acc_train: 0.8187 hloss_train: 0.0351 loss_val: 0.1376 acc_val: 0.7726 hloss_val: 0.0405 time: 2.3726s\n",
            "Epoch: 0046 loss_train: 0.1189 acc_train: 0.8333 hloss_train: 0.0316 loss_val: 0.1630 acc_val: 0.6493 hloss_val: 0.0663 time: 2.3703s\n",
            "Epoch: 0047 loss_train: 0.1060 acc_train: 0.8333 hloss_train: 0.0316 loss_val: 0.1545 acc_val: 0.7326 hloss_val: 0.0498 time: 2.3700s\n",
            "Epoch: 0048 loss_train: 0.1038 acc_train: 0.8542 hloss_train: 0.0257 loss_val: 0.1707 acc_val: 0.6927 hloss_val: 0.0564 time: 2.3727s\n",
            "Epoch: 0049 loss_train: 0.1003 acc_train: 0.8250 hloss_train: 0.0316 loss_val: 0.2182 acc_val: 0.6927 hloss_val: 0.0651 time: 2.3713s\n",
            "Epoch: 0050 loss_train: 0.0992 acc_train: 0.8729 hloss_train: 0.0236 loss_val: 0.1778 acc_val: 0.7448 hloss_val: 0.0477 time: 2.3732s\n",
            "Epoch: 0051 loss_train: 0.0939 acc_train: 0.9062 hloss_train: 0.0177 loss_val: 0.1396 acc_val: 0.7517 hloss_val: 0.0440 time: 2.3696s\n",
            "Epoch: 0052 loss_train: 0.1024 acc_train: 0.8417 hloss_train: 0.0312 loss_val: 0.1536 acc_val: 0.7483 hloss_val: 0.0472 time: 2.3699s\n",
            "Epoch: 0053 loss_train: 0.0848 acc_train: 0.9000 hloss_train: 0.0181 loss_val: 0.1483 acc_val: 0.7517 hloss_val: 0.0440 time: 2.3721s\n",
            "Epoch: 0054 loss_train: 0.0760 acc_train: 0.9062 hloss_train: 0.0177 loss_val: 0.1923 acc_val: 0.6736 hloss_val: 0.0596 time: 2.3722s\n",
            "Early Stopping...\n",
            "Total train time: 130.1512s\n",
            "\n",
            "==================================================\n",
            "TextGCN->BERT x SenticNet\n",
            "==================================================\n",
            "Accuracy Score: 0.9380\n",
            "F1 Score (Micro): 0.9776\n",
            "F1 Score (Macro): 0.9803\n",
            "F1 Score (Weighted): 0.9770\n",
            "Hamming Loss: 0.0117\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "       anger     1.0000    0.9091    0.9524        33\n",
            "     disgust     1.0000    1.0000    1.0000       100\n",
            "        fear     0.9865    1.0000    0.9932        73\n",
            "     sadness     1.0000    1.0000    1.0000       139\n",
            "    negative     0.9948    1.0000    0.9974       192\n",
            "       other     0.9787    0.9020    0.9388       255\n",
            "\n",
            "   micro avg     0.9909    0.9646    0.9776       792\n",
            "   macro avg     0.9933    0.9685    0.9803       792\n",
            "weighted avg     0.9906    0.9646    0.9770       792\n",
            " samples avg     0.6095    0.6010    0.6045       792\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/home/rcmcabral/.local/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in samples with no predicted labels. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/home/rcmcabral/.local/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in samples with no true labels. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        }
      ],
      "source": [
        "lexName = \"SenticNet\"\n",
        "title1 = \"TextGCN x \" + lexName\n",
        "title2 = \"TextGCN->BERT x \" + lexName\n",
        "texts = original_train_sentences\n",
        "\n",
        "lexTokens = senticNet_allTokens\n",
        "lexLabels = senticNet_allEmotions\n",
        "lexClassNames = senticNet_labels\n",
        "\n",
        "#Populate document multilabel emotions\n",
        "emoLabels, num_emoClass = encodeDocEmotions(lexTokens, lexLabels, tokenize_sentences)\n",
        "original_emoLabels_train = emoLabels[:train_size]\n",
        "emoLabels = torch.FloatTensor(emoLabels).to(device)\n",
        "\n",
        "doc_embeddings, word_embeddings = train_GCNBert()\n",
        "\n",
        "# saveWeights(\"./_OUTPUT/DocEmbeddings_\" + tokenTitle + \"Embeddings\" +  \".pkl\", texts, doc_embeddings, lexLabels, original_train_labels, lexClassNames)\n",
        "saveWordEmbeddings(\"./_OUTPUT/MMEMOG_\" + tokenTitle + \"Embeddings_\" + lexName + \".pkl\", vocab, word_embeddings)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [
        "f3QSsuKsDaz4",
        "AmEEIqrm-ZTY",
        "cVfHLyfD-ZTZ",
        "SemhFfyV-ZTa",
        "c5J2GPPG-ZTa",
        "hJPI-IXrBkrP",
        "a2W7wKTBfa71",
        "eyfCxMUJeEQ4",
        "ZMkEBxr6fMQi",
        "JWPxVGNeAPf7",
        "g0o8wcXgrTiD",
        "QESQPT88AqsI",
        "hynLnT3a33kW",
        "uIkGgB2aZDk7",
        "39Kj8NQujiDH",
        "k57M4sz4s4Md",
        "qbmfFDiOdwSd",
        "zEE4JxeUthCb",
        "bphsHbY4v1tW"
      ],
      "machine_shape": "hm",
      "provenance": [],
      "toc_visible": true
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "a09331114a3e4dc7b82fd818fe9c0797": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_46e1f89e3b78414c8e191cdd942b589b",
              "IPY_MODEL_5d6cc7c973eb47308a063b9d686f9562",
              "IPY_MODEL_1b7f486fb0504f768815be0bebb5d603"
            ],
            "layout": "IPY_MODEL_ad434b03e7ff4d138df37ebc5942f286"
          }
        },
        "46e1f89e3b78414c8e191cdd942b589b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6c738b4de124438abf2558879c3d7dc2",
            "placeholder": "​",
            "style": "IPY_MODEL_962be31c2c2c44bfb9a0290bc9929065",
            "value": "100%"
          }
        },
        "5d6cc7c973eb47308a063b9d686f9562": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8b444b280db64844b5242c8964b60f13",
            "max": 500,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_bbda5e69ffef472b9d361701f507e7a5",
            "value": 500
          }
        },
        "1b7f486fb0504f768815be0bebb5d603": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d74dc0d8381e4f9082dac5587a54fbeb",
            "placeholder": "​",
            "style": "IPY_MODEL_ee3c118a96ad4cd59af5da81cde0f233",
            "value": " 500/500 [00:00&lt;00:00, 1878.39it/s]"
          }
        },
        "ad434b03e7ff4d138df37ebc5942f286": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6c738b4de124438abf2558879c3d7dc2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "962be31c2c2c44bfb9a0290bc9929065": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "8b444b280db64844b5242c8964b60f13": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bbda5e69ffef472b9d361701f507e7a5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "d74dc0d8381e4f9082dac5587a54fbeb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ee3c118a96ad4cd59af5da81cde0f233": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e51f8ddc90254bff885281f8fd27aab3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_5ac030c53bfd40258b49c20b2ca5b068",
              "IPY_MODEL_2f7ad31d03794db2a57ded4f0590e874",
              "IPY_MODEL_887b8c925e36496eb05b92f1eab19f45"
            ],
            "layout": "IPY_MODEL_d5931ed4f6db4c1d84abb133abbd24a6"
          }
        },
        "5ac030c53bfd40258b49c20b2ca5b068": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c2ebb7e2bcd646dfb6b28935e4c79021",
            "placeholder": "​",
            "style": "IPY_MODEL_7f22547077f944eab0b66e9c2ec279ff",
            "value": "100%"
          }
        },
        "2f7ad31d03794db2a57ded4f0590e874": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_31156e7183d84a9d9c28d0b2ff03ccd3",
            "max": 500,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_3a255fe720334bfcbc8e7b83f018138d",
            "value": 500
          }
        },
        "887b8c925e36496eb05b92f1eab19f45": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4b1c4c65ff5744f3babe93337751193a",
            "placeholder": "​",
            "style": "IPY_MODEL_d95669ae893d4c4696336b73db108a90",
            "value": " 500/500 [00:00&lt;00:00, 1929.92it/s]"
          }
        },
        "d5931ed4f6db4c1d84abb133abbd24a6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c2ebb7e2bcd646dfb6b28935e4c79021": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7f22547077f944eab0b66e9c2ec279ff": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "31156e7183d84a9d9c28d0b2ff03ccd3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3a255fe720334bfcbc8e7b83f018138d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "4b1c4c65ff5744f3babe93337751193a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d95669ae893d4c4696336b73db108a90": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d22cabc301f24cba8d562308d4467148": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_362215065fc5406bb37ff377ad4e3210",
              "IPY_MODEL_4e5b0df2ded74685b2a8da4d6d90def1",
              "IPY_MODEL_657da52bf0b7428fbadb1e8f629fc156"
            ],
            "layout": "IPY_MODEL_9fda2e44284b40a49b722151b0b31b44"
          }
        },
        "362215065fc5406bb37ff377ad4e3210": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_285dcbae20f34e09aa13a77c4c08e7ce",
            "placeholder": "​",
            "style": "IPY_MODEL_db94baa55dbe4867ae3100eff5fe556a",
            "value": "100%"
          }
        },
        "4e5b0df2ded74685b2a8da4d6d90def1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_39aa61b334be4a63b11a0f6e8de01259",
            "max": 500,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_cfa0fb88dbe642ad8f697d6e5b0f6196",
            "value": 500
          }
        },
        "657da52bf0b7428fbadb1e8f629fc156": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ea83dccc30884aef85979303a6c9ef14",
            "placeholder": "​",
            "style": "IPY_MODEL_38b339df01f44995b066111f0daf6db6",
            "value": " 500/500 [00:00&lt;00:00, 3558.18it/s]"
          }
        },
        "9fda2e44284b40a49b722151b0b31b44": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "285dcbae20f34e09aa13a77c4c08e7ce": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "db94baa55dbe4867ae3100eff5fe556a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "39aa61b334be4a63b11a0f6e8de01259": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "cfa0fb88dbe642ad8f697d6e5b0f6196": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "ea83dccc30884aef85979303a6c9ef14": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "38b339df01f44995b066111f0daf6db6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a5d7757e709c42f789253a8d26674c2b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_026eb4e8446a48bd953f5fb3aa419593",
              "IPY_MODEL_d7046fde62c345acbf63fd0b54679d7c",
              "IPY_MODEL_b29321930db841c0ac8b895c500a23ef"
            ],
            "layout": "IPY_MODEL_fac2526914124391a0e4a192616f4b6a"
          }
        },
        "026eb4e8446a48bd953f5fb3aa419593": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ca0a1c5d01fd43beac670245cf3a4ef7",
            "placeholder": "​",
            "style": "IPY_MODEL_288c8578cbc1437587d424390ecfcc4a",
            "value": "100%"
          }
        },
        "d7046fde62c345acbf63fd0b54679d7c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_483b4dd656744f70aa33dab28328a052",
            "max": 500,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_486416b80c7f4a64ad9ca2bfac222a2e",
            "value": 500
          }
        },
        "b29321930db841c0ac8b895c500a23ef": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5de050a8934a451d9fd95b82f7c71ada",
            "placeholder": "​",
            "style": "IPY_MODEL_3608b7a9b5434da59f3a7a67bd91bd03",
            "value": " 500/500 [00:00&lt;00:00, 1141.11it/s]"
          }
        },
        "fac2526914124391a0e4a192616f4b6a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ca0a1c5d01fd43beac670245cf3a4ef7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "288c8578cbc1437587d424390ecfcc4a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "483b4dd656744f70aa33dab28328a052": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "486416b80c7f4a64ad9ca2bfac222a2e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "5de050a8934a451d9fd95b82f7c71ada": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3608b7a9b5434da59f3a7a67bd91bd03": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f8acffe7c2174ad8a7c83d92085c1f8e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_86a7081bb8b6496dbc4a55d792e22bf9",
              "IPY_MODEL_32eb260f8aa44627b6dfd31c47706411",
              "IPY_MODEL_68eae634396649c48be47a5e0a855d29"
            ],
            "layout": "IPY_MODEL_3206873d6ade4ce2a2af982beecee3a2"
          }
        },
        "86a7081bb8b6496dbc4a55d792e22bf9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_902ca8fb17d143b7840b7af112edb5b8",
            "placeholder": "​",
            "style": "IPY_MODEL_311a915b3b284c9bb7a775b2b027cfe3",
            "value": "100%"
          }
        },
        "32eb260f8aa44627b6dfd31c47706411": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0d83c8b157b54de1a5ced74cf5156da0",
            "max": 500,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_8edb55c069504913b73150b5c78f962d",
            "value": 500
          }
        },
        "68eae634396649c48be47a5e0a855d29": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_856a23f5f19342b2a502c10d8790f96a",
            "placeholder": "​",
            "style": "IPY_MODEL_5f56360c36314fab8015fc2fde6cd246",
            "value": " 500/500 [00:11&lt;00:00, 50.33it/s]"
          }
        },
        "3206873d6ade4ce2a2af982beecee3a2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "902ca8fb17d143b7840b7af112edb5b8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "311a915b3b284c9bb7a775b2b027cfe3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "0d83c8b157b54de1a5ced74cf5156da0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8edb55c069504913b73150b5c78f962d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "856a23f5f19342b2a502c10d8790f96a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5f56360c36314fab8015fc2fde6cd246": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}